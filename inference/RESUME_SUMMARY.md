# Resume åŠŸèƒ½æ€»ç»“

## ğŸ¯ å¿«é€Ÿå›ç­”ä½ çš„é—®é¢˜

**é—®é¢˜**: å¦‚ä½•è¿è¡Œresumeçš„text_html & mix_htmlï¼Ÿ

**ç­”æ¡ˆ**ï¼šä¸‰ç§æ–¹å¼ï¼Œä»ç®€åˆ°å¤æ‚ï¼š

### æ–¹å¼ 1ï¸âƒ£ - **æœ€ç®€å•**ï¼ˆä¸€è¡Œå‘½ä»¤ï¼‰

```bash
# åŒæ—¶è¿è¡Œä¸¤ä¸ªæ¨¡æ€ï¼ˆé¡ºåºæ‰§è¡Œï¼Œ~1å°æ—¶ï¼‰
bash run_resume_both.sh

# æˆ–å¹¶è¡Œè¿è¡Œï¼ˆéœ€è¦8+GPUï¼‰
bash run_resume_both.sh --parallel
```

### æ–¹å¼ 2ï¸âƒ£ - **æ ‡å‡†æ–¹å¼**ï¼ˆåŒ…è£…è„šæœ¬ï¼‰

```bash
# Text HTMLï¼ˆ~30åˆ†é’Ÿï¼‰
python run_text_html_truncate.py

# Mix HTMLï¼ˆ~30åˆ†é’Ÿï¼‰
python run_mix_html_truncate.py
```

### æ–¹å¼ 3ï¸âƒ£ - **å®Œå…¨æ§åˆ¶**ï¼ˆç›´æ¥è°ƒç”¨ï¼‰

```bash
# Text HTML with full parameters
python inference_qwen3vl_local_a100_truncate.py \
  --modality text \
  --format html \
  --model_dir /data/pan/4xin/models/Qwen3-VL-8B-Instruct \
  --data_path /data/pan/4xin/datasets/RealHiTBench \
  --resume \
  --batch_size 1

# Mix HTML with full parameters
python inference_qwen3vl_local_a100_truncate.py \
  --modality mix \
  --format html \
  --model_dir /data/pan/4xin/models/Qwen3-VL-8B-Instruct \
  --data_path /data/pan/4xin/datasets/RealHiTBench \
  --resume \
  --batch_size 1
```

---

## ğŸ” Resume æœºåˆ¶æ ¸å¿ƒåŸç†

### æ¦‚å¿µ

Resume = **æ™ºèƒ½è·³è¿‡å·²æˆåŠŸ + è‡ªåŠ¨é‡æ–°å¤„ç†å·²å¤±è´¥**

### æµç¨‹

```
åŠ è½½checkpoint.json
  â”œâ”€ results: 3060ä¸ªç»“æœï¼ˆ3043æˆåŠŸ + 17ä¸ªERRORï¼‰
  â””â”€ processed_ids: ä»…3043ä¸ªæˆåŠŸID

å¤„ç†å¾ªç¯:
  for query in all_queries:
    if query['id'] in processed_ids:  # 3043ä¸ª
      skip âœ“
    else:                              # 17ä¸ª
      process with truncation

ä¿å­˜ç»“æœ
  âœ“ 17ä¸ªERRORæ ·æœ¬æˆåŠŸå¤„ç†
  âœ“ æœ€ç»ˆ3060ä¸ªå…¨éƒ¨æˆåŠŸ
```

### å…³é”®ç‰¹æ€§

| ç‰¹æ€§ | è¯´æ˜ |
|------|------|
| **è‡ªåŠ¨ERRORæ£€æµ‹** | ERRORç»“æœä¸åœ¨processed_idsä¸­ï¼Œè‡ªåŠ¨è¢«é‡æ–°å¤„ç† |
| **æ–‡æœ¬æˆªæ–­** | MAX_INPUT_TOKENS=100,000ï¼Œè‡ªåŠ¨æˆªæ–­è¶…å¤§è¾“å…¥ |
| **æ–­ç‚¹ç»­ä¼ ** | ä¸­æ–­åç›´æ¥--resumeç»§ç»­ï¼Œæ— éœ€é‡æ–°å¼€å§‹ |
| **é«˜æ•ˆå¤„ç†** | ä»…å¤„ç†17ä¸ªå¤±è´¥æ ·æœ¬ï¼ŒèŠ‚çœ93%æ—¶é—´ |

---

## ğŸ“Š å·¥ä½œåŸç†è¯¦è§£

### ä¸ºä»€ä¹ˆERRORæ ·æœ¬ä¼šè¢«è‡ªåŠ¨é‡æ–°å¤„ç†ï¼Ÿ

```python
# åŸå› ï¼šé”™è¯¯çš„ç»“æœä¸è¢«æ ‡è®°ä¸º"å·²å¤„ç†"

# æˆåŠŸçš„æŸ¥è¯¢ï¼š
# ID 2746:
#   Prediction: "Based on the table, the answer is..."
#   â†’ åŠ å…¥ processed_ids âœ“

# å¤±è´¥çš„æŸ¥è¯¢ï¼ˆERRORï¼‰ï¼š
# ID 2747:
#   Prediction: "[ERROR] OOM: CUDA out of memory"
#   â†’ ä¸åŠ å…¥ processed_ids âŒ
#      ï¼ˆå› ä¸ºè¿™ä¸æ˜¯ä¸€ä¸ª"æˆåŠŸ"çš„ç»“æœï¼‰

# Resumeæ—¶çš„skipé€»è¾‘ï¼š
if query['id'] in processed_ids:
    continue  # åªè·³è¿‡å·²æˆåŠŸçš„
# æ‰€ä»¥ID 2747ä¼šè‡ªåŠ¨è¿›å…¥å¤„ç†å¾ªç¯
```

### æ–‡æœ¬æˆªæ–­å¦‚ä½•å·¥ä½œï¼Ÿ

```
è¾“å…¥: economy-table14_swap.html (334,162 tokens)
      â†“
æ£€æµ‹: tokens (334,162) > MAX_INPUT_TOKENS (100,000)?
      â”œâ”€ YES â†’ è§¦å‘æˆªæ–­
      â””â”€ è®¡ç®—æˆªæ–­æ¯”: 100,000 / 334,162 = 0.299
      â†“
æˆªæ–­: ä¿ç•™ 90% * 0.299 = 26.9% çš„åŸæ–‡æœ¬ (~89,814 chars)
      â†“
è¾“å‡º: Truncated HTML (99,847 tokens) âœ“
```

---

## ğŸ“‚ æ–‡ä»¶ç»“æ„

### æ¨ç†è„šæœ¬

```
inference/
â”œâ”€â”€ inference_qwen3vl_local_a100_truncate.py  â† æ ¸å¿ƒè„šæœ¬ï¼ˆ1272è¡Œï¼‰
â”‚   â””â”€â”€ åŠŸèƒ½ï¼šresume + ERRORæ£€æµ‹ + æ–‡æœ¬æˆªæ–­
â”œâ”€â”€ run_text_html_truncate.py                â† Text HTMLåŒ…è£…è„šæœ¬
â”œâ”€â”€ run_mix_html_truncate.py                 â† Mix HTMLåŒ…è£…è„šæœ¬
â””â”€â”€ run_resume_both.sh                       â† ä¸€é”®è¿è¡Œè„šæœ¬
```

### æ£€æŸ¥ç‚¹ä½ç½®

```
result/
â”œâ”€â”€ qwen3vl_local_a100/
â”‚   â””â”€â”€ Qwen3-VL-8B-Instruct_text_html_a100/
â”‚       â””â”€â”€ checkpoint.json â† åŸå§‹ï¼ˆ17ä¸ªERRORï¼‰
â””â”€â”€ qwen3vl_local_a100_truncate/
    â”œâ”€â”€ Qwen3-VL-8B-Instruct_text_html_truncate/
    â”‚   â””â”€â”€ checkpoint.json â† Resumeç›®æ ‡
    â””â”€â”€ Qwen3-VL-8B-Instruct_mix_html_truncate/
        â””â”€â”€ checkpoint.json â† Resumeç›®æ ‡
```

---

## ğŸš€ å®Œæ•´å·¥ä½œæµ

### ç¬¬ä¸€æ¬¡è¿è¡Œï¼ˆåˆå§‹åŒ–ï¼‰

```bash
# 1. éªŒè¯å’Œè®¾ç½®
bash DEPLOYMENT_GUIDE.sh
# âœ“ æ£€æŸ¥ç¯å¢ƒã€å¤åˆ¶checkpointsã€éªŒè¯17ä¸ªOOMæ ·æœ¬

# 2. è¿è¡Œresume
bash run_resume_both.sh
# âœ“ Text HTML: å¤„ç†17ä¸ªERROR â†’ æˆåŠŸ
# âœ“ Mix HTML: å¤„ç†17ä¸ªERROR â†’ æˆåŠŸ

# 3. éªŒè¯ç»“æœ
python << 'EOF'
import json
for mode in ['text_html', 'mix_html']:
    path = f'../result/qwen3vl_local_a100_truncate/Qwen3-VL-8B-Instruct_{mode}_truncate/checkpoint.json'
    data = json.load(open(path))
    errors = len([r for r in data['results'] if '[ERROR' in r.get('Prediction', '')])
    print(f"{mode}: {errors} errors remaining")
    # é¢„æœŸè¾“å‡º: errors = 0 âœ“
EOF
```

### ä¸­æ–­å’Œæ¢å¤

```bash
# è¿è¡Œä¸­æŒ‰ Ctrl+C ä¸­æ­¢
^C
# âœ“ Checkpointè‡ªåŠ¨ä¿å­˜

# ç¨åç»§ç»­è¿è¡Œç›¸åŒå‘½ä»¤
python inference_qwen3vl_local_a100_truncate.py \
  --modality text --format html --resume
# âœ“ ä»ä¸Šæ¬¡åœæ­¢çš„åœ°æ–¹ç»§ç»­
```

### å›æ»šåˆ°åŸå§‹çŠ¶æ€

```bash
# å¦‚æœéœ€è¦é‡æ–°å¼€å§‹
rm -rf ../result/qwen3vl_local_a100_truncate/

# ç„¶åé‡æ–°è¿è¡ŒDEPLOYMENT_GUIDE.shå’Œrun_resume_both.sh
```

---

## ğŸ“ˆ æ€§èƒ½å¯¹æ¯”

| æ–¹å¼ | å¤„ç†æ ·æœ¬ | æ—¶é—´ | GPUåˆ©ç”¨ | æ•ˆç‡ |
|------|---------|------|--------|------|
| âŒ å®Œå…¨é‡æ–°è¿è¡Œ | 3071ä¸ª | ~15å°æ—¶ | é«˜ | ä½ |
| âœ… Resumeå¤„ç† | 17ä¸ª | ~1å°æ—¶ | é«˜ | é«˜ |
| **èŠ‚çœ** | **99.4%** | **93%** | - | **15x** |

---

## ğŸ”§ æŠ€æœ¯ç»†èŠ‚

### Resumeå‚æ•°

```python
# å…³é”®å‚æ•°
--resume                # å¯ç”¨resumeæ¨¡å¼ï¼ˆä»checkpointç»§ç»­ï¼‰
--modality [text|mix|image]  # è¾“å…¥æ¨¡æ€
--format [html|markdown|latex|csv]  # æ–‡æœ¬æ ¼å¼
--batch_size 1          # æ‰¹å¤§å°ï¼ˆæ¨è1ï¼‰
--max_queries -1        # æœ€å¤§æŸ¥è¯¢æ•°ï¼ˆ-1=å…¨éƒ¨ï¼‰

# æ–‡æœ¬æˆªæ–­é…ç½®ï¼ˆåœ¨è„šæœ¬ä¸­ï¼‰
MAX_INPUT_TOKENS = 100,000  # æˆªæ–­é˜ˆå€¼
```

### Checkpointæ ¼å¼

```json
{
  "results": [
    {
      "id": 2746,
      "Prediction": "Based on the table...",
      "question": "...",
      ...
    },
    ...
    {
      "id": 2747,
      "Prediction": "[ERROR] OOM: CUDA out of memory",  // â† ERROR
      ...
    }
  ],
  "processed_ids": [2746, 2748, 2749, ...],  // â† ä¸åŒ…å«2747
  "config": {...}
}
```

### é”™è¯¯æ£€æµ‹ä»£ç 

```python
# åœ¨gen_solution_batchä¸­
error_ids = set()
successful_results = []
processed_ids = set()

for result in all_eval_results:
    if result['Prediction'].startswith('[ERROR'):
        error_ids.add(result['id'])  # æ ‡è®°ä¸ºé”™è¯¯
        # ä¸åŠ å…¥processed_idsï¼Œæ‰€ä»¥ä¼šè¢«é‡æ–°å¤„ç†
    else:
        successful_results.append(result)
        processed_ids.add(result['id'])  # æ ‡è®°ä¸ºå·²å¤„ç†
```

---

## âš ï¸ å¸¸è§é—®é¢˜

### Q: Resumeåè¿˜æœ‰ERRORï¼Ÿ

A: å°è¯•è¿™äº›æ­¥éª¤ï¼š
1. æ£€æŸ¥æ˜¾å­˜: `nvidia-smi`
2. é‡Šæ”¾æ˜¾å­˜: `pkill python`
3. å‡å°batch_size: `--batch_size 1`
4. æ£€æŸ¥æ—¥å¿—: `tail -f *.log`

### Q: æˆªæ–­åä¼šä¸¢å¤±ä¿¡æ¯å—ï¼Ÿ

A: ä¸ä¼šæ˜¾è‘—å½±å“ï¼Œå› ä¸ºï¼š
- ä¿ç•™äº†26.9%çš„åŸæ–‡æœ¬
- é€šå¸¸è¶³ä»¥ä¿ç•™è¡¨æ ¼å…³é”®ä¿¡æ¯
- ä¼˜äºOOMå¯¼è‡´å®Œå…¨å¤±è´¥

### Q: å¦‚ä½•éªŒè¯resumeæˆåŠŸï¼Ÿ

A: 
```bash
# æ–¹æ³•1: æ£€æŸ¥é”™è¯¯æ•°
python << 'EOF'
import json
data = json.load(open(...checkpoint.json'))
errors = len([r for r in data['results'] if '[ERROR' in r.get('Prediction', '')])
print(f"Errors: {errors}")  # åº”è¯¥æ˜¯0
EOF

# æ–¹æ³•2: æ¯”è¾ƒåŸå§‹å’Œæ–°ç»“æœ
diff <(jq '.results[].id' original.json) \
     <(jq '.results[].id' truncate.json)
# åº”è¯¥æ˜¯ä¸€è‡´çš„ï¼ˆ3060ä¸ªIDï¼‰
```

### Q: ä¸­æ–­åå¦‚ä½•ç»§ç»­ï¼Ÿ

A: ç›´æ¥è¿è¡Œç›¸åŒå‘½ä»¤ï¼ŒåŠ ä¸Š--resumeå³å¯

```bash
# ä¸­æ­¢: Ctrl+C
# ç»§ç»­: è¿è¡Œç›¸åŒå‘½ä»¤
python inference_qwen3vl_local_a100_truncate.py --resume ...
```

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [RESUME_USAGE_GUIDE.md](RESUME_USAGE_GUIDE.md) - è¯¦ç»†ä½¿ç”¨æŒ‡å—
- [RESUME_QUICK_COMMANDS.sh](RESUME_QUICK_COMMANDS.sh) - å¿«é€Ÿå‘½ä»¤å‚è€ƒ
- [RESUME_DETAILED_FLOWCHART.md](RESUME_DETAILED_FLOWCHART.md) - è¯¦ç»†æµç¨‹å›¾
- [DEPLOYMENT_GUIDE.sh](DEPLOYMENT_GUIDE.sh) - éƒ¨ç½²å’Œåˆå§‹åŒ–
- [QUICKSTART_ERROR_FIX.md](QUICKSTART_ERROR_FIX.md) - å¿«é€Ÿå¼€å§‹æŒ‡å—

---

## ğŸ“ å…³é”®æ¦‚å¿µæ€»ç»“

| æ¦‚å¿µ | è§£é‡Š |
|------|------|
| **Resume** | ä»checkpointç»§ç»­å¤„ç†ï¼Œæ™ºèƒ½è·³è¿‡æˆåŠŸæ ·æœ¬ï¼Œé‡æ–°å¤„ç†å¤±è´¥æ ·æœ¬ |
| **Checkpoint** | ä¿å­˜å·²å¤„ç†æŸ¥è¯¢çš„IDåˆ—è¡¨ï¼Œå…è®¸æ–­ç‚¹ç»­ä¼  |
| **Processed IDs** | æˆåŠŸå®Œæˆçš„æŸ¥è¯¢IDé›†åˆï¼Œç”¨äºåœ¨resumeæ—¶è·³è¿‡ |
| **ERRORæ£€æµ‹** | æ£€æŸ¥Predictionå­—æ®µæ˜¯å¦ä»¥"[ERROR"å¼€å¤´ |
| **æ–‡æœ¬æˆªæ–­** | å½“è¾“å…¥tokenæ•°>100,000æ—¶è‡ªåŠ¨æˆªæ–­ |
| **Max Tokens** | 100,000 - ä¿å®ˆçš„æˆªæ–­é˜ˆå€¼ï¼Œé˜²æ­¢OOM |
| **Modality** | è¾“å…¥ç±»å‹ï¼štextï¼ˆä»…æ–‡æœ¬ï¼‰ã€mixï¼ˆæ–‡æœ¬+å›¾åƒï¼‰ã€imageï¼ˆä»…å›¾åƒï¼‰ |

---

## âœ… éªŒè¯æ¸…å•

åœ¨è¿è¡Œresumeå‰æ£€æŸ¥ï¼š

- [ ] Python 3.10+
- [ ] CUDAå¯ç”¨ï¼ˆ4+ GPUæ¨èï¼‰
- [ ] æ¨¡å‹ç›®å½•å­˜åœ¨: `/data/pan/4xin/models/Qwen3-VL-8B-Instruct`
- [ ] æ•°æ®é›†å­˜åœ¨: `/data/pan/4xin/datasets/RealHiTBench`
- [ ] åŸå§‹checkpointå­˜åœ¨: `result/qwen3vl_local_a100/*/checkpoint.json`
- [ ] è¾“å‡ºç›®å½•åˆ›å»º: `result/qwen3vl_local_a100_truncate/*/`

è¿è¡Œresumeåæ£€æŸ¥ï¼š

- [ ] è„šæœ¬å®Œæˆæ— é”™è¯¯
- [ ] Checkpointå·²ä¿å­˜: `checkpoint.json`
- [ ] æœ€ç»ˆç»“æœæ–‡ä»¶: `results_batch_*.json`
- [ ] é”™è¯¯æ•°ä¸º0: `errors = 0` âœ“
- [ ] å¤„ç†çš„æ ·æœ¬æ•°æ­£ç¡®: `total = 3060`

---

æœ€åæ›´æ–°: 2024å¹´
ä½œè€…: GitHub Copilot

**å»ºè®®**: ç°åœ¨å°±è¿è¡Œ `bash run_resume_both.sh` æ¥å¤„ç†è¿™17ä¸ªOOMæ ·æœ¬ï¼
