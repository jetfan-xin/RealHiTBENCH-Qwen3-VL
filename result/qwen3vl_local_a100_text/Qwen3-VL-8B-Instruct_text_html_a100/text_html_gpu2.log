`torch_dtype` is deprecated! Use `dtype` instead!
Configuration:
  Model: /data/pan/4xin/models/Qwen3-VL-8B-Instruct
  Modality: text
  Format: html
  Data path: /data/pan/4xin/datasets/RealHiTBench
  Use Flash Attention: True
  Multi-GPU Mode: Data Parallel (DataParallel)
  Generation Settings (Qwen3-VL Instruct Recommended):
    Temperature: 0.7
    Top-p: 0.8
    Top-k: 20
    Repetition Penalty: 1.0
    Presence Penalty: 1.5
    Max Tokens: 32768
  Batch size: 2

============================================================
BATCH INFERENCE MODE (batch_size=2)
============================================================
Loading Qwen3-VL model from /data/pan/4xin/models/Qwen3-VL-8B-Instruct...
Available GPUs: 1
Using DATA PARALLELISM (DataParallel) - all GPUs compute simultaneously
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 39.40it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 39.32it/s]
Model loaded with flash_attention_2 attention on cuda:0
Single GPU detected, DataParallel not needed
Processor configured with dynamic resolution: min_pixels=200704, max_pixels=1605632
Successfully loaded F1, EM, ROUGE, SacreBLEU
Loaded QA file: QA_final_sc_filled.json (3071 queries)
Pending queries after filtering: 3071
Processing batches:   0%|          | 0/1536 [00:00<?, ?it/s]Processing batches:   0%|          | 1/1536 [00:07<3:22:29,  7.91s/it]Processing batches:   0%|          | 2/1536 [00:13<2:45:21,  6.47s/it]
============================================================
Batch 1/1536: Processing 2 queries
============================================================
Predictions:  ['1953 6260', '1953']
Answer:  ['1955 62170', '1954']
Predictions:  ['1953 6260']
Answer:  ['1955 62170']
  [Batch] Query 1: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.84s avg)
Predictions:  ['1953']
Answer:  ['1954']
  [Batch] Query 2: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.84s avg)
Checkpoint saved: 2 queries processed

============================================================
Batch 2/1536: Processing 2 queries
============================================================
Predictions:  ['2022', '161037']
Answer:  ['1953', '158772']
Predictions:  ['2022']
Answer:  ['1953']
  [Batch] Query 3: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.61s avg)
Predictions:  ['161037']
Answer:  ['158772']
  [Batch] Query 4: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.61s avg)
Checkpoint saved: 4 queries processed

============================================================
Batch 3/1536: Processing 2 queries
============================================================
Predictions:  ['53 15']
Answer:  ['58 16']
Predictions:  ['53 15']
Answer:  ['58 16']
  [Batch] Query 5: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.66s avg)
  Warning: Large text input (18088 tokens)
Processing batches:   0%|          | 3/1536 [00:32<5:07:14, 12.02s/it]Processing batches:   0%|          | 4/1536 [00:38<4:15:44, 10.02s/it]  [Single] Query 6: {'GPT_EVAL': 'N/A (no eval_api_key)'} (14.86s)
Checkpoint saved: 6 queries processed

============================================================
Batch 4/1536: Processing 2 queries
============================================================
Predictions:  ['562 increasing trend', 'strong positive correlation 10']
Answer:  ['predicted percentage for 1965 551', 'strong positive correlation 10']
Predictions:  ['562 increasing trend']
Answer:  ['predicted percentage for 1965 551']
  [Batch] Query 7: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.35s avg)
Predictions:  ['strong positive correlation 10']
Answer:  ['strong positive correlation 10']
  [Batch] Query 8: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (3.35s avg)
Checkpoint saved: 8 queries processed

============================================================
Batch 5/1536: Processing 2 queries
============================================================
Predictions:  ['1991']
Answer:  ['1983']
Predictions:  ['1991']
Answer:  ['1983']
  [Batch] Query 10: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.91s avg)
  Warning: Large text input (18075 tokens)
Processing batches:   0%|          | 5/1536 [00:45<3:48:12,  8.94s/it]Processing batches:   0%|          | 6/1536 [00:53<3:34:15,  8.40s/it]Processing batches:   0%|          | 7/1536 [00:59<3:13:32,  7.59s/it]  [Single] Query 9: {'GPT_EVAL': 'N/A (no eval_api_key)'} (4.01s)
Checkpoint saved: 10 queries processed

============================================================
Batch 6/1536: Processing 2 queries
============================================================
Predictions:  ['yes', '44607']
Answer:  ['no', '39957']
Predictions:  ['yes']
Answer:  ['no']
  [Batch] Query 11: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.56s avg)
Predictions:  ['44607']
Answer:  ['39957']
  [Batch] Query 12: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.56s avg)
Checkpoint saved: 12 queries processed

============================================================
Batch 7/1536: Processing 2 queries
============================================================
Predictions:  ['no', '1986']
Answer:  ['yes', '1986']
Predictions:  ['no']
Answer:  ['yes']
  [Batch] Query 13: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.84s avg)
Predictions:  ['1986']
Answer:  ['1986']
  [Batch] Query 14: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (2.84s avg)
Checkpoint saved: 14 queries processed

============================================================
Batch 8/1536: Processing 2 queries
============================================================
  Warning: Large text input (20196 tokens)
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel("/data/pan/4xin/datasets/RealHiTBench/tables/employment-table02.xlsx")
years = [1985, 1987, 1989]
civilian_population = df[df['Year'].isin(years)]['Civilian noninstitutional population'].values
employed_population = df[df['Year'].isin(years)]['Employed Total'].values
plt.bar(years, civilian_population, label='Civilian Population', alpha=0.7)
plt.bar(years, employed_population, label='Employed Population', alpha=0.7)
plt.xlabel('Year')
plt.ylabel('Population')
plt.title('Comparison of Civilian Population and Employed Population (1985, 1987, 1989)')
plt.legend()
plt.xticks(years)
plt.show()

Python Error: 'Civilian noninstitutional population'
  [Single] Query 15: {'ECR': False, 'Pass': False} (11.43s)
  Warning: Large text input (20180 tokens)
invalid visualization_answer: import pandas as pd 
 import matplotlib.pyplot as plt 
 df = pd.read_excel("/data/pan/4xin/datasets/RealHiTBench/tables/employment-table02.xlsx")
 df_men = df[df['Year'].isin(df['Year'])]
 df_women = df[df['Year'].isin(df['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men['Year'].isin(df_men['Year'])]
 df_women = df_women[df_women['Year'].isin(df_women['Year'])]
 df_men = df_men[df_men
Processing batches:   1%|          | 8/1536 [04:46<32:54:49, 77.55s/it]
Code: 

Python Error: expected an indented block after 'if' statement on line 2 (<string>, line 3)
  [Single] Query 16: {'ECR': False, 'Pass': False} (215.89s)
Checkpoint saved: 16 queries processed

============================================================
Batch 9/1536: Processing 2 queries
============================================================
  Warning: Large text input (20184 tokens)
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel("/data/pan/4xin/datasets/RealHiTBench/tables/employment-table02.xlsx")
data_1984 = df[df['Year'] == 1984]
agriculture = data_1984.iloc[0, 6]  # Agriculture employment in 1984
non_agriculture = data_1984.iloc[0, 7]  # Non-agriculture employment in 1984
labels = ['Agriculture', 'Non-agriculture']
sizes = [agriculture, non_agriculture]
plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
plt.title('Employment Distribution in 1984')
plt.show()

OUTPUT VALUE: [0.05, 0.95]

  [Single] Query 17: {'ECR': True, 'Pass': True} (11.95s)
  Warning: Large text input (20187 tokens)
Processing batches:   1%|          | 9/1536 [08:34<52:47:51, 124.47s/it]Processing batches:   1%|          | 10/1536 [08:55<39:11:40, 92.46s/it]invalid visualization_answer: import pandas as pd 
 import matplotlib.pyplot as plt 
 df = pd.read_excel("/data/pan/4xin/datasets/RealHiTBench/tables/employment-table02.xlsx")
 df_filtered = df[(df['Year'] >= 1983) & (df['Year'] <= 1990)]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990])]
 df_filtered = df_filtered[df_filtered['Year'].isin([1983, 1984, 1985, 1

Code: 

Python Error: expected an indented block after 'if' statement on line 2 (<string>, line 3)
  [Single] Query 18: {'ECR': False, 'Pass': False} (215.71s)
Checkpoint saved: 18 queries processed

============================================================
Batch 10/1536: Processing 2 queries
============================================================
Predictions:  ['167116', '35 to 44 years 30 to 34 years']
Answer:  ['161037', '35 to 39 years 35 to 44 years']
Predictions:  ['167116']
Answer:  ['161037']
  [Batch] Query 19: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (10.27s avg)
Predictions:  ['35 to 44 years 30 to 34 years']
Answer:  ['35 to 39 years 35 to 44 years']
  [Batch] Query 20: {'F1': 75.0, 'EM': 0.0, 'ROUGE-L': 62.5, 'SacreBLEU': 38.26} (10.27s avg)
Checkpoint saved: 20 queries processed
Processing batches:   1%|          | 11/1536 [09:14<29:39:55, 70.03s/it]
============================================================
Batch 11/1536: Processing 2 queries
============================================================
Predictions:  ['266942', '626 36']
Answer:  ['99826', '639']
Predictions:  ['266942']
Answer:  ['99826']
  [Batch] Query 21: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (9.46s avg)
Predictions:  ['626 36']
Answer:  ['639']
  [Batch] Query 22: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (9.46s avg)
Checkpoint saved: 22 queries processed

============================================================
Batch 12/1536: Processing 2 queries
============================================================
  Warning: Large text input (49905 tokens)
Code: import pandas as pd
import matplotlib.pyplot as plt

# Load the data from the HTML table
df = pd.read_html("/data/pan/4xin/datasets/RealHiTBench/tables/employment-table03.xlsx", header=0)[0]

# Filter for '16 years and over' age group
filtered_df = df[df['Age, sex, and race'] == '16 years and over']

# Extract the relevant data for 'employed', 'unemployed', and 'not in the labor force'
employed = filtered_df.iloc[0]['Civilian labor force'] if 'Civilian labor force' in filtered_df.columns else 0
unemployed = filtered_df.iloc[0]['Unemployed'] if 'Unemployed' in filtered_df.columns else 0
not_in_labor_force = filtered_df.iloc[0]['Not in labor force'] if 'Not in labor force' in filtered_df.columns else 0

# Create a pie chart
labels = ['Employed', 'Unemployed', 'Not in Labor Force']
sizes = [employed, unemployed, not_in_labor_force]
colors = ['gold', 'yellowgreen', 'lightcoral']
explode = (0.1, 0, 0)  # explode the first slice

plt.figure(figsize=(8, 8))
plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=140)
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
plt.title('Distribution of Civilian Non-Institutional Population (16 years and over)')
plt.show()

Python Error: 'utf-8' codec can't decode byte 0x87 in position 10: invalid start byte
  [Single] Query 23: {'ECR': False, 'Pass': False} (29.75s)
  Warning: Large text input (49881 tokens)
Processing batches:   1%|          | 12/1536 [10:17<28:43:17, 67.85s/it]Processing batches:   1%|          | 13/1536 [10:29<21:34:37, 51.00s/it]Processing batches:   1%|          | 14/1536 [10:49<17:35:50, 41.62s/it]Code: import pandas as pd
import matplotlib.pyplot as plt

# Load the data from the HTML table
df = pd.read_html('/data/pan/4xin/datasets/RealHiTBench/tables/employment-table03.xlsx', header=0)[0]

# Filter the data for unemployment rates (percentage of labor force unemployed)
# We focus on the 'Civilian labor force' section and 'Unemployed' sub-section
unemployment_data = df[df['Age, sex, and race'].isin(['16 years and over', '16 to 19 years', '18 to 19 years', '20 to 24 years', '25 to 54 years', '25 to 34 years', '30 to 34 years', '35 to 44 years', '35 to 39 years', '40 to 44 years', '45 to 54 years', '45 to 49 years', '50 to 54 years', '55 to 64 years', '55 to 59 years', '60 to 64 years', '65 years and over', '65 to 69 years', '70 to 74 years', '75 years and over'])]

# Extract the relevant columns: Age group and unemployment rate (percentage of labor force unemployed)
age_groups = unemployment_data['Age, sex, and race'].dropna().tolist()
unemployment_rates = unemployment_data['Percent of labor force'].dropna().tolist()

# Create a bar chart
plt.figure(figsize=(14, 8))
plt.bar(age_groups, unemployment_rates, color='skyblue')
plt.xlabel('Age Groups')
plt.ylabel('Unemployment Rate (%)')
plt.title('Unemployment Rates by Age Group')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

Python Error: 'utf-8' codec can't decode byte 0x87 in position 10: invalid start byte
  [Single] Query 24: {'ECR': False, 'Pass': False} (33.10s)
Checkpoint saved: 24 queries processed

============================================================
Batch 13/1536: Processing 2 queries
============================================================
Predictions:  ['18 to 19 years 16 to 17 years', '15714 2892 1867 1026 1411 5034 1797 933 864 1694 855 839 1543 810 1961 841 1119 4416 1329 1145 1942']
Answer:  ['16 to 17 years', '101529']
Predictions:  ['18 to 19 years 16 to 17 years']
Answer:  ['16 to 17 years']
  [Batch] Query 25: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 34.57} (6.00s avg)
Predictions:  ['15714 2892 1867 1026 1411 5034 1797 933 864 1694 855 839 1543 810 1961 841 1119 4416 1329 1145 1942']
Answer:  ['101529']
  [Batch] Query 26: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (6.00s avg)
Checkpoint saved: 26 queries processed

============================================================
Batch 14/1536: Processing 2 queries
============================================================
Predictions:  ['25 to 54 years 35 to 44 years 40 to 44 years 30 to 34 years 25 to 34 years 20 to 24 years 18 to 19 years 16 to 19 years 16 to 17 years 75 years and over 70 to 74 years 65 to 69 years 65 years and over 55 to 64 years 50 to 54 years 45 to 54 years 45 to 49 years 35 to 39 years 40 to 44 years 30 to 34 years 25 to 29 years 25 to 34 years 20 to 24 years 18 to 19 years 16 to 19 years 16 to 17 years', '66']
Answer:  ['45 to 49 years 40 to 44 years 35 to 39 years 35 to 44 years 25 to 54 years', '66']
Predictions:  ['25 to 54 years 35 to 44 years 40 to 44 years 30 to 34 years 25 to 34 years 20 to 24 years 18 to 19 years 16 to 19 years 16 to 17 years 75 years and over 70 to 74 years 65 to 69 years 65 years and over 55 to 64 years 50 to 54 years 45 to 54 years 45 to 49 years 35 to 39 years 40 to 44 years 30 to 34 years 25 to 29 years 25 to 34 years 20 to 24 years 18 to 19 years 16 to 19 years 16 to 17 years']
Answer:  ['45 to 49 years 40 to 44 years 35 to 39 years 35 to 44 years 25 to 54 years']
  [Batch] Query 27: {'F1': 32.26, 'EM': 0.0, 'ROUGE-L': 25.81, 'SacreBLEU': 14.01} (9.85s avg)
Predictions:  ['66']
Answer:  ['66']
  [Batch] Query 28: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (9.85s avg)
Checkpoint saved: 28 queries processed

============================================================
Batch 15/1536: Processing 2 queries
============================================================
Predictions:  ['188 126']
Answer:  ['188 126']
Predictions:  ['188 126']
Answer:  ['188 126']
  [Batch] Query 29: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (2.36s avg)
  Warning: Large text input (14371 tokens)
Processing batches:   1%|          | 15/1536 [11:02<13:56:06, 32.98s/it]Processing batches:   1%|          | 16/1536 [11:05<10:12:49, 24.19s/it]Processing batches:   1%|          | 17/1536 [11:09<7:34:00, 17.93s/it]   [Single] Query 30: {'GPT_EVAL': 'N/A (no eval_api_key)'} (10.48s)
Checkpoint saved: 30 queries processed

============================================================
Batch 16/1536: Processing 2 queries
============================================================
Predictions:  ['164287', '2023 2022']
Answer:  ['164287', '2023']
Predictions:  ['164287']
Answer:  ['164287']
  [Batch] Query 31: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.77s avg)
Predictions:  ['2023 2022']
Answer:  ['2023']
  [Batch] Query 32: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (1.77s avg)
Checkpoint saved: 32 queries processed

============================================================
Batch 17/1536: Processing 2 queries
============================================================
Predictions:  ['2829', 'yes']
Answer:  ['2829', 'yes']
Predictions:  ['2829']
Answer:  ['2829']
  [Batch] Query 33: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.57s avg)
Predictions:  ['yes']
Answer:  ['yes']
  [Batch] Query 34: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.57s avg)
Checkpoint saved: 34 queries processed

============================================================
Batch 18/1536: Processing 2 queries
============================================================
Predictions:  ['543']
Answer:  ['543']
Predictions:  ['543']
Answer:  ['543']
  [Batch] Query 36: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.75s avg)
  Warning: Large text input (11524 tokens)
Processing batches:   1%|          | 18/1536 [11:18<6:23:56, 15.18s/it]Processing batches:   1%|          | 19/1536 [11:22<5:01:10, 11.91s/it]Processing batches:   1%|▏         | 20/1536 [11:26<4:00:19,  9.51s/it]Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/data/pan/4xin/datasets/RealHiTBench/tables/employment-table05.xlsx', sheet_name=0)
data = df.iloc[3:5, 1:3].values
years = ['2022', '2023']
populations = data.flatten()
plt.plot(years, populations, marker='o')
plt.title('Total Civilian Noninstitutional Population from 2022 to 2023')
plt.xlabel('Year')
plt.ylabel('Population')
plt.xticks(years)
plt.grid(True)
plt.show()

Python Error: x and y must have same first dimension, but have shapes (2,) and (4,)
  [Single] Query 35: {'ECR': False, 'Pass': False} (6.89s)
Checkpoint saved: 36 queries processed

============================================================
Batch 19/1536: Processing 2 queries
============================================================
Predictions:  ['men 16 years and over women 16 years and over', '3926 13233']
Answer:  ['men women', '4135']
Predictions:  ['men 16 years and over women 16 years and over']
Answer:  ['men women']
  [Batch] Query 37: {'F1': 33.33, 'EM': 0.0, 'ROUGE-L': 33.33, 'SacreBLEU': 4.99} (2.03s avg)
Predictions:  ['3926 13233']
Answer:  ['4135']
  [Batch] Query 38: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.03s avg)
Checkpoint saved: 38 queries processed

============================================================
Batch 20/1536: Processing 2 queries
============================================================
Predictions:  ['663 669', '591 591']
Answer:  ['1332', 'mean 2022 622 median 2022 629 mean 2023 628 median 2023 640']
Predictions:  ['663 669']
Answer:  ['1332']
  [Batch] Query 39: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.84s avg)
Predictions:  ['591 591']
Answer:  ['mean 2022 622 median 2022 629 mean 2023 628 median 2023 640']
  [Batch] Query 40: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.84s avg)
Checkpoint saved: 40 queries processed

============================================================
Batch 21/1536: Processing 2 queries
============================================================
Predictions:  ['39357 24720']
Answer:  ['39357']
Predictions:  ['39357 24720']
Answer:  ['39357']
  [Batch] Query 42: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (2.14s avg)
  Warning: Large text input (11985 tokens)
Processing batches:   1%|▏         | 21/1536 [11:41<4:39:20, 11.06s/it]Processing batches:   1%|▏         | 22/1536 [11:44<3:42:04,  8.80s/it]  [Single] Query 41: {'GPT_EVAL': 'N/A (no eval_api_key)'} (12.42s)
Checkpoint saved: 42 queries processed

============================================================
Batch 22/1536: Processing 2 queries
============================================================
Predictions:  ['bachelors degree only associate degree', '16796 17302']
Answer:  ['associate degree', '7668']
Predictions:  ['bachelors degree only associate degree']
Answer:  ['associate degree']
  [Batch] Query 43: {'F1': 57.14, 'EM': 0.0, 'ROUGE-L': 57.14, 'SacreBLEU': 21.36} (1.64s avg)
Predictions:  ['16796 17302']
Answer:  ['7668']
  [Batch] Query 44: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.64s avg)
Checkpoint saved: 44 queries processed

============================================================
Batch 23/1536: Processing 2 queries
============================================================
Predictions:  ['women less than high school diploma']
Answer:  ['women']
Predictions:  ['women less than high school diploma']
Answer:  ['women']
  [Batch] Query 45: {'F1': 28.57, 'EM': 0.0, 'ROUGE-L': 28.57, 'SacreBLEU': 8.12} (1.91s avg)
  Warning: Large text input (11772 tokens)
Processing batches:   1%|▏         | 23/1536 [11:57<4:10:26,  9.93s/it]Processing batches:   2%|▏         | 24/1536 [12:01<3:24:43,  8.12s/it]Processing batches:   2%|▏         | 25/1536 [12:05<2:55:38,  6.97s/it]  [Single] Query 46: {'GPT_EVAL': 'N/A (no eval_api_key)'} (10.54s)
Checkpoint saved: 46 queries processed

============================================================
Batch 24/1536: Processing 2 queries
============================================================
Predictions:  ['increasing trend increasing trend', 'men women']
Answer:  ['increasing trend', 'men']
Predictions:  ['increasing trend increasing trend']
Answer:  ['increasing trend']
  [Batch] Query 47: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 31.95} (1.83s avg)
Predictions:  ['men women']
Answer:  ['men']
  [Batch] Query 48: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (1.83s avg)
Checkpoint saved: 48 queries processed

============================================================
Batch 25/1536: Processing 2 queries
============================================================
Predictions:  ['436', '05 05']
Answer:  ['436', '07']
Predictions:  ['436']
Answer:  ['436']
  [Batch] Query 49: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (2.03s avg)
Predictions:  ['05 05']
Answer:  ['07']
  [Batch] Query 50: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.03s avg)
Checkpoint saved: 50 queries processed

============================================================
Batch 26/1536: Processing 2 queries
============================================================
Predictions:  ['478 481']
Answer:  ['478']
Predictions:  ['478 481']
Answer:  ['478']
  [Batch] Query 51: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (2.34s avg)
  Warning: Large text input (13903 tokens)
Processing batches:   2%|▏         | 26/1536 [12:16<3:30:32,  8.37s/it]Processing batches:   2%|▏         | 27/1536 [12:20<2:53:40,  6.91s/it]  [Single] Query 52: {'GPT_EVAL': 'N/A (no eval_api_key)'} (9.16s)
Checkpoint saved: 52 queries processed

============================================================
Batch 27/1536: Processing 2 queries
============================================================
Predictions:  ['management professional and related occupations management occupations business and financial operations occupations', '2067 33016']
Answer:  ['management professional and related occupations management occupations business and financial operations occupations', '2067']
Predictions:  ['management professional and related occupations management occupations business and financial operations occupations']
Answer:  ['management professional and related occupations management occupations business and financial operations occupations']
  [Batch] Query 53: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (1.63s avg)
Predictions:  ['2067 33016']
Answer:  ['2067']
  [Batch] Query 54: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (1.63s avg)
Checkpoint saved: 54 queries processed

============================================================
Batch 28/1536: Processing 2 queries
============================================================
  Warning: Large text input (9113 tokens)
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel("/data/pan/4xin/datasets/RealHiTBench/tables/employment-table09.xlsx")
men_2023 = df[df['Occupation'] != 'Total']['Men 2023'].values
women_2023 = df[df['Occupation'] != 'Total']['Women 2023'].values
plt.scatter(men_2023, women_2023)
plt.xlabel('Men Employment in 2023')
plt.ylabel('Women Employment in 2023')
plt.title('Relationship between Men and Women Employment in 2023')
plt.grid(True)
plt.show()

Python Error: 'Men 2023'
  [Single] Query 55: {'ECR': False, 'Pass': False} (7.41s)
  Warning: Large text input (9128 tokens)
Processing batches:   2%|▏         | 28/1536 [12:38<4:17:55, 10.26s/it]Processing batches:   2%|▏         | 29/1536 [12:44<3:46:04,  9.00s/it]Processing batches:   2%|▏         | 30/1536 [12:50<3:22:42,  8.08s/it]Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/data/pan/4xin/datasets/RealHiTBench/tables/employment-table09.xlsx')
data_2023 = df[df['Occupation'].isin(['Management occupations', 'Business and financial operations occupations', 'Management, professional, and related occupations'])]
data_2023 = data_2023.iloc[:, 2:4]  # Selecting 2023 data for total and men
data_2023 = data_2023.sum(axis=1)  # Summing up total and men for 2023
labels = data_2023.index
sizes = data_2023.values
plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140)
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
plt.title('Proportion of Total Employment in 2023')
plt.show()

OUTPUT VALUE: [0.69, 0.22, 0.09]

  [Single] Query 56: {'ECR': True, 'Pass': False} (10.69s)
Checkpoint saved: 56 queries processed

============================================================
Batch 29/1536: Processing 2 queries
============================================================
Predictions:  ['24153 24274', '119454 26981']
Answer:  ['24165', '134056 26981']
Predictions:  ['24153 24274']
Answer:  ['24165']
  [Batch] Query 57: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.91s avg)
Predictions:  ['119454 26981']
Answer:  ['134056 26981']
  [Batch] Query 58: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (2.91s avg)
Checkpoint saved: 58 queries processed

============================================================
Batch 30/1536: Processing 2 queries
============================================================
Predictions:  ['4945 1135', '1200 536']
Answer:  ['3810', 'parttime workers']
Predictions:  ['4945 1135']
Answer:  ['3810']
  [Batch] Query 59: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.84s avg)
Predictions:  ['1200 536']
Answer:  ['parttime workers']
  [Batch] Query 60: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.84s avg)
Checkpoint saved: 60 queries processed

============================================================
Batch 31/1536: Processing 2 queries
============================================================
  Warning: Large text input (20500 tokens)
  [Single] Query 61: {'GPT_EVAL': 'N/A (no eval_api_key)'} (2.79s)
  Warning: Large text input (20512 tokens)
Processing batches:   2%|▏         | 31/1536 [13:10<4:51:10, 11.61s/it]Processing batches:   2%|▏         | 32/1536 [13:13<3:48:24,  9.11s/it]Processing batches:   2%|▏         | 33/1536 [13:17<3:05:44,  7.41s/it]Processing batches:   2%|▏         | 34/1536 [13:20<2:38:07,  6.32s/it]Processing batches:   2%|▏         | 35/1536 [13:23<2:13:22,  5.33s/it]  [Single] Query 62: {'GPT_EVAL': 'N/A (no eval_api_key)'} (17.06s)
Checkpoint saved: 62 queries processed

============================================================
Batch 32/1536: Processing 2 queries
============================================================
Predictions:  ['5243', 'white black']
Answer:  ['5243', 'white']
Predictions:  ['5243']
Answer:  ['5243']
  [Batch] Query 63: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.52s avg)
Predictions:  ['white black']
Answer:  ['white']
  [Batch] Query 64: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (1.52s avg)
Checkpoint saved: 64 queries processed

============================================================
Batch 33/1536: Processing 2 queries
============================================================
Predictions:  ['17', 'increasing trend']
Answer:  ['17', 'stabilize']
Predictions:  ['17']
Answer:  ['17']
  [Batch] Query 65: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.61s avg)
Predictions:  ['increasing trend']
Answer:  ['stabilize']
  [Batch] Query 66: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.61s avg)
Checkpoint saved: 66 queries processed

============================================================
Batch 34/1536: Processing 2 queries
============================================================
Predictions:  ['84203 74089', '17071 13271']
Answer:  ['79146', '3800']
Predictions:  ['84203 74089']
Answer:  ['79146']
  [Batch] Query 67: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.76s avg)
Predictions:  ['17071 13271']
Answer:  ['3800']
  [Batch] Query 68: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.76s avg)
Checkpoint saved: 68 queries processed

============================================================
Batch 35/1536: Processing 2 queries
============================================================
Predictions:  ['7414', 'mexican puerto rican cuban']
Answer:  ['7414', 'mexican puerto rican cuban']
Predictions:  ['7414']
Answer:  ['7414']
  [Batch] Query 69: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.40s avg)
Predictions:  ['mexican puerto rican cuban']
Answer:  ['mexican puerto rican cuban']
  [Batch] Query 70: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (1.40s avg)
Checkpoint saved: 70 queries processed

============================================================
Batch 36/1536: Processing 2 queries
============================================================
  Warning: Large text input (9890 tokens)
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/data/pan/4xin/datasets/RealHiTBench/tables/employment-table14.xlsx')
data = df[df['Category'].isin(['Men', 'Women'])]
data = data[['Category', 'Total(1)', '2022', '2023']]
data = data.set_index('Category')
data = data[['2022', '2023']]
data.plot(kind='bar', figsize=(10, 6))
plt.title('Total Employment Numbers for Men and Women among Hispanic or Latino Workers')
plt.xlabel('Category')
plt.ylabel('Number of Workers')
plt.xticks(rotation=0)
plt.legend(title='Year')
plt.tight_layout()
plt.show()

Python Error: "['Total(1)', '2022', '2023'] not in index"
  [Single] Query 71: {'ECR': False, 'Pass': False} (7.83s)
  Warning: Large text input (9896 tokens)
invalid visualization_answer: import pandas as pd 
 import matplotlib.pyplot as plt 
 df = pd.read_excel("/data/pan/4xin/datasets/RealHiTBench/tables/employment-table14.xlsx")
 data = df[df['Category'].isin(['Management, professional, and related occupations'])]
 data = data[['Category', 'Men', 'Women', '2022', '2023']]
 data = data[data['Category'] == 'Management, professional, and related occupations']
 data = data[['2022', '2023', 'Men', 'Women']]
 data = data.set_index('2022').T
 data.columns = ['Men', 'Women']
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(str)
 data = data.set_index('index')
 data = data.reset_index()
 data['index'] = data['index'].astype(int)
Processing batches:   2%|▏         | 36/1536 [16:46<26:52:37, 64.51s/it]Processing batches:   2%|▏         | 37/1536 [16:53<19:38:34, 47.17s/it]
Code: 

Python Error: expected an indented block after 'if' statement on line 2 (<string>, line 3)
  [Single] Query 72: {'ECR': False, 'Pass': False} (194.75s)
Checkpoint saved: 72 queries processed

============================================================
Batch 37/1536: Processing 2 queries
============================================================
Predictions:  ['1358', 'wholesale and retail trade']
Answer:  ['2218', 'leisure and hospitality']
Predictions:  ['1358']
Answer:  ['2218']
  [Batch] Query 73: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.25s avg)
Predictions:  ['wholesale and retail trade']
Answer:  ['leisure and hospitality']
  [Batch] Query 74: {'F1': 28.57, 'EM': 0.0, 'ROUGE-L': 28.57, 'SacreBLEU': 15.97} (3.25s avg)
Checkpoint saved: 74 queries processed

============================================================
Batch 38/1536: Processing 2 queries
============================================================
Predictions:  ['no']
Answer:  ['yes']
Predictions:  ['no']
Answer:  ['yes']
  [Batch] Query 75: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.08s avg)
  Warning: Large text input (22868 tokens)
Processing batches:   2%|▏         | 38/1536 [17:10<15:55:14, 38.26s/it]Processing batches:   3%|▎         | 39/1536 [17:16<11:55:14, 28.67s/it]Processing batches:   3%|▎         | 40/1536 [17:21<8:53:07, 21.38s/it]   [Single] Query 76: {'GPT_EVAL': 'N/A (no eval_api_key)'} (14.26s)
Checkpoint saved: 76 queries processed

============================================================
Batch 39/1536: Processing 2 queries
============================================================
Predictions:  ['weak positive correlation 05', '75 10']
Answer:  ['strong positive correlation 10', '65']
Predictions:  ['weak positive correlation 05']
Answer:  ['strong positive correlation 10']
  [Batch] Query 77: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 31.95} (3.02s avg)
Predictions:  ['75 10']
Answer:  ['65']
  [Batch] Query 78: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.02s avg)
Checkpoint saved: 78 queries processed

============================================================
Batch 40/1536: Processing 2 queries
============================================================
Predictions:  ['352064231163111', '128154 21538']
Answer:  ['35', '128154 21538']
Predictions:  ['352064231163111']
Answer:  ['35']
  [Batch] Query 79: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.07s avg)
Predictions:  ['128154 21538']
Answer:  ['128154 21538']
  [Batch] Query 80: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (2.07s avg)
Checkpoint saved: 80 queries processed

============================================================
Batch 41/1536: Processing 2 queries
============================================================
  Warning: Large text input (9707 tokens)
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel("/data/pan/4xin/datasets/RealHiTBench/tables/employment-table16.xlsx")
# Extract relevant data for non-agricultural industries
non_agricultural = df[df['Age and sex'].isin(['Total, 16 years and over', '16 to 19 years', '16 to 17 years', '18 to 19 years', '20 to 24 years', '25 to 34 years', '35 to 44 years', '45 to 54 years', '55 to 64 years', '65 years and over', 'Men, 16 years and over', 'Women, 16 years and over'])]
# Extract wage and salary workers and self-employed workers from non-agricultural industries
wage_salary_workers = non_agricultural.iloc[:, 6].values
self_employed_workers = non_agricultural.iloc[:, 11].values
# Create scatter plot
plt.scatter(wage_salary_workers, self_employed_workers)
plt.xlabel('Wage and Salary Workers (Non-agricultural industries)')
plt.ylabel('Self-employed Workers (Non-agricultural industries)')
plt.title('Relationship between Wage and Salary Workers and Self-employed Workers in Non-agricultural Industries')
plt.show()

OUTPUT VALUE: [[9030.0, 95.0, 35.0, 60.0, 318.0, 1427.0, 1973.0, 2078.0, 1818.0, 1321.0, 5355.0, 56.0, 21.0, 35.0, 190.0, 852.0, 1135.0, 1229.0, 1076.0, 816.0, 3675.0, 39.0, 14.0, 25.0, 128.0, 574.0, 839.0, 849.0, 742.0, 504.0]]

  [Single] Query 81: {'ECR': True, 'Pass': False} (13.80s)
  Warning: Large text input (9703 tokens)
Processing batches:   3%|▎         | 41/1536 [17:49<9:40:45, 23.31s/it]Processing batches:   3%|▎         | 42/1536 [17:53<7:21:15, 17.72s/it]Processing batches:   3%|▎         | 43/1536 [17:58<5:44:30, 13.85s/it]Code: import pandas as pd
import matplotlib.pyplot as plt

# Load the data from the HTML table
df = pd.read_html("/data/pan/4xin/datasets/RealHiTBench/tables/employment-table16.xlsx")[0]

# Extract the row for "Total, 16 years and over" under "Nonagricultural industries"
row = df[df.iloc[:, 0].str.contains("Total, 16 years and over", na=False)].iloc[0]

# Extract the values for private industry workers, government workers, and unpaid family workers
private_industry = row.iloc[6]  # Total private industry workers
government = row.iloc[10]       # Total government workers
unpaid_family = row.iloc[12]    # Total unpaid family workers

# Create a pie chart
labels = ['Private Industry Workers', 'Government Workers', 'Unpaid Family Workers']
sizes = [private_industry, government, unpaid_family]
colors = ['lightblue', 'lightgreen', 'lightcoral']

plt.figure(figsize=(8, 8))
plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)
plt.title('Proportion of Workers by Sector for Individuals Aged 16 Years and Older')
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
plt.show()

Python Error: 'utf-8' codec can't decode byte 0x87 in position 10: invalid start byte
  [Single] Query 82: {'ECR': False, 'Pass': False} (14.00s)
Checkpoint saved: 82 queries processed

============================================================
Batch 42/1536: Processing 2 queries
============================================================
Predictions:  ['590 11', 'education and health services']
Answer:  ['590', 'education and health services']
Predictions:  ['590 11']
Answer:  ['590']
  [Batch] Query 83: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (2.22s avg)
Predictions:  ['education and health services']
Answer:  ['education and health services']
  [Batch] Query 84: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (2.22s avg)
Checkpoint saved: 84 queries processed

============================================================
Batch 43/1536: Processing 2 queries
============================================================
Predictions:  ['00', 'strong positive correlation 10']
Answer:  ['01', 'strong positive correlation 10']
Predictions:  ['00']
Answer:  ['01']
  [Batch] Query 85: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.28s avg)
Predictions:  ['strong positive correlation 10']
Answer:  ['strong positive correlation 10']
  [Batch] Query 86: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (2.28s avg)
Checkpoint saved: 86 queries processed

============================================================
Batch 44/1536: Processing 2 queries
============================================================
Predictions:  ['161037']
Answer:  ['145345']
Predictions:  ['161037']
Answer:  ['145345']
  [Batch] Query 88: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (7.95s avg)
  Warning: Large text input (15523 tokens)
Processing batches:   3%|▎         | 44/1536 [18:16<6:13:27, 15.02s/it]Processing batches:   3%|▎         | 45/1536 [18:33<6:28:50, 15.65s/it]  [Single] Query 87: {'GPT_EVAL': 'N/A (no eval_api_key)'} (9.68s)
Checkpoint saved: 88 queries processed

============================================================
Batch 45/1536: Processing 2 queries
============================================================
Predictions:  ['child day care services', 'crop production forestry except logging']
Answer:  ['child day care services', 'crop production']
Predictions:  ['child day care services']
Answer:  ['child day care services']
  [Batch] Query 89: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (8.44s avg)
Predictions:  ['crop production forestry except logging']
Answer:  ['crop production']
  [Batch] Query 90: {'F1': 57.14, 'EM': 0.0, 'ROUGE-L': 57.14, 'SacreBLEU': 21.36} (8.44s avg)
Checkpoint saved: 90 queries processed

============================================================
Batch 46/1536: Processing 2 queries
============================================================
Predictions:  ['2264 590']
Answer:  ['2264 590']
Predictions:  ['2264 590']
Answer:  ['2264 590']
  [Batch] Query 92: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (5.00s avg)
  Warning: Large text input (46486 tokens)
Processing batches:   3%|▎         | 46/1536 [18:56<7:21:39, 17.79s/it]Processing batches:   3%|▎         | 47/1536 [19:06<6:25:53, 15.55s/it]Code: import pandas as pd
import matplotlib.pyplot as plt

# Load the data from the HTML table
df = pd.read_html("/data/pan/4xin/datasets/RealHiTBench/tables/employment-table19.xlsx", header=0)[0]

# Extract the industry names and total employed values
industries = df[df['Industry'] != 'Industry']['Industry']
total_employed = df[df['Industry'] != 'Industry']['Total<br />employed'].astype(float)

# Create a line chart
plt.figure(figsize=(14, 7))
plt.plot(industries, total_employed, marker='o', linestyle='-', color='blue')
plt.title('Total Number of Employed Individuals Across Different Industries')
plt.xlabel('Industry')
plt.ylabel('Total Employed')
plt.xticks(rotation=90)
plt.grid(True)
plt.tight_layout()
plt.show()

Python Error: 'utf-8' codec can't decode byte 0x87 in position 10: invalid start byte
  [Single] Query 91: {'ECR': False, 'Pass': False} (17.66s)
Checkpoint saved: 92 queries processed

============================================================
Batch 47/1536: Processing 2 queries
============================================================
Predictions:  ['construction manufacturing agriculture', '220 220']
Answer:  ['manufacturing construction agriculture', '265']
Predictions:  ['construction manufacturing agriculture']
Answer:  ['manufacturing construction agriculture']
  [Batch] Query 93: {'F1': 100.0, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (5.05s avg)
Predictions:  ['220 220']
Answer:  ['265']
  [Batch] Query 94: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (5.05s avg)
Checkpoint saved: 94 queries processed

============================================================
Batch 48/1536: Processing 2 queries
============================================================
Predictions:  ['13067 wholesale and retail trade']
Answer:  ['15825 leisure and hospitality']
Predictions:  ['13067 wholesale and retail trade']
Answer:  ['15825 leisure and hospitality']
  [Batch] Query 96: {'F1': 22.22, 'EM': 0.0, 'ROUGE-L': 22.22, 'SacreBLEU': 10.68} (5.19s avg)
  Warning: Large text input (31122 tokens)
Processing batches:   3%|▎         | 48/1536 [19:26<6:54:45, 16.72s/it]Processing batches:   3%|▎         | 49/1536 [19:28<5:07:24, 12.40s/it]Processing batches:   3%|▎         | 50/1536 [19:41<5:12:18, 12.61s/it]Processing batches:   3%|▎         | 51/1536 [19:43<3:52:51,  9.41s/it]Processing batches:   3%|▎         | 52/1536 [19:45<2:57:04,  7.16s/it]Processing batches:   3%|▎         | 53/1536 [19:53<3:02:15,  7.37s/it]Processing batches:   4%|▎         | 54/1536 [19:56<2:28:36,  6.02s/it]Processing batches:   4%|▎         | 55/1536 [20:11<3:36:16,  8.76s/it]Processing batches:   4%|▎         | 56/1536 [20:15<3:00:45,  7.33s/it]  [Single] Query 95: {'GPT_EVAL': 'N/A (no eval_api_key)'} (14.15s)
Checkpoint saved: 96 queries processed

============================================================
Batch 49/1536: Processing 2 queries
============================================================
Predictions:  ['24492 24062', '377102']
Answer:  ['24492 24062', '377102']
Predictions:  ['24492 24062']
Answer:  ['24492 24062']
  [Batch] Query 97: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.04s avg)
Predictions:  ['377102']
Answer:  ['377102']
  [Batch] Query 98: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.04s avg)
Checkpoint saved: 98 queries processed

============================================================
Batch 50/1536: Processing 2 queries
============================================================
Predictions:  ['economic reasons noneconomic reasons']
Answer:  ['4']
Predictions:  ['economic reasons noneconomic reasons']
Answer:  ['4']
  [Batch] Query 99: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.05s avg)
  [Single] Query 100: {'GPT_EVAL': 'N/A (no eval_api_key)'} (11.92s)
Checkpoint saved: 100 queries processed

============================================================
Batch 51/1536: Processing 2 queries
============================================================
Predictions:  ['48828', '33892']
Answer:  ['48828', '33695']
Predictions:  ['48828']
Answer:  ['48828']
  [Batch] Query 101: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (0.85s avg)
Predictions:  ['33892']
Answer:  ['33695']
  [Batch] Query 102: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (0.85s avg)
Checkpoint saved: 102 queries processed

============================================================
Batch 52/1536: Processing 2 queries
============================================================
Predictions:  ['134', '35 hours and over']
Answer:  ['134', '35 hours and over']
Predictions:  ['134']
Answer:  ['134']
  [Batch] Query 103: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (0.83s avg)
Predictions:  ['35 hours and over']
Answer:  ['35 hours and over']
  [Batch] Query 104: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (0.83s avg)
Checkpoint saved: 104 queries processed

============================================================
Batch 53/1536: Processing 2 queries
============================================================
Predictions:  ['14880 10054']
Answer:  ['4826']
Predictions:  ['14880 10054']
Answer:  ['4826']
  [Batch] Query 106: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.45s avg)
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/data/pan/4xin/datasets/RealHiTBench/tables/employment-table21.xlsx')
agriculture = df[df['Hours of work'].str.contains('Agriculture')]['Total, persons at work'].values
non_agricultural = df[df['Hours of work'].str.contains('Nonagricultural')]['Total, persons at work'].values
plt.scatter(agriculture, non_agricultural)
plt.xlabel('Agriculture and related industries')
plt.ylabel('Nonagricultural industries')
plt.title('Relationship between persons working in agriculture and non-agricultural industries')
plt.show()

Python Error: Cannot mask with non-boolean array containing NA / NaN values
  [Single] Query 105: {'ECR': False, 'Pass': False} (6.30s)
Checkpoint saved: 106 queries processed

============================================================
Batch 54/1536: Processing 2 queries
============================================================
Predictions:  ['total nonagricultural industries wage and salary workers1 education and health services', 'wholesale and retail trade education and health services leisure and hospitality']
Answer:  ['7', 'mining quarrying and oil and gas extraction unpaid family workers information']
Predictions:  ['total nonagricultural industries wage and salary workers1 education and health services']
Answer:  ['7']
  [Batch] Query 107: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.30s avg)
Predictions:  ['wholesale and retail trade education and health services leisure and hospitality']
Answer:  ['mining quarrying and oil and gas extraction unpaid family workers information']
  [Batch] Query 108: {'F1': 18.18, 'EM': 0.0, 'ROUGE-L': 18.18, 'SacreBLEU': 4.46} (1.30s avg)
Checkpoint saved: 108 queries processed

============================================================
Batch 55/1536: Processing 2 queries
============================================================
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel("/data/pan/4xin/datasets/RealHiTBench/tables/employment-table23.xlsx")
industry_data = df[df['Industry and class of worker'].isin(['Manufacturing', 'Construction'])]
values = industry_data['Total at work'].values
labels = industry_data['Industry and class of worker'].values
plt.pie(values, labels=labels, autopct='%1.1f%%', startangle=140)
plt.title('Proportion in Manufacturing and Construction Industries in 2023')
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
plt.show()

Python Error: 'Total at work'
  [Single] Query 109: {'ECR': False, 'Pass': False} (6.75s)
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/data/pan/4xin/datasets/RealHiTBench/tables/employment-table23.xlsx')
industry = 'Manufacturing'
subset = df[df['Industry and class of worker'] == industry]
full_time = subset.iloc[0]['Average hours']['Persons who usually work full time']
part_time = subset.iloc[0]['Average hours']['Persons who usually work part time']
categories = ['Full Time', 'Part Time']
values = [full_time, part_time]
plt.figure(figsize=(8, 6))
plt.plot(categories, values, marker='o', linestyle='-', color='blue')
plt.title(f'Average Hours Worked by {industry} Workers')
plt.xlabel('Work Category')
plt.ylabel('Average Hours')
plt.xticks(rotation=45)
plt.grid(True)
plt.tight_layout()
plt.show()

Python Error: 'Average hours'
  [Single] Query 110: {'ECR': False, 'Pass': False} (8.41s)
Checkpoint saved: 110 queries processed

============================================================
Batch 56/1536: Processing 2 queries
============================================================
Predictions:  ['married spouse present1 418', '34282 118705']
Answer:  ['men 16 years and over married spouse present1 433', '34282 118705']
Predictions:  ['married spouse present1 418']
Answer:  ['men 16 years and over married spouse present1 433']
  [Batch] Query 111: {'F1': 46.15, 'EM': 0.0, 'ROUGE-L': 46.15, 'SacreBLEU': 17.04} (1.87s avg)
Predictions:  ['34282 118705']
Answer:  ['34282 118705']
  [Batch] Query 112: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.87s avg)
Checkpoint saved: 112 queries processed

============================================================
Batch 57/1536: Processing 2 queries
============================================================
Predictions:  ['406 376']
Answer:  ['406 376']
Predictions:  ['406 376']
Answer:  ['406 376']
  [Batch] Query 113: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (2.03s avg)
  Warning: Large text input (11594 tokens)
Processing batches:   4%|▎         | 57/1536 [20:25<3:19:45,  8.10s/it]Processing batches:   4%|▍         | 58/1536 [20:28<2:48:02,  6.82s/it]Processing batches:   4%|▍         | 59/1536 [20:34<2:38:11,  6.43s/it]Processing batches:   4%|▍         | 60/1536 [20:37<2:16:12,  5.54s/it]Processing batches:   4%|▍         | 61/1536 [20:41<1:58:44,  4.83s/it]Processing batches:   4%|▍         | 62/1536 [20:44<1:48:03,  4.40s/it]Processing batches:   4%|▍         | 63/1536 [20:47<1:34:46,  3.86s/it]  [Single] Query 114: {'GPT_EVAL': 'N/A (no eval_api_key)'} (7.77s)
Checkpoint saved: 114 queries processed

============================================================
Batch 58/1536: Processing 2 queries
============================================================
Predictions:  ['152987', '25193 37780']
Answer:  ['152987', '12587']
Predictions:  ['152987']
Answer:  ['152987']
  [Batch] Query 115: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.79s avg)
Predictions:  ['25193 37780']
Answer:  ['12587']
  [Batch] Query 116: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.79s avg)
Checkpoint saved: 116 queries processed

============================================================
Batch 59/1536: Processing 2 queries
============================================================
Predictions:  ['30091', 'management business and financial operations occupations service occupations sales and office occupations sales and related occupations office and administrative support occupations installation maintenance and repair occupations production occupations transportation and material moving occupations']
Answer:  ['30091', '6']
Predictions:  ['30091']
Answer:  ['30091']
  [Batch] Query 117: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (2.63s avg)
Predictions:  ['management business and financial operations occupations service occupations sales and office occupations sales and related occupations office and administrative support occupations installation maintenance and repair occupations production occupations transportation and material moving occupations']
Answer:  ['6']
  [Batch] Query 118: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.63s avg)
Checkpoint saved: 118 queries processed

============================================================
Batch 60/1536: Processing 2 queries
============================================================
Predictions:  ['41 35', '3218 2778']
Answer:  ['41 35', 'men']
Predictions:  ['41 35']
Answer:  ['41 35']
  [Batch] Query 119: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.61s avg)
Predictions:  ['3218 2778']
Answer:  ['men']
  [Batch] Query 120: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.61s avg)
Checkpoint saved: 120 queries processed

============================================================
Batch 61/1536: Processing 2 queries
============================================================
Predictions:  ['135', 'increase 65']
Answer:  ['135', 'increasing trend']
Predictions:  ['135']
Answer:  ['135']
  [Batch] Query 121: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.47s avg)
Predictions:  ['increase 65']
Answer:  ['increasing trend']
  [Batch] Query 122: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.47s avg)
Checkpoint saved: 122 queries processed

============================================================
Batch 62/1536: Processing 2 queries
============================================================
Predictions:  ['strong positive correlation 10', '418 472']
Answer:  ['strong positive correlation 10', '418 472']
Predictions:  ['strong positive correlation 10']
Answer:  ['strong positive correlation 10']
  [Batch] Query 123: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (1.58s avg)
Predictions:  ['418 472']
Answer:  ['418 472']
  [Batch] Query 124: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.58s avg)
Checkpoint saved: 124 queries processed

============================================================
Batch 63/1536: Processing 2 queries
============================================================
Predictions:  ['31', 'men 05']
Answer:  ['31', 'men 01']
Predictions:  ['31']
Answer:  ['31']
  [Batch] Query 125: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.18s avg)
Predictions:  ['men 05']
Answer:  ['men 01']
  [Batch] Query 126: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (1.18s avg)
Checkpoint saved: 126 queries processed

============================================================
Batch 64/1536: Processing 2 queries
============================================================
Predictions:  ['20 20']
Answer:  ['20']
Predictions:  ['20 20']
Answer:  ['20']
  [Batch] Query 127: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (1.43s avg)
  Warning: Large text input (8130 tokens)
Processing batches:   4%|▍         | 64/1536 [21:02<3:01:20,  7.39s/it]Code: import pandas as pd
import matplotlib.pyplot as plt

# Load the data from the HTML table
df = pd.read_html('/data/pan/4xin/datasets/RealHiTBench/tables/employment-table27.xlsx', header=0)[0]

# Extract relevant columns for men and women unemployment rates in 2023
men_2023 = df[df['Occupation'].notna()]['Unemployment rates - Men - 2023'].dropna()
women_2023 = df[df['Occupation'].notna()]['Unemployment rates - Women - 2023'].dropna()

# Ensure the data is aligned (same occupations)
common_occupations = men_2023.index.intersection(women_2023.index)
men_2023 = men_2023.loc[common_occupations]
women_2023 = women_2023.loc[common_occupations]

# Create scatter plot
plt.figure(figsize=(10, 6))
plt.scatter(men_2023, women_2023, alpha=0.7)
plt.title('Correlation between Unemployment Rates for Men and Women in 2023')
plt.xlabel('Unemployment Rate for Men (2023)')
plt.ylabel('Unemployment Rate for Women (2023)')
plt.grid(True)
plt.show()

Python Error: 'utf-8' codec can't decode byte 0x87 in position 10: invalid start byte
  [Single] Query 128: {'ECR': False, 'Pass': False} (14.08s)
Checkpoint saved: 128 queries processed

============================================================
Batch 65/1536: Processing 2 queries
============================================================
Predictions:  ['142']
Answer:  ['142']
Predictions:  ['142']
Answer:  ['142']
  [Batch] Query 129: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.50s avg)
  Warning: Large text input (9134 tokens)
Processing batches:   4%|▍         | 65/1536 [21:08<2:52:58,  7.06s/it]Processing batches:   4%|▍         | 66/1536 [21:12<2:25:21,  5.93s/it]Processing batches:   4%|▍         | 67/1536 [21:15<2:03:14,  5.03s/it]Processing batches:   4%|▍         | 68/1536 [21:19<1:55:57,  4.74s/it]  [Single] Query 130: {'GPT_EVAL': 'N/A (no eval_api_key)'} (4.65s)
Checkpoint saved: 130 queries processed

============================================================
Batch 66/1536: Processing 2 queries
============================================================
Predictions:  ['shelter fuels and utilities household furnishings and operations', '1861 06']
Answer:  ['shelter household furnishings and operations fuels and utilities', '1857']
Predictions:  ['shelter fuels and utilities household furnishings and operations']
Answer:  ['shelter household furnishings and operations fuels and utilities']
  [Batch] Query 131: {'F1': 100.0, 'EM': 0.0, 'ROUGE-L': 62.5, 'SacreBLEU': 51.7} (1.54s avg)
Predictions:  ['1861 06']
Answer:  ['1857']
  [Batch] Query 132: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.54s avg)
Checkpoint saved: 132 queries processed

============================================================
Batch 67/1536: Processing 2 queries
============================================================
Predictions:  ['142', 'housing food and beverages']
Answer:  ['142', 'housing']
Predictions:  ['142']
Answer:  ['142']
  [Batch] Query 133: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.34s avg)
Predictions:  ['housing food and beverages']
Answer:  ['housing']
  [Batch] Query 134: {'F1': 40.0, 'EM': 0.0, 'ROUGE-L': 40.0, 'SacreBLEU': 15.97} (1.34s avg)
Checkpoint saved: 134 queries processed

============================================================
Batch 68/1536: Processing 2 queries
============================================================
Predictions:  ['no', 'cereals and bakery products']
Answer:  ['no', 'cereals and bakery products']
Predictions:  ['no']
Answer:  ['no']
  [Batch] Query 135: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.90s avg)
Predictions:  ['cereals and bakery products']
Answer:  ['cereals and bakery products']
  [Batch] Query 136: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (1.90s avg)
Checkpoint saved: 136 queries processed

============================================================
Batch 69/1536: Processing 2 queries
============================================================
Predictions:  ['135 1000']
Answer:  ['135']
Predictions:  ['135 1000']
Answer:  ['135']
  [Batch] Query 137: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (2.48s avg)
  Warning: Large text input (13356 tokens)
Processing batches:   4%|▍         | 69/1536 [21:29<2:35:19,  6.35s/it]Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/data/pan/4xin/datasets/RealHiTBench/tables/economy-table137.xlsx', sheet_name=0)
data = df[df['Expenditure category'] == 'All items']
x = data.iloc[:, 3:6].columns.tolist()
y = data.iloc[:, 3:6].values[0].tolist()
plt.plot(x, y, marker='o')
plt.title('Trend in Unadjusted Indexes for All Items')
plt.xlabel('Time')
plt.ylabel('Unadjusted Indexes')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

OUTPUT VALUE: [[289.109, 301.836, 303.363]]

  [Single] Query 138: {'ECR': True, 'Pass': True} (7.51s)
Checkpoint saved: 138 queries processed

============================================================
Batch 70/1536: Processing 2 queries
============================================================
Predictions:  ['electricity utility piped gas service']
Answer:  ['electricity']
Predictions:  ['electricity utility piped gas service']
Answer:  ['electricity']
  [Batch] Query 140: {'F1': 33.33, 'EM': 0.0, 'ROUGE-L': 33.33, 'SacreBLEU': 10.68} (2.13s avg)
  Warning: Large text input (13369 tokens)
Processing batches:   5%|▍         | 70/1536 [21:49<4:19:22, 10.62s/it]Processing batches:   5%|▍         | 71/1536 [21:53<3:31:00,  8.64s/it]Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/data/pan/4xin/datasets/RealHiTBench/tables/economy-table137.xlsx', sheet_name=0)
df = df[df['Expenditure category'].notna()]
df = df[df['Unadjusted percent change (Apr. 2022-April 2023)'].notna()]
df = df[df['Unadjusted percent change (Mar. 2023-April 2023)'].notna()]
df = df[df['Indent Level'] == 1]
df = df[['Expenditure category', 'Unadjusted percent change (Apr. 2022-April 2023)', 'Unadjusted percent change (Mar. 2023-April 2023)']]
df = df.rename(columns={'Unadjusted percent change (Apr. 2022-April 2023)': 'Apr_2022_Apr_2023', 'Unadjusted percent change (Mar. 2023-April 2023)': 'Mar_2023_Apr_2023'})
plt.scatter(df['Apr_2022_Apr_2023'], df['Mar_2023_Apr_2023'])
plt.xlabel('April 2022 - April 2023')
plt.ylabel('March 2023 - April 2023')
plt.title('Relationship between Changes over April 2022-April 2023 and March 2023-April 2023')
plt.grid(True)
plt.show()

Python Error: 'Unadjusted percent change (Apr. 2022-April 2023)'
  [Single] Query 139: {'ECR': False, 'Pass': False} (18.30s)
Checkpoint saved: 140 queries processed

============================================================
Batch 71/1536: Processing 2 queries
============================================================
Predictions:  ['motor vehicle insurance', 'tobacco and smoking products']
Answer:  ['airline fares', 'airline fares']
Predictions:  ['motor vehicle insurance']
Answer:  ['airline fares']
  [Batch] Query 141: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.75s avg)
Predictions:  ['tobacco and smoking products']
Answer:  ['airline fares']
  [Batch] Query 142: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.75s avg)
Checkpoint saved: 142 queries processed

============================================================
Batch 72/1536: Processing 2 queries
============================================================
  Warning: Large text input (13260 tokens)
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/data/pan/4xin/datasets/RealHiTBench/tables/economy-table136.xlsx', sheet_name=0)
food_at_home = df[df['Expenditure category'] == 'Food at home']
subcategories = food_at_home['Expenditure category'].tolist()
importance = food_at_home['Relative importance Sep. 2024'].tolist()
plt.bar(subcategories, importance)
plt.xlabel('Expenditure Category')
plt.ylabel('Relative Importance (Sep. 2024)')
plt.title('Relative Importance of Expenditure Categories under Food at Home (Sep. 2024)')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

Python Error: 'Relative importance Sep. 2024'
  [Single] Query 143: {'ECR': False, 'Pass': False} (8.38s)
  Warning: Large text input (13259 tokens)
Processing batches:   5%|▍         | 72/1536 [22:10<4:31:05, 11.11s/it]Processing batches:   5%|▍         | 73/1536 [22:24<4:51:44, 11.96s/it]Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel("/data/pan/4xin/datasets/RealHiTBench/tables/economy-table136.xlsx")
food_at_home = df[df["Expenditure category"] == "Food at home"]
data = food_at_home.iloc[0:11, 2].dropna().reset_index(drop=True)
labels = food_at_home.iloc[0:11, 1].dropna().reset_index(drop=True)
plt.pie(data, labels=labels, autopct='%1.1f%%', startangle=90)
plt.axis('equal')
plt.title("Proportion of Different Expenditure Categories under 'Food at home' as of September 2024")
plt.show()

OUTPUT VALUE: [1.0]

  [Single] Query 144: {'ECR': True, 'Pass': False} (8.48s)
Checkpoint saved: 144 queries processed

============================================================
Batch 73/1536: Processing 2 queries
============================================================
Predictions:  ['32 107', 'logging workers']
Answer:  ['139', 'logging workers']
Predictions:  ['32 107']
Answer:  ['139']
  [Batch] Query 145: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (6.86s avg)
Predictions:  ['logging workers']
Answer:  ['logging workers']
  [Batch] Query 146: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (6.86s avg)
Checkpoint saved: 146 queries processed

============================================================
Batch 74/1536: Processing 2 queries
============================================================
Predictions:  ['no']
Answer:  ['no']
Predictions:  ['no']
Answer:  ['no']
  [Batch] Query 147: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (6.15s avg)
  Warning: Large text input (39277 tokens)
Processing batches:   5%|▍         | 74/1536 [22:43<5:40:25, 13.97s/it]Processing batches:   5%|▍         | 75/1536 [22:57<5:39:25, 13.94s/it]Processing batches:   5%|▍         | 76/1536 [23:10<5:36:22, 13.82s/it]Processing batches:   5%|▌         | 77/1536 [23:25<5:40:41, 14.01s/it]Processing batches:   5%|▌         | 78/1536 [23:27<4:17:07, 10.58s/it]Processing batches:   5%|▌         | 79/1536 [23:35<3:56:47,  9.75s/it]Processing batches:   5%|▌         | 80/1536 [23:47<4:09:10, 10.27s/it]Processing batches:   5%|▌         | 81/1536 [23:52<3:32:59,  8.78s/it]Processing batches:   5%|▌         | 82/1536 [23:55<2:52:07,  7.10s/it]  [Single] Query 148: {'GPT_EVAL': 'N/A (no eval_api_key)'} (12.38s)
Checkpoint saved: 148 queries processed

============================================================
Batch 75/1536: Processing 2 queries
============================================================
Predictions:  ['16400', '135 368']
Answer:  ['16400', '1025']
Predictions:  ['16400']
Answer:  ['16400']
  [Batch] Query 149: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (6.81s avg)
Predictions:  ['135 368']
Answer:  ['1025']
  [Batch] Query 150: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (6.81s avg)
Checkpoint saved: 150 queries processed

============================================================
Batch 76/1536: Processing 2 queries
============================================================
Predictions:  ['texas 497', 'kentucky illinois']
Answer:  ['california 639', 'kentucky']
Predictions:  ['texas 497']
Answer:  ['california 639']
  [Batch] Query 151: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (6.66s avg)
Predictions:  ['kentucky illinois']
Answer:  ['kentucky']
  [Batch] Query 152: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (6.66s avg)
Checkpoint saved: 152 queries processed

============================================================
Batch 77/1536: Processing 2 queries
============================================================
Predictions:  ['strong negative correlation 08', '52880 decreasing trend']
Answer:  ['weak positive correlation 01', '5557']
Predictions:  ['strong negative correlation 08']
Answer:  ['weak positive correlation 01']
  [Batch] Query 153: {'F1': 25.0, 'EM': 0.0, 'ROUGE-L': 25.0, 'SacreBLEU': 15.97} (7.10s avg)
Predictions:  ['52880 decreasing trend']
Answer:  ['5557']
  [Batch] Query 154: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (7.10s avg)
Checkpoint saved: 154 queries processed

============================================================
Batch 78/1536: Processing 2 queries
============================================================
Predictions:  ['1217 558', '336 336']
Answer:  ['1217', '304']
Predictions:  ['1217 558']
Answer:  ['1217']
  [Batch] Query 155: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (1.17s avg)
Predictions:  ['336 336']
Answer:  ['304']
  [Batch] Query 156: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.17s avg)
Checkpoint saved: 156 queries processed

============================================================
Batch 79/1536: Processing 2 queries
============================================================
Predictions:  ['falls slips trips exposure to harmful substances or environments fires and explosions']
Answer:  ['falls slips trips exposure to harmful substances or environments fires and explosions']
Predictions:  ['falls slips trips exposure to harmful substances or environments fires and explosions']
Answer:  ['falls slips trips exposure to harmful substances or environments fires and explosions']
  [Batch] Query 157: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (1.71s avg)
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel("/data/pan/4xin/datasets/RealHiTBench/tables/injuries-table04.xlsx")
categories = ['Transportation incidents', 'Violence and other injuries by persons or animals', 'Falls, slips, trips', 'Exposure to harmful substances or environments']
values = [2066, 849, 738, 865]
plt.pie(values, labels=categories, autopct='%1.1f%%')
plt.title('Proportion of Total Fatalities')
plt.show()

OUTPUT VALUE: [0.46, 0.19, 0.16, 0.19]

  [Single] Query 158: {'ECR': True, 'Pass': False} (5.98s)
Checkpoint saved: 158 queries processed

============================================================
Batch 80/1536: Processing 2 queries
============================================================
Predictions:  ['couriers and express delivery services private industry 4921']
Answer:  ['couriers and express delivery services private industry 4921']
Predictions:  ['couriers and express delivery services private industry 4921']
Answer:  ['couriers and express delivery services private industry 4921']
  [Batch] Query 160: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (1.93s avg)
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/data/pan/4xin/datasets/RealHiTBench/tables/injuries-table04.xlsx')
wage_salary = df[df['Worker Characteristics'] == 'Wage and salary']
self_employed = df[df['Worker Characteristics'] == 'Self-employed']
categories = ['Transportation incidents', 'Falls, slips, trips']
data = {'Wage and salary': [wage_salary.iloc[0, 2], wage_salary.iloc[0, 4]], 'Self-employed': [self_employed.iloc[0, 2], self_employed.iloc[0, 4]]}
df_plot = pd.DataFrame(data, index=categories)
df_plot.plot(kind='bar', figsize=(10,6))
plt.xlabel('Event Categories')
plt.ylabel('Total Fatalities')
plt.title('Comparison of Total Fatalities by Worker Status')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

Python Error: index 0 is out of bounds for axis 0 with size 0
  [Single] Query 159: {'ECR': False, 'Pass': False} (9.42s)
Checkpoint saved: 160 queries processed

============================================================
Batch 81/1536: Processing 2 queries
============================================================
Predictions:  ['couriers and express delivery services private industry spectator sports private industry light truck and utility vehicle manufacturing private industry', '06']
Answer:  ['3', '23']
Predictions:  ['couriers and express delivery services private industry spectator sports private industry light truck and utility vehicle manufacturing private industry']
Answer:  ['3']
  [Batch] Query 161: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.54s avg)
Predictions:  ['06']
Answer:  ['23']
  [Batch] Query 162: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.54s avg)
Checkpoint saved: 162 queries processed

============================================================
Batch 82/1536: Processing 2 queries
============================================================
Predictions:  ['performing arts companies private industry nursing and residential care facilities state government', 'nursing and residential care facilities state government scheduled passenger air transportation private industry']
Answer:  ['performing arts companies private industry nursing and residential care facilities state government', 'nursing and residential care facilities state government']
Predictions:  ['performing arts companies private industry nursing and residential care facilities state government']
Answer:  ['performing arts companies private industry nursing and residential care facilities state government']
  [Batch] Query 163: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (1.47s avg)
Predictions:  ['nursing and residential care facilities state government scheduled passenger air transportation private industry']
Answer:  ['nursing and residential care facilities state government']
  [Batch] Query 164: {'F1': 70.0, 'EM': 0.0, 'ROUGE-L': 70.0, 'SacreBLEU': 47.04} (1.47s avg)
Checkpoint saved: 164 queries processed

============================================================
Batch 83/1536: Processing 2 queries
============================================================
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel("/data/pan/4xin/datasets/RealHiTBench/tables/injuries-table07.xlsx")
top_five = df.sort_values(by='Incidence Rate', ascending=False).head(5)
labels = top_five['Industry']
sizes = top_five['Incidence Rate']
plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140)
plt.axis('equal')
plt.title('Proportion of Incidence Rates for Top Five Industries')
plt.show()

Python Error: 'Industry'
  [Single] Query 165: {'ECR': False, 'Pass': False} (5.75s)
Code: Processing batches:   5%|▌         | 83/1536 [24:06<3:21:06,  8.30s/it]Processing batches:   5%|▌         | 84/1536 [24:10<2:45:01,  6.82s/it]import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel("/data/pan/4xin/datasets/RealHiTBench/tables/injuries-table07.xlsx")
filtered_df = df[df['Incidence Rate'] > 4.0]
plt.bar(filtered_df['Industry'], filtered_df['Incidence Rate'])
plt.xlabel('Industry')
plt.ylabel('Incidence Rate')
plt.title('Incidence Rates of Industries (Above 4.0)')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

Python Error: 'Industry'
  [Single] Query 166: {'ECR': False, 'Pass': False} (5.35s)
Checkpoint saved: 166 queries processed

============================================================
Batch 84/1536: Processing 2 queries
============================================================
Predictions:  ['80 62', 'performing arts companies nursing and residential care facilities spectator sports']
Answer:  ['142', 'performing arts companies nursing and residential care facilities spectator sports']
Predictions:  ['80 62']
Answer:  ['142']
  [Batch] Query 167: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.56s avg)
Predictions:  ['performing arts companies nursing and residential care facilities spectator sports']
Answer:  ['performing arts companies nursing and residential care facilities spectator sports']
  [Batch] Query 168: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (1.56s avg)
Checkpoint saved: 168 queries processed

============================================================
Batch 85/1536: Processing 2 queries
============================================================
Predictions:  ['scheduled passenger air transportation private industry']
Answer:  ['nursing care facilities skilled nursing facilities private industry']
Predictions:  ['scheduled passenger air transportation private industry']
Answer:  ['nursing care facilities skilled nursing facilities private industry']
  [Batch] Query 169: {'F1': 28.57, 'EM': 0.0, 'ROUGE-L': 28.57, 'SacreBLEU': 11.63} (1.60s avg)
  Warning: Large text input (9180 tokens)
Processing batches:   6%|▌         | 85/1536 [24:23<3:33:49,  8.84s/it]  [Single] Query 170: {'GPT_EVAL': 'N/A (no eval_api_key)'} (11.84s)
Checkpoint saved: 170 queries processed

============================================================
Batch 86/1536: Processing 2 queries
============================================================
Predictions:  ['agriculture forestry fishing and hunting']
Answer:  ['sports teams and clubs naics 711211']
Predictions:  ['agriculture forestry fishing and hunting']
Answer:  ['sports teams and clubs naics 711211']
  [Batch] Query 172: {'F1': 18.18, 'EM': 0.0, 'ROUGE-L': 18.18, 'SacreBLEU': 8.75} (3.80s avg)
  Warning: Large text input (9197 tokens)
Processing batches:   6%|▌         | 86/1536 [24:36<3:59:07,  9.89s/it]Processing batches:   6%|▌         | 87/1536 [24:44<3:45:11,  9.32s/it]  [Single] Query 171: {'GPT_EVAL': 'N/A (no eval_api_key)'} (8.42s)
Checkpoint saved: 172 queries processed

============================================================
Batch 87/1536: Processing 2 queries
============================================================
Predictions:  ['29 76', 'no']
Answer:  ['30', 'yes']
Predictions:  ['29 76']
Answer:  ['30']
  [Batch] Query 173: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.88s avg)
Predictions:  ['no']
Answer:  ['yes']
  [Batch] Query 174: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.88s avg)
Checkpoint saved: 174 queries processed

============================================================
Batch 88/1536: Processing 2 queries
============================================================
Predictions:  ['50 249 250 999']
Answer:  ['50 249']
Predictions:  ['50 249 250 999']
Answer:  ['50 249']
  [Batch] Query 175: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 31.95} (4.40s avg)
  Warning: Large text input (25096 tokens)
Processing batches:   6%|▌         | 88/1536 [24:58<4:23:54, 10.94s/it]Processing batches:   6%|▌         | 89/1536 [25:03<3:36:05,  8.96s/it]Processing batches:   6%|▌         | 90/1536 [25:07<3:04:39,  7.66s/it]Processing batches:   6%|▌         | 91/1536 [25:15<3:04:39,  7.67s/it]Processing batches:   6%|▌         | 92/1536 [25:24<3:11:53,  7.97s/it]Processing batches:   6%|▌         | 93/1536 [25:32<3:17:34,  8.22s/it]Processing batches:   6%|▌         | 94/1536 [25:48<4:08:27, 10.34s/it]Processing batches:   6%|▌         | 95/1536 [26:06<5:03:57, 12.66s/it]Processing batches:   6%|▋         | 96/1536 [26:17<4:53:59, 12.25s/it]Processing batches:   6%|▋         | 97/1536 [26:21<3:50:33,  9.61s/it]  [Single] Query 176: {'GPT_EVAL': 'N/A (no eval_api_key)'} (10.17s)
Checkpoint saved: 176 queries processed

============================================================
Batch 89/1536: Processing 2 queries
============================================================
Predictions:  ['02', '2020 q3']
Answer:  ['04', '2020 q3']
Predictions:  ['02']
Answer:  ['04']
  [Batch] Query 177: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.05s avg)
Predictions:  ['2020 q3']
Answer:  ['2020 q3']
  [Batch] Query 178: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (2.05s avg)
Checkpoint saved: 178 queries processed

============================================================
Batch 90/1536: Processing 2 queries
============================================================
Predictions:  ['07 01', 'manufacturing']
Answer:  ['15', 'whole economy']
Predictions:  ['07 01']
Answer:  ['15']
  [Batch] Query 179: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.20s avg)
Predictions:  ['manufacturing']
Answer:  ['whole economy']
  [Batch] Query 180: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.20s avg)
Checkpoint saved: 180 queries processed

============================================================
Batch 91/1536: Processing 2 queries
============================================================
Predictions:  ['strong positive correlation 08', '31 28']
Answer:  ['weak positive correlation', '32']
Predictions:  ['strong positive correlation 08']
Answer:  ['weak positive correlation']
  [Batch] Query 181: {'F1': 57.14, 'EM': 0.0, 'ROUGE-L': 57.14, 'SacreBLEU': 31.95} (3.72s avg)
Predictions:  ['31 28']
Answer:  ['32']
  [Batch] Query 182: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.72s avg)
Checkpoint saved: 182 queries processed

============================================================
Batch 92/1536: Processing 2 queries
============================================================
Predictions:  ['999 1003', '976 983 976 974']
Answer:  ['increase', '977']
Predictions:  ['999 1003']
Answer:  ['increase']
  [Batch] Query 183: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.22s avg)
Predictions:  ['976 983 976 974']
Answer:  ['977']
  [Batch] Query 184: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.22s avg)
Checkpoint saved: 184 queries processed

============================================================
Batch 93/1536: Processing 2 queries
============================================================
Predictions:  ['q3', 'strong positive correlation 08']
Answer:  ['q3', 'positive correlation 07']
Predictions:  ['q3']
Answer:  ['q3']
  [Batch] Query 185: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (4.27s avg)
Predictions:  ['strong positive correlation 08']
Answer:  ['positive correlation 07']
  [Batch] Query 186: {'F1': 57.14, 'EM': 0.0, 'ROUGE-L': 57.14, 'SacreBLEU': 31.95} (4.27s avg)
Checkpoint saved: 186 queries processed

============================================================
Batch 94/1536: Processing 2 queries
============================================================
Predictions:  ['81 80', '04 06']
Answer:  ['162', '07']
Predictions:  ['81 80']
Answer:  ['162']
  [Batch] Query 187: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (7.52s avg)
Predictions:  ['04 06']
Answer:  ['07']
  [Batch] Query 188: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (7.52s avg)
Checkpoint saved: 188 queries processed

============================================================
Batch 95/1536: Processing 2 queries
============================================================
Predictions:  ['notemployed fathers 02', '12 02 06 03 05']
Answer:  ['fulltime employed mothers 03', '18']
Predictions:  ['notemployed fathers 02']
Answer:  ['fulltime employed mothers 03']
  [Batch] Query 189: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (8.92s avg)
Predictions:  ['12 02 06 03 05']
Answer:  ['18']
  [Batch] Query 190: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (8.92s avg)
Checkpoint saved: 190 queries processed

============================================================
Batch 96/1536: Processing 2 queries
============================================================
Predictions:  ['not employed', '04']
Answer:  ['not employed', '01']
Predictions:  ['not employed']
Answer:  ['not employed']
  [Batch] Query 191: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (5.53s avg)
Predictions:  ['04']
Answer:  ['01']
  [Batch] Query 192: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (5.53s avg)
Checkpoint saved: 192 queries processed

============================================================
Batch 97/1536: Processing 2 queries
============================================================
Predictions:  ['85 81', '38']
Answer:  ['employed parttime married mothers', '41']
Predictions:  ['85 81']
Answer:  ['employed parttime married mothers']
  [Batch] Query 193: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.61s avg)
Predictions:  ['38']
Answer:  ['41']
  [Batch] Query 194: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.61s avg)
Checkpoint saved: 194 queries processed

============================================================
Batch 98/1536: Processing 2 queries
============================================================
  Warning: Large text input (9650 tokens)
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/data/pan/4xin/datasets/RealHiTBench/tables/activitytime-table02.xlsx')
data = df.loc[df['Activity'] == 'Household activities', ['Activity', 'Employed full time', 'Employed part time', 'Not employed']].set_index('Activity').iloc[0]
labels = data.index
sizes = data.values
plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)
plt.axis('equal')
plt.title('Percentage of Participation in Household Activities for Married Mothers')
plt.show()

Python Error: "['Employed full time', 'Employed part time', 'Not employed'] not in index"
  [Single] Query 195: {'ECR': False, 'Pass': False} (6.69s)
  Warning: Large text input (9649 tokens)
Processing batches:   6%|▋         | 98/1536 [26:34<4:19:50, 10.84s/it]Processing batches:   6%|▋         | 99/1536 [26:57<5:42:59, 14.32s/it]Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/data/pan/4xin/datasets/RealHiTBench/tables/activitytime-table02.xlsx')
data = df[df['Activity'] == 'Household activities']
employment_statuses = ['Employed full time', 'Employed part time', 'Not employed']
hours = data.loc[:, employment_statuses].iloc[0].values
plt.plot(employment_statuses, hours, marker='o')
plt.title('Average Hours Spent on Household Activities for Married Mothers')
plt.xlabel('Employment Status')
plt.ylabel('Average Hours per Day')
plt.grid(True)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

Python Error: "None of [Index(['Employed full time', 'Employed part time', 'Not employed'], dtype='object')] are in the [columns]"
  [Single] Query 196: {'ECR': False, 'Pass': False} (7.02s)
Checkpoint saved: 196 queries processed

============================================================
Batch 99/1536: Processing 2 queries
============================================================
Predictions:  ['29 37', 'caring for and helping household members']
Answer:  ['29 37', 'household activities']
Predictions:  ['29 37']
Answer:  ['29 37']
  [Batch] Query 197: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (11.10s avg)
Predictions:  ['caring for and helping household members']
Answer:  ['household activities']
  [Batch] Query 198: {'F1': 25.0, 'EM': 0.0, 'ROUGE-L': 25.0, 'SacreBLEU': 8.12} (11.10s avg)
Checkpoint saved: 198 queries processed

============================================================
Batch 100/1536: Processing 2 queries
============================================================
Predictions:  ['caring for and helping household children caring for and helping household children']
Answer:  ['reading towith children']
Predictions:  ['caring for and helping household children caring for and helping household children']
Answer:  ['reading towith children']
  [Batch] Query 199: {'F1': 13.33, 'EM': 0.0, 'ROUGE-L': 13.33, 'SacreBLEU': 3.39} (10.60s avg)
  Warning: Large text input (54182 tokens)
Processing batches:   7%|▋         | 100/1536 [27:26<7:30:36, 18.83s/it]Processing batches:   7%|▋         | 101/1536 [27:49<8:00:03, 20.07s/it]Processing batches:   7%|▋         | 102/1536 [28:17<8:56:36, 22.45s/it]  [Single] Query 200: {'GPT_EVAL': 'N/A (no eval_api_key)'} (18.61s)
Checkpoint saved: 200 queries processed

============================================================
Batch 101/1536: Processing 2 queries
============================================================
Predictions:  ['strong positive correlation 09', '43 28']
Answer:  ['strong positive correlation 09', '22']
Predictions:  ['strong positive correlation 09']
Answer:  ['strong positive correlation 09']
  [Batch] Query 201: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (11.37s avg)
Predictions:  ['43 28']
Answer:  ['22']
  [Batch] Query 202: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (11.37s avg)
Checkpoint saved: 202 queries processed

============================================================
Batch 102/1536: Processing 2 queries
============================================================
Predictions:  ['caring for and helping household members caring for and helping household children physical care educationrelated activities reading towith children playingdoing hobbies with children', 'lawn and garden care']
Answer:  ['watching television', 'reading towith children']
Predictions:  ['caring for and helping household members caring for and helping household children physical care educationrelated activities reading towith children playingdoing hobbies with children']
Answer:  ['watching television']
  [Batch] Query 203: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (13.88s avg)
Predictions:  ['lawn and garden care']
Answer:  ['reading towith children']
  [Batch] Query 204: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (13.88s avg)
Checkpoint saved: 204 queries processed

============================================================
Batch 103/1536: Processing 2 queries
============================================================
  Warning: Large text input (55692 tokens)
  [Single] Query 205: {'GPT_EVAL': 'N/A (no eval_api_key)'} (18.89s)
  Warning: Large text input (55711 tokens)
Processing batches:   7%|▋         | 103/1536 [28:51<10:18:53, 25.91s/it]Processing batches:   7%|▋         | 104/1536 [29:13<9:47:34, 24.62s/it]   [Single] Query 206: {'GPT_EVAL': 'N/A (no eval_api_key)'} (15.10s)
Checkpoint saved: 206 queries processed

============================================================
Batch 104/1536: Processing 2 queries
============================================================
Predictions:  ['05 04', '06 06']
Answer:  ['05', '06']
Predictions:  ['05 04']
Answer:  ['05']
  [Batch] Query 207: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (10.68s avg)
Predictions:  ['06 06']
Answer:  ['06']
  [Batch] Query 208: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (10.68s avg)
Checkpoint saved: 208 queries processed

============================================================
Batch 105/1536: Processing 2 queries
============================================================
Predictions:  ['both spouses work full time mother employed part time and father employed full time mother not employed and father employed full time']
Answer:  ['3']
Predictions:  ['both spouses work full time mother employed part time and father employed full time mother not employed and father employed full time']
Answer:  ['3']
  [Batch] Query 209: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (11.10s avg)
  Warning: Large text input (52158 tokens)
Processing batches:   7%|▋         | 105/1536 [30:06<13:14:22, 33.31s/it]Processing batches:   7%|▋         | 106/1536 [30:23<11:13:17, 28.25s/it]Code: import pandas as pd
import matplotlib.pyplot as plt

# Load the data from the Excel file
df = pd.read_excel('/data/pan/4xin/datasets/RealHiTBench/tables/activitytime-table04.xlsx')

# Extract the relevant data for household activities
# The table is structured with multiple sections for different age groups and employment statuses.
# We'll extract the household activities data for each category.

# Define the categories for the x-axis
categories = [
"Both spouses work full time",
"Mother employed part time and father employed full time",
"Mother not employed and father employed full time"
]

# Define the age groups
age_groups = [
"Own household children under 18",
"Own household children, youngest under 6",
"Own household children 6-17, none younger"
]

# Initialize lists to store the data
mother_hours = []
father_hours = []
difference_hours = []

# Extract data for "Household activities" for each category and age group
for age_group in age_groups:
for category in categories:
# Find the row for "Household activities" under the current category and age group
row_index = df[df['Activity'] == 'Household activities'].index[0]
# Find the column for the current category
col_index = df.columns.get_loc(category)
# Extract the data for mothers and fathers
mother_hours.append(df.iloc[row_index, col_index + 1])
father_hours.append(df.iloc[row_index, col_index + 2])
difference_hours.append(df.iloc[row_index, col_index + 3])

# Create a bar chart
plt.figure(figsize=(10, 6))
bar_width = 0.35
index = range(len(categories))
plt.bar(index, mother_hours, bar_width, label='Mothers', color='blue')
plt.bar([i + bar_width for i in index], father_hours, bar_width, label='Fathers', color='red')
plt.bar([i + 2 * bar_width for i in index], difference_hours, bar_width, label='Difference', color='green')

# Set the x-axis labels
plt.xticks([i + bar_width for i in index], categories)

# Set the y-axis label
plt.ylabel('Hours per day')

# Set the title
plt.title('Differences in time spent on household activities between married mothers and fathers')

# Add a legend
plt.legend()

# Show the plot
plt.tight_layout()
plt.show()

Python Error: expected an indented block after 'for' statement on line 33 (<string>, line 34)
  [Single] Query 210: {'ECR': False, 'Pass': False} (42.36s)
Checkpoint saved: 210 queries processed

============================================================
Batch 106/1536: Processing 2 queries
============================================================
Predictions:  ['06 16', 'serviceproviding industries']
Answer:  ['06', 'serviceproviding industries']
Predictions:  ['06 16']
Answer:  ['06']
  [Batch] Query 211: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (8.10s avg)
Predictions:  ['serviceproviding industries']
Answer:  ['serviceproviding industries']
  [Batch] Query 212: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (8.10s avg)
Checkpoint saved: 212 queries processed

============================================================
Batch 107/1536: Processing 2 queries
============================================================
Predictions:  ['no']
Answer:  ['no']
Predictions:  ['no']
Answer:  ['no']
  [Batch] Query 213: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (2.39s avg)
  Warning: Large text input (17450 tokens)
Processing batches:   7%|▋         | 107/1536 [30:30<8:45:08, 22.05s/it] Processing batches:   7%|▋         | 108/1536 [30:35<6:44:09, 16.98s/it]Processing batches:   7%|▋         | 109/1536 [30:38<5:02:14, 12.71s/it]Processing batches:   7%|▋         | 110/1536 [30:50<4:52:59, 12.33s/it]Processing batches:   7%|▋         | 111/1536 [30:52<3:42:33,  9.37s/it]Processing batches:   7%|▋         | 112/1536 [30:54<2:52:24,  7.26s/it]Processing batches:   7%|▋         | 113/1536 [31:04<3:07:44,  7.92s/it]Processing batches:   7%|▋         | 114/1536 [31:13<3:18:20,  8.37s/it]Processing batches:   7%|▋         | 115/1536 [31:24<3:38:39,  9.23s/it]Processing batches:   8%|▊         | 116/1536 [31:30<3:10:55,  8.07s/it]  [Single] Query 214: {'GPT_EVAL': 'N/A (no eval_api_key)'} (5.07s)
Checkpoint saved: 214 queries processed

============================================================
Batch 108/1536: Processing 2 queries
============================================================
Predictions:  ['1646 1771', 'pacific']
Answer:  ['higher eci in leisure and hospitality consistent eci in education and health services', 'pacific']
Predictions:  ['1646 1771']
Answer:  ['higher eci in leisure and hospitality consistent eci in education and health services']
  [Batch] Query 215: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.45s avg)
Predictions:  ['pacific']
Answer:  ['pacific']
  [Batch] Query 216: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (2.45s avg)
Checkpoint saved: 216 queries processed

============================================================
Batch 109/1536: Processing 2 queries
============================================================
Predictions:  ['1574 1664', 'new england middle atlantic south west north central west']
Answer:  ['84', '7']
Predictions:  ['1574 1664']
Answer:  ['84']
  [Batch] Query 217: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.25s avg)
Predictions:  ['new england middle atlantic south west north central west']
Answer:  ['7']
  [Batch] Query 218: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.25s avg)
Checkpoint saved: 218 queries processed

============================================================
Batch 110/1536: Processing 2 queries
============================================================
Predictions:  ['1623']
Answer:  ['1615']
Predictions:  ['1623']
Answer:  ['1615']
  [Batch] Query 219: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.29s avg)
  [Single] Query 220: {'GPT_EVAL': 'N/A (no eval_api_key)'} (10.03s)
Checkpoint saved: 220 queries processed

============================================================
Batch 111/1536: Processing 2 queries
============================================================
Predictions:  ['production transportation and material moving service occupations', '1077 01']
Answer:  ['3', '1077 01']
Predictions:  ['production transportation and material moving service occupations']
Answer:  ['3']
  [Batch] Query 221: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.11s avg)
Predictions:  ['1077 01']
Answer:  ['1077 01']
  [Batch] Query 222: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.11s avg)
Checkpoint saved: 222 queries processed

============================================================
Batch 112/1536: Processing 2 queries
============================================================
Predictions:  ['34 34', 'no clear trend']
Answer:  ['equal', '2018']
Predictions:  ['34 34']
Answer:  ['equal']
  [Batch] Query 223: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.05s avg)
Predictions:  ['no clear trend']
Answer:  ['2018']
  [Batch] Query 224: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.05s avg)
Checkpoint saved: 224 queries processed

============================================================
Batch 113/1536: Processing 2 queries
============================================================
Predictions:  ['39 35 33', '540 581 570 532 513']
Answer:  ['36', '571']
Predictions:  ['39 35 33']
Answer:  ['36']
  [Batch] Query 225: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.60s avg)
Predictions:  ['540 581 570 532 513']
Answer:  ['571']
  [Batch] Query 226: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.60s avg)
Checkpoint saved: 226 queries processed

============================================================
Batch 114/1536: Processing 2 queries
============================================================
Predictions:  ['san josesunnyvalesanta clara ca 641', '338 313']
Answer:  ['san josesunnyvalesanta clara ca 641', '23']
Predictions:  ['san josesunnyvalesanta clara ca 641']
Answer:  ['san josesunnyvalesanta clara ca 641']
  [Batch] Query 227: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (4.59s avg)
Predictions:  ['338 313']
Answer:  ['23']
  [Batch] Query 228: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.59s avg)
Checkpoint saved: 228 queries processed

============================================================
Batch 115/1536: Processing 2 queries
============================================================
Predictions:  ['64', '530 523 525 549 552']
Answer:  ['50', '553']
Predictions:  ['64']
Answer:  ['50']
  [Batch] Query 229: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (5.50s avg)
Predictions:  ['530 523 525 549 552']
Answer:  ['553']
  [Batch] Query 230: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (5.50s avg)
Checkpoint saved: 230 queries processed

============================================================
Batch 116/1536: Processing 2 queries
============================================================
Predictions:  ['13 09', 'production transportation and material moving']
Answer:  ['21', 'service occupations']
Predictions:  ['13 09']
Answer:  ['21']
  [Batch] Query 231: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.55s avg)
Predictions:  ['production transportation and material moving']
Answer:  ['service occupations']
  [Batch] Query 232: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.55s avg)
Checkpoint saved: 232 queries processed

============================================================
Batch 117/1536: Processing 2 queries
============================================================
Predictions:  ['06 06']
Answer:  ['06']
Predictions:  ['06 06']
Answer:  ['06']
  [Batch] Query 233: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (2.71s avg)
  Warning: Large text input (17026 tokens)
Processing batches:   8%|▊         | 117/1536 [31:44<3:55:23,  9.95s/it]Processing batches:   8%|▊         | 118/1536 [31:49<3:20:20,  8.48s/it]Processing batches:   8%|▊         | 119/1536 [31:54<2:51:34,  7.27s/it]Processing batches:   8%|▊         | 120/1536 [31:57<2:24:26,  6.12s/it]Processing batches:   8%|▊         | 121/1536 [32:00<2:01:37,  5.16s/it]Processing batches:   8%|▊         | 122/1536 [32:02<1:41:08,  4.29s/it]Processing batches:   8%|▊         | 123/1536 [32:07<1:47:16,  4.56s/it]  [Single] Query 234: {'GPT_EVAL': 'N/A (no eval_api_key)'} (11.52s)
Checkpoint saved: 234 queries processed

============================================================
Batch 118/1536: Processing 2 queries
============================================================
Predictions:  ['1700 increasing trend', '230 548']
Answer:  ['1714', '230']
Predictions:  ['1700 increasing trend']
Answer:  ['1714']
  [Batch] Query 235: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.39s avg)
Predictions:  ['230 548']
Answer:  ['230']
  [Batch] Query 236: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (2.39s avg)
Checkpoint saved: 236 queries processed

============================================================
Batch 119/1536: Processing 2 queries
============================================================
Predictions:  ['bostoncambridgenashua manh', 'atlantasandy springsroswell ga detroitwarrendearborn mi houstonthe woodlandssugar land tx las vegashendersonparadise nv']
Answer:  ['sacramentorosevilleardenarcade ca', '6']
Predictions:  ['bostoncambridgenashua manh']
Answer:  ['sacramentorosevilleardenarcade ca']
  [Batch] Query 237: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.10s avg)
Predictions:  ['atlantasandy springsroswell ga detroitwarrendearborn mi houstonthe woodlandssugar land tx las vegashendersonparadise nv']
Answer:  ['6']
  [Batch] Query 238: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.10s avg)
Checkpoint saved: 238 queries processed

============================================================
Batch 120/1536: Processing 2 queries
============================================================
Predictions:  ['los angeleslong beachanaheim ca philadelphiacamdenwilmington panjdemd', '778']
Answer:  ['los angeleslong beachanaheim ca', '778']
Predictions:  ['los angeleslong beachanaheim ca philadelphiacamdenwilmington panjdemd']
Answer:  ['los angeleslong beachanaheim ca']
  [Batch] Query 239: {'F1': 80.0, 'EM': 0.0, 'ROUGE-L': 80.0, 'SacreBLEU': 50.81} (1.60s avg)
Predictions:  ['778']
Answer:  ['778']
  [Batch] Query 240: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.60s avg)
Checkpoint saved: 240 queries processed

============================================================
Batch 121/1536: Processing 2 queries
============================================================
Predictions:  ['increasing trend 1606']
Answer:  ['increasing trend']
Predictions:  ['increasing trend 1606']
Answer:  ['increasing trend']
  [Batch] Query 242: {'F1': 80.0, 'EM': 0.0, 'ROUGE-L': 80.0, 'SacreBLEU': 0.0} (1.48s avg)
  [Single] Query 241: {'GPT_EVAL': 'N/A (no eval_api_key)'} (1.30s)
Checkpoint saved: 242 queries processed

============================================================
Batch 122/1536: Processing 2 queries
============================================================
Predictions:  ['service occupations', 'public administration']
Answer:  ['service occupations', 'transportation and material moving']
Predictions:  ['service occupations']
Answer:  ['service occupations']
  [Batch] Query 243: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.01s avg)
Predictions:  ['public administration']
Answer:  ['transportation and material moving']
  [Batch] Query 244: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.01s avg)
Checkpoint saved: 244 queries processed

============================================================
Batch 123/1536: Processing 2 queries
============================================================
Predictions:  ['1793 1724', '1591 1628']
Answer:  ['6', 'jun 2024 37']
Predictions:  ['1793 1724']
Answer:  ['6']
  [Batch] Query 245: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.46s avg)
Predictions:  ['1591 1628']
Answer:  ['jun 2024 37']
  [Batch] Query 246: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.46s avg)
Checkpoint saved: 246 queries processed

============================================================
Batch 124/1536: Processing 2 queries
============================================================
Predictions:  ['38']
Answer:  ['36']
Predictions:  ['38']
Answer:  ['36']
  [Batch] Query 248: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.32s avg)
  Warning: Large text input (15705 tokens)
Processing batches:   8%|▊         | 124/1536 [32:17<2:24:03,  6.12s/it]Processing batches:   8%|▊         | 125/1536 [32:22<2:15:21,  5.76s/it]Processing batches:   8%|▊         | 126/1536 [32:27<2:09:20,  5.50s/it]Processing batches:   8%|▊         | 127/1536 [32:32<2:06:26,  5.38s/it]Processing batches:   8%|▊         | 128/1536 [32:37<2:02:08,  5.20s/it]Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/data/pan/4xin/datasets/RealHiTBench/tables/welfare-table09.xlsx')
data = df[df['Occupational group and industry'] == 'All workers']
x = data.iloc[:, 4:7].columns.tolist()
y = data.iloc[:, 4:7].values[0]
plt.bar(x, y)
plt.xlabel('Period')
plt.ylabel('Percent Change')
plt.title('Percent Changes in Employment Cost Index for All Workers')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

OUTPUT VALUE: [0.9, 1.0, 0.6]

  [Single] Query 247: {'ECR': True, 'Pass': False} (7.33s)
Checkpoint saved: 248 queries processed

============================================================
Batch 125/1536: Processing 2 queries
============================================================
Predictions:  ['12171 12484', '3']
Answer:  ['246551', '26']
Predictions:  ['12171 12484']
Answer:  ['246551']
  [Batch] Query 249: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.33s avg)
Predictions:  ['3']
Answer:  ['26']
  [Batch] Query 250: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.33s avg)
Checkpoint saved: 250 queries processed

============================================================
Batch 126/1536: Processing 2 queries
============================================================
Predictions:  ['182527', '12171 12484']
Answer:  ['1825266', '123275']
Predictions:  ['182527']
Answer:  ['1825266']
  [Batch] Query 251: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.33s avg)
Predictions:  ['12171 12484']
Answer:  ['123275']
  [Batch] Query 252: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.33s avg)
Checkpoint saved: 252 queries processed

============================================================
Batch 127/1536: Processing 2 queries
============================================================
Predictions:  ['51881586', 'china european union27 mexico japan indonesia taiwan egypt south korea vietnam thailand']
Answer:  ['599694862', 'china european union27 mexico japan indonesia taiwan egypt south korea vietnam thailand']
Predictions:  ['51881586']
Answer:  ['599694862']
  [Batch] Query 253: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.43s avg)
Predictions:  ['china european union27 mexico japan indonesia taiwan egypt south korea vietnam thailand']
Answer:  ['china european union27 mexico japan indonesia taiwan egypt south korea vietnam thailand']
  [Batch] Query 254: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (2.43s avg)
Checkpoint saved: 254 queries processed

============================================================
Batch 128/1536: Processing 2 queries
============================================================
Predictions:  ['aug 2022 12020670', 'decrease decrease']
Answer:  ['aug 2022 9634024', 'increasing trend']
Predictions:  ['aug 2022 12020670']
Answer:  ['aug 2022 9634024']
  [Batch] Query 255: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (2.27s avg)
Predictions:  ['decrease decrease']
Answer:  ['increasing trend']
  [Batch] Query 256: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.27s avg)
Checkpoint saved: 256 queries processed

============================================================
Batch 129/1536: Processing 2 queries
============================================================
Predictions:  ['no']
Answer:  ['no']
Predictions:  ['no']
Answer:  ['no']
  [Batch] Query 258: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.76s avg)
  Warning: Large text input (12914 tokens)
Processing batches:   8%|▊         | 129/1536 [32:41<1:51:48,  4.77s/it]Processing batches:   8%|▊         | 130/1536 [32:45<1:46:25,  4.54s/it]  [Single] Query 257: {'GPT_EVAL': 'N/A (no eval_api_key)'} (1.87s)
Checkpoint saved: 258 queries processed

============================================================
Batch 130/1536: Processing 2 queries
============================================================
Predictions:  ['3902', '2021 2022']
Answer:  ['3902', '2021 2022']
Predictions:  ['3902']
Answer:  ['3902']
  [Batch] Query 259: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.88s avg)
Predictions:  ['2021 2022']
Answer:  ['2021 2022']
  [Batch] Query 260: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.88s avg)
Checkpoint saved: 260 queries processed

============================================================
Batch 131/1536: Processing 2 queries
============================================================
Predictions:  ['1692 1692 1692']
Answer:  ['1692']
Predictions:  ['1692 1692 1692']
Answer:  ['1692']
  [Batch] Query 261: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (2.71s avg)
  Warning: Large text input (12235 tokens)
Processing batches:   9%|▊         | 131/1536 [32:56<2:31:37,  6.48s/it]Processing batches:   9%|▊         | 132/1536 [33:01<2:20:10,  5.99s/it]Processing batches:   9%|▊         | 133/1536 [33:10<2:42:55,  6.97s/it]Processing batches:   9%|▊         | 134/1536 [33:14<2:25:46,  6.24s/it]Processing batches:   9%|▉         | 135/1536 [33:18<2:11:01,  5.61s/it]Processing batches:   9%|▉         | 136/1536 [33:23<2:00:13,  5.15s/it]Processing batches:   9%|▉         | 137/1536 [33:26<1:44:47,  4.49s/it]Processing batches:   9%|▉         | 138/1536 [33:33<2:07:17,  5.46s/it]Processing batches:   9%|▉         | 139/1536 [33:50<3:22:51,  8.71s/it]Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel("/data/pan/4xin/datasets/RealHiTBench/tables/agriculture-table02.xlsx")
fiscal_years = df.columns[1:8]  # Extract fiscal years columns
agricultural_exports = df.iloc[3, 1:8]  # Extract agricultural exports row
plt.plot(fiscal_years, agricultural_exports, marker='o')
plt.title("Agricultural Export Values (Billion Dollars) from Fiscal Years 2020 to 2024")
plt.xlabel("Fiscal Year")
plt.ylabel("Export Value (Billion Dollars)")
plt.xticks(fiscal_years, rotation=45)
plt.grid(True)
plt.tight_layout()
plt.show()

OUTPUT VALUE: [[143.402657062, 163.321690214, 194.137500777, 195.333657355, 195.333657355, 206.207275626, 17.387802869]]

  [Single] Query 262: {'ECR': True, 'Pass': False} (8.15s)
Checkpoint saved: 262 queries processed

============================================================
Batch 132/1536: Processing 2 queries
============================================================
Predictions:  ['407670', 'fy 11 fy 12 fy 10 fy 13 fy 14 fy 09 fy 15 fy 16 fy 17 fy 18']
Answer:  ['406943', 'fy 12 fy 13 fy 11 fy 14 fy 15 fy 16 fy 17 fy 10 fy 18 fy 09']
Predictions:  ['407670']
Answer:  ['406943']
  [Batch] Query 263: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.31s avg)
Predictions:  ['fy 11 fy 12 fy 10 fy 13 fy 14 fy 09 fy 15 fy 16 fy 17 fy 18']
Answer:  ['fy 12 fy 13 fy 11 fy 14 fy 15 fy 16 fy 17 fy 10 fy 18 fy 09']
  [Batch] Query 264: {'F1': 100.0, 'EM': 0.0, 'ROUGE-L': 70.0, 'SacreBLEU': 59.32} (2.31s avg)
Checkpoint saved: 264 queries processed

============================================================
Batch 133/1536: Processing 2 queries
============================================================
Predictions:  ['andaman nicobar']
Answer:  ['andaman nicobar']
Predictions:  ['andaman nicobar']
Answer:  ['andaman nicobar']
  [Batch] Query 266: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (2.20s avg)
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/data/pan/4xin/datasets/RealHiTBench/tables/economy-table02.xlsx')
data = df.iloc[2:5, 2:13].values.tolist()
years = ['FY \'09', 'FY \'13', 'FY \'18']
revenues = [data[0][0], data[0][5], data[0][10]]
total = sum(revenues)
proportions = [revenue / total for revenue in revenues]
plt.pie(proportions, labels=years, autopct='%1.1f%%')
plt.title('Proportion of Net Operating Revenue')
plt.show()

Python Error: list index out of range
  [Single] Query 265: {'ECR': False, 'Pass': False} (6.92s)
Checkpoint saved: 266 queries processed

============================================================
Batch 134/1536: Processing 2 queries
============================================================
Predictions:  ['yes', '992']
Answer:  ['yes', '992']
Predictions:  ['yes']
Answer:  ['yes']
  [Batch] Query 267: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (2.15s avg)
Predictions:  ['992']
Answer:  ['992']
  [Batch] Query 268: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (2.15s avg)
Checkpoint saved: 268 queries processed

============================================================
Batch 135/1536: Processing 2 queries
============================================================
Predictions:  ['karnataka kerala', '21364']
Answer:  ['kerala', '21364']
Predictions:  ['karnataka kerala']
Answer:  ['kerala']
  [Batch] Query 269: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (1.95s avg)
Predictions:  ['21364']
Answer:  ['21364']
  [Batch] Query 270: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.95s avg)
Checkpoint saved: 270 queries processed

============================================================
Batch 136/1536: Processing 2 queries
============================================================
Predictions:  ['punjab', '36']
Answer:  ['punjab', '36']
Predictions:  ['punjab']
Answer:  ['punjab']
  [Batch] Query 271: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.92s avg)
Predictions:  ['36']
Answer:  ['36']
  [Batch] Query 272: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.92s avg)
Checkpoint saved: 272 queries processed

============================================================
Batch 137/1536: Processing 2 queries
============================================================
Predictions:  ['canned packed in syrup or water', '466 262']
Answer:  ['canned packed in syrup or water', '495']
Predictions:  ['canned packed in syrup or water']
Answer:  ['canned packed in syrup or water']
  [Batch] Query 273: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (1.36s avg)
Predictions:  ['466 262']
Answer:  ['495']
  [Batch] Query 274: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.36s avg)
Checkpoint saved: 274 queries processed

============================================================
Batch 138/1536: Processing 2 queries
============================================================
Predictions:  ['usda economic research service ers calculations from 2022 circana formerly information resources inc iri omnimarket core outlets formerly infoscan data and usda ars national nutrient database for standard reference sr legacy release food patterns equivalents database fped 2017–18 and fpeds accompanying methodology and user guide', '50 03']
Answer:  ['source usda economic research service ers calculations from 2022 circana formerly information resources inc iri omnimarket core outlets formerly infoscan data and usda ars national nutrient database for standard reference sr legacy release food patterns equivalents database fped 2017–18 and fpeds accompanying methodology and user guide', '50 04']
Predictions:  ['usda economic research service ers calculations from 2022 circana formerly information resources inc iri omnimarket core outlets formerly infoscan data and usda ars national nutrient database for standard reference sr legacy release food patterns equivalents database fped 2017–18 and fpeds accompanying methodology and user guide']
Answer:  ['source usda economic research service ers calculations from 2022 circana formerly information resources inc iri omnimarket core outlets formerly infoscan data and usda ars national nutrient database for standard reference sr legacy release food patterns equivalents database fped 2017–18 and fpeds accompanying methodology and user guide']
  [Batch] Query 275: {'F1': 98.9, 'EM': 0.0, 'ROUGE-L': 98.92, 'SacreBLEU': 97.8} (3.74s avg)
Predictions:  ['50 03']
Answer:  ['50 04']
  [Batch] Query 276: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (3.74s avg)
Checkpoint saved: 276 queries processed

============================================================
Batch 139/1536: Processing 2 queries
============================================================
Predictions:  ['92 92 93', '93 95']
Answer:  ['95 92 93', 'after']
Predictions:  ['92 92 93']
Answer:  ['95 92 93']
  [Batch] Query 277: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (8.02s avg)
Predictions:  ['93 95']
Answer:  ['after']
  [Batch] Query 278: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (8.02s avg)
Checkpoint saved: 278 queries processed

============================================================
Batch 140/1536: Processing 2 queries
============================================================
Predictions:  ['weak positive correlation 03']
Answer:  ['weak negative correlation 04']
Predictions:  ['weak positive correlation 03']
Answer:  ['weak negative correlation 04']
  [Batch] Query 279: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 19.0} (7.16s avg)
  Warning: Large text input (41392 tokens)
Processing batches:   9%|▉         | 140/1536 [34:08<4:31:46, 11.68s/it]Processing batches:   9%|▉         | 141/1536 [34:10<3:22:29,  8.71s/it]Processing batches:   9%|▉         | 142/1536 [34:13<2:40:35,  6.91s/it]Processing batches:   9%|▉         | 143/1536 [34:15<2:08:01,  5.51s/it]Processing batches:   9%|▉         | 144/1536 [34:17<1:42:13,  4.41s/it]Processing batches:   9%|▉         | 145/1536 [34:20<1:35:53,  4.14s/it]Processing batches:  10%|▉         | 146/1536 [34:24<1:31:08,  3.93s/it]  [Single] Query 280: {'GPT_EVAL': 'N/A (no eval_api_key)'} (11.33s)
Checkpoint saved: 280 queries processed

============================================================
Batch 141/1536: Processing 2 queries
============================================================
Predictions:  ['109', '0 mgl malathion']
Answer:  ['172', 'no such concentration exists']
Predictions:  ['109']
Answer:  ['172']
  [Batch] Query 281: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (0.76s avg)
Predictions:  ['0 mgl malathion']
Answer:  ['no such concentration exists']
  [Batch] Query 282: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (0.76s avg)
Checkpoint saved: 282 queries processed

============================================================
Batch 142/1536: Processing 2 queries
============================================================
Predictions:  ['0 mgl 5 mgl', '5 mgl malathion 1 mgl malathion 0 mgl malathion']
Answer:  ['5 mgl', '1 mgl 5 mgl 0 mgl']
Predictions:  ['0 mgl 5 mgl']
Answer:  ['5 mgl']
  [Batch] Query 283: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 31.95} (1.24s avg)
Predictions:  ['5 mgl malathion 1 mgl malathion 0 mgl malathion']
Answer:  ['1 mgl 5 mgl 0 mgl']
  [Batch] Query 284: {'F1': 80.0, 'EM': 0.0, 'ROUGE-L': 53.33, 'SacreBLEU': 16.52} (1.24s avg)
Checkpoint saved: 284 queries processed

============================================================
Batch 143/1536: Processing 2 queries
============================================================
Predictions:  ['strong negative correlation 09', '463']
Answer:  ['negative impact', '463']
Predictions:  ['strong negative correlation 09']
Answer:  ['negative impact']
  [Batch] Query 285: {'F1': 33.33, 'EM': 0.0, 'ROUGE-L': 33.33, 'SacreBLEU': 15.97} (1.00s avg)
Predictions:  ['463']
Answer:  ['463']
  [Batch] Query 286: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.00s avg)
Checkpoint saved: 286 queries processed

============================================================
Batch 144/1536: Processing 2 queries
============================================================
Predictions:  ['barley', 'corn barley']
Answer:  ['soybean', 'corn']
Predictions:  ['barley']
Answer:  ['soybean']
  [Batch] Query 287: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (0.79s avg)
Predictions:  ['corn barley']
Answer:  ['corn']
  [Batch] Query 288: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (0.79s avg)
Checkpoint saved: 288 queries processed

============================================================
Batch 145/1536: Processing 2 queries
============================================================
Predictions:  ['17 137 463 32 12 302', 'decreasing trend 320 265']
Answer:  ['252', 'decreasing trend']
Predictions:  ['17 137 463 32 12 302']
Answer:  ['252']
  [Batch] Query 289: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.63s avg)
Predictions:  ['decreasing trend 320 265']
Answer:  ['decreasing trend']
  [Batch] Query 290: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 31.95} (1.63s avg)
Checkpoint saved: 290 queries processed

============================================================
Batch 146/1536: Processing 2 queries
============================================================
Predictions:  ['israel netherlands united kingdom united states', 'belgium malta']
Answer:  ['malta belgium canada france greece hungary ireland israel italy lithuania luxembourg netherlands poland portugal slovak republic spain united kingdom united states cyprus romania', 'belgium']
Predictions:  ['israel netherlands united kingdom united states']
Answer:  ['malta belgium canada france greece hungary ireland israel italy lithuania luxembourg netherlands poland portugal slovak republic spain united kingdom united states cyprus romania']
  [Batch] Query 291: {'F1': 41.38, 'EM': 0.0, 'ROUGE-L': 41.38, 'SacreBLEU': 3.31} (1.61s avg)
Predictions:  ['belgium malta']
Answer:  ['belgium']
  [Batch] Query 292: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (1.61s avg)
Checkpoint saved: 292 queries processed

============================================================
Batch 147/1536: Processing 2 queries
============================================================
Predictions:  ['00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00']
Answer:  ['00']
Predictions:  ['00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00']
Answer:  ['00']
  [Batch] Query 294: {'F1': 0.39, 'EM': 0.0, 'ROUGE-L': 0.39, 'SacreBLEU': 0.07} (196.30s avg)
  Warning: Large text input (10579 tokens)
Processing batches:  10%|▉         | 147/1536 [37:48<24:44:12, 64.11s/it]  [Single] Query 293: {'GPT_EVAL': 'N/A (no eval_api_key)'} (8.10s)
Checkpoint saved: 294 queries processed

============================================================
Batch 148/1536: Processing 2 queries
============================================================
Predictions:  ['northern territory tl2']
Answer:  ['northern territory tl2']
Predictions:  ['northern territory tl2']
Answer:  ['northern territory tl2']
  [Batch] Query 296: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (3.76s avg)
  Warning: Large text input (10554 tokens)
Processing batches:  10%|▉         | 148/1536 [37:54<17:56:32, 46.54s/it]Processing batches:  10%|▉         | 149/1536 [38:02<13:31:20, 35.10s/it]  [Single] Query 295: {'GPT_EVAL': 'N/A (no eval_api_key)'} (1.64s)
Checkpoint saved: 296 queries processed

============================================================
Batch 149/1536: Processing 2 queries
============================================================
Predictions:  ['2018 2016', '4333']
Answer:  ['2018', '4283']
Predictions:  ['2018 2016']
Answer:  ['2018']
  [Batch] Query 297: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (4.08s avg)
Predictions:  ['4333']
Answer:  ['4283']
  [Batch] Query 298: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.08s avg)
Checkpoint saved: 298 queries processed

============================================================
Batch 150/1536: Processing 2 queries
============================================================
Predictions:  ['increasing trend']
Answer:  ['increasing trend']
Predictions:  ['increasing trend']
Answer:  ['increasing trend']
  [Batch] Query 300: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (3.64s avg)
  Warning: Large text input (25841 tokens)
Processing batches:  10%|▉         | 150/1536 [38:20<11:31:29, 29.93s/it]Processing batches:  10%|▉         | 151/1536 [38:24<8:28:38, 22.03s/it] Processing batches:  10%|▉         | 152/1536 [38:27<6:21:39, 16.55s/it]  [Single] Query 299: {'GPT_EVAL': 'N/A (no eval_api_key)'} (14.12s)
Checkpoint saved: 300 queries processed

============================================================
Batch 151/1536: Processing 2 queries
============================================================
Predictions:  ['baby john bertrand jesse', '15']
Answer:  ['baby john', '42']
Predictions:  ['baby john bertrand jesse']
Answer:  ['baby john']
  [Batch] Query 301: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 31.95} (1.68s avg)
Predictions:  ['15']
Answer:  ['42']
  [Batch] Query 302: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.68s avg)
Checkpoint saved: 302 queries processed

============================================================
Batch 152/1536: Processing 2 queries
============================================================
Predictions:  ['riberdymichel', '2279631']
Answer:  ['riberdy michel', '25329']
Predictions:  ['riberdymichel']
Answer:  ['riberdy michel']
  [Batch] Query 303: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.75s avg)
Predictions:  ['2279631']
Answer:  ['25329']
  [Batch] Query 304: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.75s avg)
Checkpoint saved: 304 queries processed

============================================================
Batch 153/1536: Processing 2 queries
============================================================
Predictions:  ['31961']
Answer:  ['31961']
Predictions:  ['31961']
Answer:  ['31961']
  [Batch] Query 306: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (4.36s avg)
  Warning: Large text input (11617 tokens)
Processing batches:  10%|▉         | 153/1536 [38:39<5:49:31, 15.16s/it]Processing batches:  10%|█         | 154/1536 [38:53<5:38:30, 14.70s/it]  [Single] Query 305: {'GPT_EVAL': 'N/A (no eval_api_key)'} (7.45s)
Checkpoint saved: 306 queries processed

============================================================
Batch 154/1536: Processing 2 queries
============================================================
Predictions:  ['09 09 09 10 10 10 10', '09']
Answer:  ['09', '09']
Predictions:  ['09 09 09 10 10 10 10']
Answer:  ['09']
  [Batch] Query 307: {'F1': 25.0, 'EM': 0.0, 'ROUGE-L': 25.0, 'SacreBLEU': 6.57} (6.68s avg)
Predictions:  ['09']
Answer:  ['09']
  [Batch] Query 308: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (6.68s avg)
Checkpoint saved: 308 queries processed

============================================================
Batch 155/1536: Processing 2 queries
============================================================
Predictions:  ['09 09 10 10 10 10 10']
Answer:  ['09']
Predictions:  ['09 09 10 10 10 10 10']
Answer:  ['09']
  [Batch] Query 310: {'F1': 25.0, 'EM': 0.0, 'ROUGE-L': 25.0, 'SacreBLEU': 6.57} (6.25s avg)
  Warning: Large text input (28513 tokens)
Processing batches:  10%|█         | 155/1536 [39:15<6:32:29, 17.05s/it]Processing batches:  10%|█         | 156/1536 [39:19<4:59:48, 13.04s/it]Processing batches:  10%|█         | 157/1536 [39:32<4:59:01, 13.01s/it]Processing batches:  10%|█         | 158/1536 [39:39<4:20:19, 11.33s/it]Processing batches:  10%|█         | 159/1536 [39:47<3:55:16, 10.25s/it]Processing batches:  10%|█         | 160/1536 [39:55<3:40:08,  9.60s/it]Processing batches:  10%|█         | 161/1536 [40:05<3:38:36,  9.54s/it]  [Single] Query 309: {'GPT_EVAL': 'N/A (no eval_api_key)'} (16.18s)
Checkpoint saved: 310 queries processed

============================================================
Batch 156/1536: Processing 2 queries
============================================================
Predictions:  ['archered cecuttianthony albert fowkekevin g hardingbrian jacquessteve woodian', 'archered']
Answer:  ['archered cecuttianthony albert fowkekevin g hardingbrian jacquessteve verrilligiovanna woodian', 'verrilli giovanna']
Predictions:  ['archered cecuttianthony albert fowkekevin g hardingbrian jacquessteve woodian']
Answer:  ['archered cecuttianthony albert fowkekevin g hardingbrian jacquessteve verrilligiovanna woodian']
  [Batch] Query 311: {'F1': 94.12, 'EM': 0.0, 'ROUGE-L': 94.12, 'SacreBLEU': 76.73} (1.71s avg)
Predictions:  ['archered']
Answer:  ['verrilli giovanna']
  [Batch] Query 312: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.71s avg)
Checkpoint saved: 312 queries processed

============================================================
Batch 157/1536: Processing 2 queries
============================================================
Predictions:  ['43560']
Answer:  ['43229']
Predictions:  ['43560']
Answer:  ['43229']
  [Batch] Query 313: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.31s avg)
  [Single] Query 314: {'GPT_EVAL': 'N/A (no eval_api_key)'} (11.52s)
Checkpoint saved: 314 queries processed

============================================================
Batch 158/1536: Processing 2 queries
============================================================
Predictions:  ['43560 18577', 'cripplegate aldersgate']
Answer:  ['43229 18905', 'cripplegate']
Predictions:  ['43560 18577']
Answer:  ['43229 18905']
  [Batch] Query 315: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.59s avg)
Predictions:  ['cripplegate aldersgate']
Answer:  ['cripplegate']
  [Batch] Query 316: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (3.59s avg)
Checkpoint saved: 316 queries processed

============================================================
Batch 159/1536: Processing 2 queries
============================================================
Predictions:  ['becontree', 'portsoken aldersgate']
Answer:  ['abbey', 'portsoken']
Predictions:  ['becontree']
Answer:  ['abbey']
  [Batch] Query 317: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.74s avg)
Predictions:  ['portsoken aldersgate']
Answer:  ['portsoken']
  [Batch] Query 318: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (3.74s avg)
Checkpoint saved: 318 queries processed

============================================================
Batch 160/1536: Processing 2 queries
============================================================
Predictions:  ['farringdon without abbey', 'strong positive correlation 10']
Answer:  ['abbey', 'strong positive correlation 09']
Predictions:  ['farringdon without abbey']
Answer:  ['abbey']
  [Batch] Query 319: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (3.92s avg)
Predictions:  ['strong positive correlation 10']
Answer:  ['strong positive correlation 09']
  [Batch] Query 320: {'F1': 75.0, 'EM': 0.0, 'ROUGE-L': 75.0, 'SacreBLEU': 59.46} (3.92s avg)
Checkpoint saved: 320 queries processed

============================================================
Batch 161/1536: Processing 2 queries
============================================================
Predictions:  ['1376 1084 1074', 'mexico 223168']
Answer:  ['3534', 'china people’s republic of 1942008']
Predictions:  ['1376 1084 1074']
Answer:  ['3534']
  [Batch] Query 321: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.58s avg)
Predictions:  ['mexico 223168']
Answer:  ['china people’s republic of 1942008']
  [Batch] Query 322: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.58s avg)
Checkpoint saved: 322 queries processed

============================================================
Batch 162/1536: Processing 2 queries
============================================================
Predictions:  ['2840']
Answer:  ['2832']
Predictions:  ['2840']
Answer:  ['2832']
  [Batch] Query 323: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.04s avg)
  Warning: Large text input (26583 tokens)
Processing batches:  11%|█         | 162/1536 [40:16<3:51:36, 10.11s/it]Processing batches:  11%|█         | 163/1536 [40:23<3:29:22,  9.15s/it]Processing batches:  11%|█         | 164/1536 [40:26<2:47:42,  7.33s/it]  [Single] Query 324: {'GPT_EVAL': 'N/A (no eval_api_key)'} (7.29s)
Checkpoint saved: 324 queries processed

============================================================
Batch 163/1536: Processing 2 queries
============================================================
Predictions:  ['decreasing trend', '03']
Answer:  ['increasing trend', '03']
Predictions:  ['decreasing trend']
Answer:  ['increasing trend']
  [Batch] Query 325: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (3.33s avg)
Predictions:  ['03']
Answer:  ['03']
  [Batch] Query 326: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (3.33s avg)
Checkpoint saved: 326 queries processed

============================================================
Batch 164/1536: Processing 2 queries
============================================================
Predictions:  ['08 07', 'yes']
Answer:  ['yes', 'yes']
Predictions:  ['08 07']
Answer:  ['yes']
  [Batch] Query 327: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.43s avg)
Predictions:  ['yes']
Answer:  ['yes']
  [Batch] Query 328: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.43s avg)
Checkpoint saved: 328 queries processed

============================================================
Batch 165/1536: Processing 2 queries
============================================================
Predictions:  ['0905080101']
Answer:  ['04']
Predictions:  ['0905080101']
Answer:  ['04']
  [Batch] Query 329: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.35s avg)
  Warning: Large text input (8641 tokens)
Processing batches:  11%|█         | 165/1536 [40:37<3:09:38,  8.30s/it]Processing batches:  11%|█         | 166/1536 [40:41<2:41:09,  7.06s/it]  [Single] Query 330: {'GPT_EVAL': 'N/A (no eval_api_key)'} (8.07s)
Checkpoint saved: 330 queries processed

============================================================
Batch 166/1536: Processing 2 queries
============================================================
Predictions:  ['4144', 'air']
Answer:  ['15371', 'air visits']
Predictions:  ['4144']
Answer:  ['15371']
  [Batch] Query 331: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.96s avg)
Predictions:  ['air']
Answer:  ['air visits']
  [Batch] Query 332: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (1.96s avg)
Checkpoint saved: 332 queries processed

============================================================
Batch 167/1536: Processing 2 queries
============================================================
Predictions:  ['1457 1463']
Answer:  ['996']
Predictions:  ['1457 1463']
Answer:  ['996']
  [Batch] Query 333: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.49s avg)
  Warning: Large text input (14304 tokens)
Processing batches:  11%|█         | 167/1536 [40:51<3:01:58,  7.98s/it]  [Single] Query 334: {'GPT_EVAL': 'N/A (no eval_api_key)'} (7.50s)
Checkpoint saved: 334 queries processed

============================================================
Batch 168/1536: Processing 2 queries
============================================================
Predictions:  ['england']
Answer:  ['england']
Predictions:  ['england']
Answer:  ['england']
  [Batch] Query 336: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.10s avg)
  Warning: Large text input (14285 tokens)
Processing batches:  11%|█         | 168/1536 [40:55<2:32:49,  6.70s/it]Processing batches:  11%|█         | 169/1536 [40:58<2:07:27,  5.59s/it]Processing batches:  11%|█         | 170/1536 [41:02<1:59:58,  5.27s/it]Processing batches:  11%|█         | 171/1536 [41:06<1:47:46,  4.74s/it]  [Single] Query 335: {'GPT_EVAL': 'N/A (no eval_api_key)'} (2.51s)
Checkpoint saved: 336 queries processed

============================================================
Batch 169/1536: Processing 2 queries
============================================================
Predictions:  ['decrease 2681686', 'strong positive correlation 10']
Answer:  ['decrease', 'strong positive correlation 10']
Predictions:  ['decrease 2681686']
Answer:  ['decrease']
  [Batch] Query 337: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (1.38s avg)
Predictions:  ['strong positive correlation 10']
Answer:  ['strong positive correlation 10']
  [Batch] Query 338: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (1.38s avg)
Checkpoint saved: 338 queries processed

============================================================
Batch 170/1536: Processing 2 queries
============================================================
Predictions:  ['2259333 390413 31940', '626 272']
Answer:  ['8938953', '626']
Predictions:  ['2259333 390413 31940']
Answer:  ['8938953']
  [Batch] Query 339: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.13s avg)
Predictions:  ['626 272']
Answer:  ['626']
  [Batch] Query 340: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (2.13s avg)
Checkpoint saved: 340 queries processed

============================================================
Batch 171/1536: Processing 2 queries
============================================================
Predictions:  ['sector j', 'northern ireland sector f']
Answer:  ['sector j', 'sector s']
Predictions:  ['sector j']
Answer:  ['sector j']
  [Batch] Query 341: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.62s avg)
Predictions:  ['northern ireland sector f']
Answer:  ['sector s']
  [Batch] Query 342: {'F1': 33.33, 'EM': 0.0, 'ROUGE-L': 33.33, 'SacreBLEU': 15.97} (1.62s avg)
Checkpoint saved: 342 queries processed

============================================================
Batch 172/1536: Processing 2 queries
============================================================
Predictions:  ['945 945']
Answer:  ['949']
Predictions:  ['945 945']
Answer:  ['949']
  [Batch] Query 343: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.07s avg)
  Warning: Large text input (11873 tokens)
Processing batches:  11%|█         | 172/1536 [41:12<1:58:15,  5.20s/it]Processing batches:  11%|█▏        | 173/1536 [41:17<1:56:25,  5.13s/it]  [Single] Query 344: {'GPT_EVAL': 'N/A (no eval_api_key)'} (4.08s)
Checkpoint saved: 344 queries processed

============================================================
Batch 173/1536: Processing 2 queries
============================================================
Predictions:  ['327884', '2014']
Answer:  ['327884', '2014']
Predictions:  ['327884']
Answer:  ['327884']
  [Batch] Query 345: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (2.35s avg)
Predictions:  ['2014']
Answer:  ['2014']
  [Batch] Query 346: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (2.35s avg)
Checkpoint saved: 346 queries processed

============================================================
Batch 174/1536: Processing 2 queries
============================================================
Predictions:  ['23681 8281']
Answer:  ['76319']
Predictions:  ['23681 8281']
Answer:  ['76319']
  [Batch] Query 347: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.75s avg)
  Warning: Large text input (16585 tokens)
Processing batches:  11%|█▏        | 174/1536 [41:33<3:12:16,  8.47s/it]Processing batches:  11%|█▏        | 175/1536 [42:03<5:35:04, 14.77s/it]Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/data/pan/4xin/datasets/RealHiTBench/tables/society-table84.xlsx')
high_value_visas = df.iloc[2:5, 3:11].iloc[:, 1:]
high_value_visas.columns = ['2008', '2009', '2010', '2011', '2012', '2013', '2014']
high_value_visas = high_value_visas.reset_index().melt(id_vars='index', var_name='Year', value_name='Visas')
high_value_visas['Year'] = high_value_visas['Year'].astype(int)
high_value_visas = high_value_visas.set_index('Year')
high_value_visas.plot(kind='line', marker='o')
plt.title('Trend in High-Value Visas Issued from 2008 to 2014')
plt.xlabel('Year')
plt.ylabel('Number of Visas')
plt.xticks(range(2008, 2015))
plt.grid(True)
plt.show()

OUTPUT VALUE: [[2, 3, 4, 2, 3, 4, 2, 3, 4, 2, 3, 4, 2, 3, 4, 2, 3, 4, 2, 3, 4], [90, 382, 172204, 46723, 31857, 45344, 64282, 37252, 26639, 64842, 37923, 23851, 67468, 38275, 21452, 79752, 41044, 22451, 90615, 44003, 22832]]

  [Single] Query 348: {'ECR': True, 'Pass': False} (13.41s)
Checkpoint saved: 348 queries processed

============================================================
Batch 175/1536: Processing 2 queries
============================================================
Predictions:  ['573480', '364000 120490']
Answer:  ['573480', '243510']
Predictions:  ['573480']
Answer:  ['573480']
  [Batch] Query 349: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (14.61s avg)
Predictions:  ['364000 120490']
Answer:  ['243510']
  [Batch] Query 350: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (14.61s avg)
Checkpoint saved: 350 queries processed

============================================================
Batch 176/1536: Processing 2 queries
============================================================
Predictions:  ['english and maths']
Answer:  ['sum of participation english and maths']
Predictions:  ['english and maths']
Answer:  ['sum of participation english and maths']
  [Batch] Query 351: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (12.29s avg)
  Warning: Large text input (63462 tokens)
Processing batches:  11%|█▏        | 176/1536 [42:37<7:44:37, 20.50s/it]Processing batches:  12%|█▏        | 177/1536 [42:45<6:20:21, 16.79s/it]Processing batches:  12%|█▏        | 178/1536 [42:53<5:22:02, 14.23s/it]  [Single] Query 352: {'GPT_EVAL': 'N/A (no eval_api_key)'} (21.43s)
Checkpoint saved: 352 queries processed

============================================================
Batch 177/1536: Processing 2 queries
============================================================
Predictions:  ['13 28', '201011 910200']
Answer:  ['13 28', '200910 952400']
Predictions:  ['13 28']
Answer:  ['13 28']
  [Batch] Query 353: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (3.95s avg)
Predictions:  ['201011 910200']
Answer:  ['200910 952400']
  [Batch] Query 354: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.95s avg)
Checkpoint saved: 354 queries processed

============================================================
Batch 178/1536: Processing 2 queries
============================================================
Predictions:  ['200809 200910', '14384000']
Answer:  ['201112 13', '14404200']
Predictions:  ['200809 200910']
Answer:  ['201112 13']
  [Batch] Query 355: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.00s avg)
Predictions:  ['14384000']
Answer:  ['14404200']
  [Batch] Query 356: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.00s avg)
Checkpoint saved: 356 queries processed

============================================================
Batch 179/1536: Processing 2 queries
============================================================
Predictions:  ['level 1']
Answer:  ['of which level 1']
Predictions:  ['level 1']
Answer:  ['of which level 1']
  [Batch] Query 358: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (3.35s avg)
  Warning: Large text input (23343 tokens)
Processing batches:  12%|█▏        | 179/1536 [43:00<4:34:45, 12.15s/it]Processing batches:  12%|█▏        | 180/1536 [43:26<6:04:21, 16.12s/it]Processing batches:  12%|█▏        | 181/1536 [43:54<7:27:38, 19.82s/it]Processing batches:  12%|█▏        | 182/1536 [44:22<8:21:13, 22.21s/it]Traceback (most recent call last):
  File "/export/home/pan/4xin/RealHiTBENCH-Qwen3-VL/inference/inference_qwen3vl_local_a100.py", line 1186, in gen_solution_batch
    batch_results = process_batch_queries(
  File "/export/home/pan/4xin/RealHiTBENCH-Qwen3-VL/inference/inference_qwen3vl_local_a100.py", line 955, in process_batch_queries
    batch_responses = get_batch_final_answers_local(
  File "/export/home/pan/4xin/RealHiTBENCH-Qwen3-VL/inference/inference_qwen3vl_local_a100.py", line 590, in get_batch_final_answers_local
    responses = get_batch_text_response_local(pending_messages, model, processor, opt)
  File "/export/home/pan/4xin/RealHiTBENCH-Qwen3-VL/inference/inference_qwen3vl_local_a100.py", line 533, in get_batch_text_response_local
    generated_ids = base_model.generate(**generate_kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/generation/utils.py", line 2566, in generate
    result = decoding_method(
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/generation/utils.py", line 2786, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/models/qwen3_vl/modeling_qwen3_vl.py", line 1344, in forward
    outputs = self.model(
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/models/qwen3_vl/modeling_qwen3_vl.py", line 1223, in forward
    outputs = self.language_model(
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/models/qwen3_vl/modeling_qwen3_vl.py", line 850, in forward
    layer_outputs = decoder_layer(
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/models/qwen3_vl/modeling_qwen3_vl.py", line 517, in forward
    hidden_states = self.mlp(hidden_states)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/models/qwen3_vl/modeling_qwen3_vl.py", line 472, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 6.20 GiB. GPU 0 has a total capacity of 79.25 GiB of which 4.40 GiB is free. Including non-PyTorch memory, this process has 74.84 GiB memory in use. Of the allocated memory 64.02 GiB is allocated by PyTorch, and 10.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing batches:  12%|█▏        | 183/1536 [45:28<13:17:37, 35.37s/it]  [Single] Query 357: {'GPT_EVAL': 'N/A (no eval_api_key)'} (3.81s)
Checkpoint saved: 358 queries processed

============================================================
Batch 180/1536: Processing 2 queries
============================================================
Predictions:  ['level 2', '1344570 1224210 1156780 1046240']
Answer:  ['of which level 1', '13823080']
Predictions:  ['level 2']
Answer:  ['of which level 1']
  [Batch] Query 359: {'F1': 33.33, 'EM': 0.0, 'ROUGE-L': 33.33, 'SacreBLEU': 0.0} (12.58s avg)
Predictions:  ['1344570 1224210 1156780 1046240']
Answer:  ['13823080']
  [Batch] Query 360: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (12.58s avg)
Checkpoint saved: 360 queries processed

============================================================
Batch 181/1536: Processing 2 queries
============================================================
Predictions:  ['201415', '518800 438100']
Answer:  ['201415', 'yes']
Predictions:  ['201415']
Answer:  ['201415']
  [Batch] Query 361: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (14.10s avg)
Predictions:  ['518800 438100']
Answer:  ['yes']
  [Batch] Query 362: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (14.10s avg)
Checkpoint saved: 362 queries processed

============================================================
Batch 182/1536: Processing 2 queries
============================================================
Predictions:  ['strong positive correlation 10', '11842500']
Answer:  ['strong positive correlation 10', '1192950']
Predictions:  ['strong positive correlation 10']
Answer:  ['strong positive correlation 10']
  [Batch] Query 363: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (13.77s avg)
Predictions:  ['11842500']
Answer:  ['1192950']
  [Batch] Query 364: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (13.77s avg)
Checkpoint saved: 364 queries processed

============================================================
Batch 183/1536: Processing 2 queries
============================================================
Error processing batch 183: CUDA out of memory. Tried to allocate 6.20 GiB. GPU 0 has a total capacity of 79.25 GiB of which 4.40 GiB is free. Including non-PyTorch memory, this process has 74.84 GiB memory in use. Of the allocated memory 64.02 GiB is allocated by PyTorch, and 10.33 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

============================================================
Batch 184/1536: Processing 2 queries
============================================================
Predictions:  ['general fe college incl tertiary sixth form college special colleges other public funded schools private sector public funded unknown']
Answer:  ['6']
Predictions:  ['general fe college incl tertiary sixth form college special colleges other public funded schools private sector public funded unknown']
Answer:  ['6']
  [Batch] Query 367: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (49.58s avg)
  Warning: Large text input (135511 tokens)
Processing batches:  12%|█▏        | 184/1536 [47:27<22:39:25, 60.33s/it]Code: import pandas as pd
import matplotlib.pyplot as plt

# Load the data
df = pd.read_excel('/data/pan/4xin/datasets/RealHiTBench/tables/education-table06.xlsx')

# Extract the relevant data for "of which English" across all provider types
english_data = df.iloc[2, 1:9].tolist()  # Row 2, columns 1 to 8 (General FE College incl Tertiary to Private Sector Public Funded)
english_data.extend(df.iloc[2, 9:17].tolist())  # Row 2, columns 9 to 16 (General FE College incl Tertiary to Private Sector Public Funded in Achievement)

# Create a bar chart
plt.figure(figsize=(10, 6))
plt.bar(df.columns[1:9], english_data, color='blue', label='Participation')
plt.xlabel('Provider Type')
plt.ylabel('Number of Learners')
plt.title('Total Participation for "of which English" Across All Provider Types')
plt.xticks(rotation=45)
plt.legend()

# Show the plot
plt.tight_layout()
plt.show()

Python Error: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (8,) and arg 1 with shape (16,).
  [Single] Query 368: {'ECR': False, 'Pass': False} (68.85s)
Checkpoint saved: 366 queries processed

============================================================
Batch 185/1536: Processing 2 queries
============================================================
Predictions:  ['702230 30150 39820']
Answer:  ['772200']
Predictions:  ['702230 30150 39820']
Answer:  ['772200']
  [Batch] Query 370: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.20s avg)
  Warning: Large text input (135510 tokens)
Processing batches:  12%|█▏        | 185/1536 [48:27<22:36:28, 60.24s/it]Processing batches:  12%|█▏        | 186/1536 [48:31<16:21:24, 43.62s/it]Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/data/pan/4xin/datasets/RealHiTBench/tables/education-table06.xlsx')
participation_english = df.iloc[2, 1:9].tolist()
achievement_english = df.iloc[2, 9:17].tolist()
plt.scatter(participation_english, achievement_english)
plt.xlabel('Participation (of which English)')
plt.ylabel('Achievement (of which English)')
plt.title('Relationship between Participation and Achievement for "of which English"')
plt.show()

Python Error: could not convert string to float: '-'
  [Single] Query 369: {'ECR': False, 'Pass': False} (56.72s)
Checkpoint saved: 368 queries processed

============================================================
Batch 186/1536: Processing 2 queries
============================================================
Predictions:  ['164210', 'general fe college incl tertiary']
Answer:  ['164210', 'general fe college incl tertiary']
Predictions:  ['164210']
Answer:  ['164210']
  [Batch] Query 371: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (2.29s avg)
Predictions:  ['general fe college incl tertiary']
Answer:  ['general fe college incl tertiary']
  [Batch] Query 372: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (2.29s avg)
Checkpoint saved: 370 queries processed

============================================================
Batch 187/1536: Processing 2 queries
============================================================
Predictions:  ['1297800']
Answer:  ['1297800']
Predictions:  ['1297800']
Answer:  ['1297800']
  [Batch] Query 374: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (2.47s avg)
  Warning: Large text input (15362 tokens)
Processing batches:  12%|█▏        | 187/1536 [48:45<12:59:13, 34.66s/it]Processing batches:  12%|█▏        | 188/1536 [48:50<9:37:57, 25.73s/it]   [Single] Query 373: {'GPT_EVAL': 'N/A (no eval_api_key)'} (11.15s)
Checkpoint saved: 372 queries processed

============================================================
Batch 188/1536: Processing 2 queries
============================================================
Predictions:  ['860200', 'general fe college incl tertiary 462770']
Answer:  ['860200', 'general fe college incl tertiary 462770']
Predictions:  ['860200']
Answer:  ['860200']
  [Batch] Query 375: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (2.32s avg)
Predictions:  ['general fe college incl tertiary 462770']
Answer:  ['general fe college incl tertiary 462770']
  [Batch] Query 376: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (2.32s avg)
Checkpoint saved: 374 queries processed

============================================================
Batch 189/1536: Processing 2 queries
============================================================
Predictions:  ['572740 492230']
Answer:  ['572740']
Predictions:  ['572740 492230']
Answer:  ['572740']
  [Batch] Query 377: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (2.63s avg)
  Warning: Large text input (14438 tokens)
Processing batches:  12%|█▏        | 189/1536 [49:04<8:15:34, 22.07s/it]Processing batches:  12%|█▏        | 190/1536 [49:09<6:21:47, 17.02s/it]Processing batches:  12%|█▏        | 191/1536 [49:14<5:00:00, 13.38s/it]  [Single] Query 378: {'GPT_EVAL': 'N/A (no eval_api_key)'} (10.79s)
Checkpoint saved: 376 queries processed

============================================================
Batch 190/1536: Processing 2 queries
============================================================
Predictions:  ['maths 12100', '3822495 3822495']
Answer:  ['maths 2700', '5059195']
Predictions:  ['maths 12100']
Answer:  ['maths 2700']
  [Batch] Query 379: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (2.49s avg)
Predictions:  ['3822495 3822495']
Answer:  ['5059195']
  [Batch] Query 380: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.49s avg)
Checkpoint saved: 378 queries processed

============================================================
Batch 191/1536: Processing 2 queries
============================================================
Predictions:  ['820730 820730', '951100 872800']
Answer:  ['870830', '1823950']
Predictions:  ['820730 820730']
Answer:  ['870830']
  [Batch] Query 381: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.32s avg)
Predictions:  ['951100 872800']
Answer:  ['1823950']
  [Batch] Query 382: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.32s avg)
Checkpoint saved: 380 queries processed

============================================================
Batch 192/1536: Processing 2 queries
============================================================
Predictions:  ['753390']
Answer:  ['753390']
Predictions:  ['753390']
Answer:  ['753390']
  [Batch] Query 383: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (2.14s avg)
  Warning: Large text input (13813 tokens)
Processing batches:  12%|█▎        | 192/1536 [49:25<4:43:11, 12.64s/it]Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/data/pan/4xin/datasets/RealHiTBench/tables/education-table10.xlsx', sheet_name='2009-2010')
participation_english = df.iloc[1:2, 1:9].iloc[0].values
institutions = ['General FE College incl Tertiary', 'Sixth form college', 'Special colleges', 'Other Public Funded', 'Schools', 'Private Sector Public Funded', 'Total']
plt.bar(institutions, participation_english)
plt.title('Total Participation for English across All Institution Types')
plt.xlabel('Institution Type')
plt.ylabel('Participation')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

Python Error: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (7,) and arg 1 with shape (8,).
  [Single] Query 384: {'ECR': False, 'Pass': False} (8.64s)
Checkpoint saved: 382 queries processed

============================================================
Batch 193/1536: Processing 2 queries
============================================================
Predictions:  ['485340 437520']
Answer:  ['922860']
Predictions:  ['485340 437520']
Answer:  ['922860']
  [Batch] Query 386: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.25s avg)
  Warning: Large text input (13819 tokens)
Processing batches:  13%|█▎        | 193/1536 [49:36<4:34:53, 12.28s/it]Processing batches:  13%|█▎        | 194/1536 [49:42<3:53:33, 10.44s/it]Processing batches:  13%|█▎        | 195/1536 [49:51<3:40:44,  9.88s/it]Processing batches:  13%|█▎        | 196/1536 [50:02<3:51:15, 10.35s/it]Processing batches:  13%|█▎        | 197/1536 [50:12<3:48:47, 10.25s/it]Processing batches:  13%|█▎        | 198/1536 [50:24<4:01:40, 10.84s/it]Processing batches:  13%|█▎        | 199/1536 [50:37<4:14:51, 11.44s/it]Processing batches:  13%|█▎        | 200/1536 [50:49<4:17:52, 11.58s/it]Processing batches:  13%|█▎        | 201/1536 [51:00<4:10:34, 11.26s/it]Processing batches:  13%|█▎        | 202/1536 [51:10<4:06:46, 11.10s/it]Processing batches:  13%|█▎        | 203/1536 [51:20<3:56:47, 10.66s/it]Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/data/pan/4xin/datasets/RealHiTBench/tables/education-table10.xlsx', sheet_name='2009-2010')
english_participation = df.iloc[1:5, 1:9].iloc[-1].values
institution_types = df.iloc[0, 1:9].values
plt.figure(figsize=(8, 8))
plt.pie(english_participation, labels=institution_types, autopct='%1.1f%%', startangle=140)
plt.title('Proportion of Total Participation for English by Institution Type')
plt.axis('equal')
plt.show()

OUTPUT VALUE: [0.22, 0.01, 0.01, 0.06, 0.0, 0.12, 0.42, 0.16]

  [Single] Query 385: {'ECR': True, 'Pass': False} (8.06s)
Checkpoint saved: 384 queries processed

============================================================
Batch 194/1536: Processing 2 queries
============================================================
Predictions:  ['560 411040', 'general fe college incl tertiary other public funded']
Answer:  ['853070', 'other public funded']
Predictions:  ['560 411040']
Answer:  ['853070']
  [Batch] Query 387: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.95s avg)
Predictions:  ['general fe college incl tertiary other public funded']
Answer:  ['other public funded']
  [Batch] Query 388: {'F1': 54.55, 'EM': 0.0, 'ROUGE-L': 54.55, 'SacreBLEU': 20.56} (2.95s avg)
Checkpoint saved: 386 queries processed

============================================================
Batch 195/1536: Processing 2 queries
============================================================
Predictions:  ['440750 21530 16620 77150 720 440750', '568']
Answer:  ['994290 private sector public funded', '07']
Predictions:  ['440750 21530 16620 77150 720 440750']
Answer:  ['994290 private sector public funded']
  [Batch] Query 389: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.15s avg)
Predictions:  ['568']
Answer:  ['07']
  [Batch] Query 390: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.15s avg)
Checkpoint saved: 388 queries processed

============================================================
Batch 196/1536: Processing 2 queries
============================================================
Predictions:  ['1119800', 'private sector public funded general fe college incl tertiary other public funded special colleges sixth form college schools']
Answer:  ['1119800', 'general fe college incl tertiary private sector public funded other public funded sixth form college special colleges schools']
Predictions:  ['1119800']
Answer:  ['1119800']
  [Batch] Query 391: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (5.61s avg)
Predictions:  ['private sector public funded general fe college incl tertiary other public funded special colleges sixth form college schools']
Answer:  ['general fe college incl tertiary private sector public funded other public funded sixth form college special colleges schools']
  [Batch] Query 392: {'F1': 100.0, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 49.85} (5.61s avg)
Checkpoint saved: 390 queries processed

============================================================
Batch 197/1536: Processing 2 queries
============================================================
Predictions:  ['23410 23410', '1573']
Answer:  ['23370', '183610']
Predictions:  ['23410 23410']
Answer:  ['23370']
  [Batch] Query 393: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.88s avg)
Predictions:  ['1573']
Answer:  ['183610']
  [Batch] Query 394: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.88s avg)
Checkpoint saved: 392 queries processed

============================================================
Batch 198/1536: Processing 2 queries
============================================================
Predictions:  ['28368', '2020 q2']
Answer:  ['28368', 'q2 2019']
Predictions:  ['28368']
Answer:  ['28368']
  [Batch] Query 395: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (5.98s avg)
Predictions:  ['2020 q2']
Answer:  ['q2 2019']
  [Batch] Query 396: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (5.98s avg)
Checkpoint saved: 394 queries processed

============================================================
Batch 199/1536: Processing 2 queries
============================================================
Predictions:  ['2019 2018', '59465']
Answer:  ['2018', '17745']
Predictions:  ['2019 2018']
Answer:  ['2018']
  [Batch] Query 397: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (6.29s avg)
Predictions:  ['59465']
Answer:  ['17745']
  [Batch] Query 398: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (6.29s avg)
Checkpoint saved: 396 queries processed

============================================================
Batch 200/1536: Processing 2 queries
============================================================
Predictions:  ['strong positive correlation 10', '115010']
Answer:  ['strong positive correlation 10', '115010']
Predictions:  ['strong positive correlation 10']
Answer:  ['strong positive correlation 10']
  [Batch] Query 399: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (5.83s avg)
Predictions:  ['115010']
Answer:  ['115010']
  [Batch] Query 400: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (5.83s avg)
Checkpoint saved: 398 queries processed

============================================================
Batch 201/1536: Processing 2 queries
============================================================
Predictions:  ['2019 1683', 'increasing']
Answer:  ['2019 4085', 'increasing']
Predictions:  ['2019 1683']
Answer:  ['2019 4085']
  [Batch] Query 401: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (5.13s avg)
Predictions:  ['increasing']
Answer:  ['increasing']
  [Batch] Query 402: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (5.13s avg)
Checkpoint saved: 400 queries processed

============================================================
Batch 202/1536: Processing 2 queries
============================================================
Predictions:  ['decreasing trend decreasing trend', 'strong positive correlation 10']
Answer:  ['decreasing', 'strong positive correlation 10']
Predictions:  ['decreasing trend decreasing trend']
Answer:  ['decreasing']
  [Batch] Query 403: {'F1': 40.0, 'EM': 0.0, 'ROUGE-L': 40.0, 'SacreBLEU': 15.97} (5.23s avg)
Predictions:  ['strong positive correlation 10']
Answer:  ['strong positive correlation 10']
  [Batch] Query 404: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (5.23s avg)
Checkpoint saved: 402 queries processed

============================================================
Batch 203/1536: Processing 2 queries
============================================================
Predictions:  ['257', 'q1 q2 q3 q4']
Answer:  ['257', '3']
Predictions:  ['257']
Answer:  ['257']
  [Batch] Query 405: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (4.69s avg)
Predictions:  ['q1 q2 q3 q4']
Answer:  ['3']
  [Batch] Query 406: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.69s avg)
Checkpoint saved: 404 queries processed

============================================================
Batch 204/1536: Processing 2 queries
============================================================
Predictions:  ['q1 q2']
Answer:  ['q2']
Predictions:  ['q1 q2']
Answer:  ['q2']
  [Batch] Query 407: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (4.20s avg)
  Warning: Large text input (27271 tokens)
Processing batches:  13%|█▎        | 204/1536 [51:35<4:22:07, 11.81s/it]Processing batches:  13%|█▎        | 205/1536 [51:43<3:58:00, 10.73s/it]Processing batches:  13%|█▎        | 206/1536 [51:50<3:32:06,  9.57s/it]  [Single] Query 408: {'GPT_EVAL': 'N/A (no eval_api_key)'} (10.16s)
Checkpoint saved: 406 queries processed

============================================================
Batch 205/1536: Processing 2 queries
============================================================
Predictions:  ['weak positive correlation 06', '15849']
Answer:  ['strong negative correlation 09', '15849']
Predictions:  ['weak positive correlation 06']
Answer:  ['strong negative correlation 09']
  [Batch] Query 409: {'F1': 25.0, 'EM': 0.0, 'ROUGE-L': 25.0, 'SacreBLEU': 15.97} (3.98s avg)
Predictions:  ['15849']
Answer:  ['15849']
  [Batch] Query 410: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (3.98s avg)
Checkpoint saved: 408 queries processed

============================================================
Batch 206/1536: Processing 2 queries
============================================================
Predictions:  ['2014 4783 3902 881', '4596 4391 3703']
Answer:  ['2014 881', '38491']
Predictions:  ['2014 4783 3902 881']
Answer:  ['2014 881']
  [Batch] Query 411: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 19.0} (3.30s avg)
Predictions:  ['4596 4391 3703']
Answer:  ['38491']
  [Batch] Query 412: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.30s avg)
Checkpoint saved: 410 queries processed

============================================================
Batch 207/1536: Processing 2 queries
============================================================
Predictions:  ['1722']
Answer:  ['8719']
Predictions:  ['1722']
Answer:  ['8719']
  [Batch] Query 414: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (5.42s avg)
  Warning: Large text input (18436 tokens)
Processing batches:  13%|█▎        | 207/1536 [52:11<4:52:53, 13.22s/it]Processing batches:  14%|█▎        | 208/1536 [52:27<5:10:12, 14.02s/it]Processing batches:  14%|█▎        | 209/1536 [52:41<5:05:04, 13.79s/it]Processing batches:  14%|█▎        | 210/1536 [52:50<4:39:23, 12.64s/it]Processing batches:  14%|█▎        | 211/1536 [53:02<4:29:30, 12.20s/it]Processing batches:  14%|█▍        | 212/1536 [53:07<3:42:22, 10.08s/it]Processing batches:  14%|█▍        | 213/1536 [53:12<3:10:48,  8.65s/it]Processing batches:  14%|█▍        | 214/1536 [53:36<4:51:33, 13.23s/it]Processing batches:  14%|█▍        | 215/1536 [53:44<4:13:45, 11.53s/it]Processing batches:  14%|█▍        | 216/1536 [54:00<4:46:35, 13.03s/it]Traceback (most recent call last):
  File "/export/home/pan/4xin/RealHiTBENCH-Qwen3-VL/inference/inference_qwen3vl_local_a100.py", line 1186, in gen_solution_batch
    batch_results = process_batch_queries(
  File "/export/home/pan/4xin/RealHiTBENCH-Qwen3-VL/inference/inference_qwen3vl_local_a100.py", line 955, in process_batch_queries
    batch_responses = get_batch_final_answers_local(
  File "/export/home/pan/4xin/RealHiTBENCH-Qwen3-VL/inference/inference_qwen3vl_local_a100.py", line 590, in get_batch_final_answers_local
    responses = get_batch_text_response_local(pending_messages, model, processor, opt)
  File "/export/home/pan/4xin/RealHiTBENCH-Qwen3-VL/inference/inference_qwen3vl_local_a100.py", line 533, in get_batch_text_response_local
    generated_ids = base_model.generate(**generate_kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/generation/utils.py", line 2566, in generate
    result = decoding_method(
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/generation/utils.py", line 2786, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/models/qwen3_vl/modeling_qwen3_vl.py", line 1344, in forward
    outputs = self.model(
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/models/qwen3_vl/modeling_qwen3_vl.py", line 1223, in forward
    outputs = self.language_model(
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/models/qwen3_vl/modeling_qwen3_vl.py", line 850, in forward
    layer_outputs = decoder_layer(
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/models/qwen3_vl/modeling_qwen3_vl.py", line 517, in forward
    hidden_states = self.mlp(hidden_states)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/models/qwen3_vl/modeling_qwen3_vl.py", line 472, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.10 GiB. GPU 0 has a total capacity of 79.25 GiB of which 4.68 GiB is free. Including non-PyTorch memory, this process has 74.57 GiB memory in use. Of the allocated memory 57.24 GiB is allocated by PyTorch, and 16.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing batches:  14%|█▍        | 217/1536 [54:51<8:59:00, 24.52s/it]Code: import pandas as pd
import matplotlib.pyplot as plt

# Load the data from the HTML table
df = pd.read_html('/data/pan/4xin/datasets/RealHiTBench/tables/economy-table08.xlsx', header=0)[0]

# Filter data for years 2012 to 2016
df_filtered = df[df['Year'].isin(['2012', '2013', '2014', '2015', '2016'])]

# Convert 'Year' to numeric and 'Quarter' to numeric for sorting
df_filtered['Year'] = pd.to_numeric(df_filtered['Year'])
df_filtered['Quarter'] = pd.to_numeric(df_filtered['Quarter'])

# Sort by Year and Quarter
df_filtered = df_filtered.sort_values(['Year', 'Quarter'])

# Extract the 'Total bankruptcies' column
total_bankruptcies = df_filtered['Total bankruptcies [note 8]']

# Create a line chart
plt.figure(figsize=(10, 6))
plt.plot(df_filtered['Year'], total_bankruptcies, marker='o', linestyle='-', color='blue')
plt.title('Trend of Total Bankruptcies from 2012 to 2016')
plt.xlabel('Year')
plt.ylabel('Total Bankruptcies')
plt.grid(True)
plt.xticks(df_filtered['Year'].unique())
plt.show()

Python Error: 'utf-8' codec can't decode byte 0x87 in position 10: invalid start byte
  [Single] Query 413: {'ECR': False, 'Pass': False} (16.20s)
Checkpoint saved: 412 queries processed

============================================================
Batch 208/1536: Processing 2 queries
============================================================
Predictions:  ['2018', '2016 2017 2018 2019 2020 2021 2022']
Answer:  ['2019', '2013 2014 2015 2016 2017 2018 2019 2020 2021']
Predictions:  ['2018']
Answer:  ['2019']
  [Batch] Query 415: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (7.81s avg)
Predictions:  ['2016 2017 2018 2019 2020 2021 2022']
Answer:  ['2013 2014 2015 2016 2017 2018 2019 2020 2021']
  [Batch] Query 416: {'F1': 75.0, 'EM': 0.0, 'ROUGE-L': 75.0, 'SacreBLEU': 60.8} (7.81s avg)
Checkpoint saved: 414 queries processed

============================================================
Batch 209/1536: Processing 2 queries
============================================================
Predictions:  ['149775 149775', 'strong positive correlation 10']
Answer:  ['187479', 'strong positive correlation 10']
Predictions:  ['149775 149775']
Answer:  ['187479']
  [Batch] Query 417: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (6.31s avg)
Predictions:  ['strong positive correlation 10']
Answer:  ['strong positive correlation 10']
  [Batch] Query 418: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (6.31s avg)
Checkpoint saved: 416 queries processed

============================================================
Batch 210/1536: Processing 2 queries
============================================================
Predictions:  ['6451', 'q4 2012 173']
Answer:  ['6451', 'q1 2013 845']
Predictions:  ['6451']
Answer:  ['6451']
  [Batch] Query 419: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (4.85s avg)
Predictions:  ['q4 2012 173']
Answer:  ['q1 2013 845']
  [Batch] Query 420: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.85s avg)
Checkpoint saved: 418 queries processed

============================================================
Batch 211/1536: Processing 2 queries
============================================================
Predictions:  ['no', '8686 8075 7719 7296']
Answer:  ['yes', '7944']
Predictions:  ['no']
Answer:  ['yes']
  [Batch] Query 421: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (5.47s avg)
Predictions:  ['8686 8075 7719 7296']
Answer:  ['7944']
  [Batch] Query 422: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (5.47s avg)
Checkpoint saved: 420 queries processed

============================================================
Batch 212/1536: Processing 2 queries
============================================================
Predictions:  ['greece spain', 'austria 07']
Answer:  ['11', 'austria 04']
Predictions:  ['greece spain']
Answer:  ['11']
  [Batch] Query 423: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.42s avg)
Predictions:  ['austria 07']
Answer:  ['austria 04']
  [Batch] Query 424: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (2.42s avg)
Checkpoint saved: 422 queries processed

============================================================
Batch 213/1536: Processing 2 queries
============================================================
Predictions:  ['35', 'weak positive correlation 05']
Answer:  ['48', 'weak positive correlation 07']
Predictions:  ['35']
Answer:  ['48']
  [Batch] Query 425: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.54s avg)
Predictions:  ['weak positive correlation 05']
Answer:  ['weak positive correlation 07']
  [Batch] Query 426: {'F1': 75.0, 'EM': 0.0, 'ROUGE-L': 75.0, 'SacreBLEU': 59.46} (2.54s avg)
Checkpoint saved: 424 queries processed

============================================================
Batch 214/1536: Processing 2 queries
============================================================
Predictions:  ['50 56 48 70 108 45 78 42 177 32 74 93 84 72 115 50 34 40 64 53 53 91 43 54 60 61 80 34 30 27 25 29 25 18 17 27', '3173375 3302667']
Answer:  ['65', '64760422']
Predictions:  ['50 56 48 70 108 45 78 42 177 32 74 93 84 72 115 50 34 40 64 53 53 91 43 54 60 61 80 34 30 27 25 29 25 18 17 27']
Answer:  ['65']
  [Batch] Query 427: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (11.83s avg)
Predictions:  ['3173375 3302667']
Answer:  ['64760422']
  [Batch] Query 428: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (11.83s avg)
Checkpoint saved: 426 queries processed

============================================================
Batch 215/1536: Processing 2 queries
============================================================
Predictions:  ['creative', 'north east']
Answer:  ['creative', 'north east']
Predictions:  ['creative']
Answer:  ['creative']
  [Batch] Query 429: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (3.65s avg)
Predictions:  ['north east']
Answer:  ['north east']
  [Batch] Query 430: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (3.65s avg)
Checkpoint saved: 428 queries processed

============================================================
Batch 216/1536: Processing 2 queries
============================================================
Predictions:  ['1899271 3302667 24020716 930128 4349957 10882020 2561668 2775420 2182638 53708763', 'weak positive correlation 05']
Answer:  ['1066132471', 'strong positive correlation 10']
Predictions:  ['1899271 3302667 24020716 930128 4349957 10882020 2561668 2775420 2182638 53708763']
Answer:  ['1066132471']
  [Batch] Query 431: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (8.12s avg)
Predictions:  ['weak positive correlation 05']
Answer:  ['strong positive correlation 10']
  [Batch] Query 432: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 31.95} (8.12s avg)
Checkpoint saved: 430 queries processed

============================================================
Batch 217/1536: Processing 2 queries
============================================================
Error processing batch 217: CUDA out of memory. Tried to allocate 5.10 GiB. GPU 0 has a total capacity of 79.25 GiB of which 4.68 GiB is free. Including non-PyTorch memory, this process has 74.57 GiB memory in use. Of the allocated memory 57.24 GiB is allocated by PyTorch, and 16.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

============================================================
Batch 218/1536: Processing 2 queries
============================================================
Predictions:  ['london']
Answer:  ['england']
Predictions:  ['london']
Answer:  ['england']
  [Batch] Query 435: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (32.39s avg)
  Warning: Large text input (111425 tokens)
Processing batches:  14%|█▍        | 218/1536 [56:43<18:34:17, 50.73s/it]Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/data/pan/4xin/datasets/RealHiTBench/tables/economy-table13.xlsx')
region_columns = ['East Midlands', 'East of England']
sectors = ['Creative', 'Heritage', 'MLA', 'Sport']
total_births = df[region_columns + ['Sector']].copy()
total_births = total_births[total_births['Sector'].isin(sectors)]
total_births = total_births.groupby(['Sector'])['Births'].sum().reset_index()
total_births['Region'] = 'Combined'
total_births = total_births.append(df[df['Region'].isin(region_columns)].groupby('Sector')['Births'].sum().reset_index())
total_births['Region'] = 'East Midlands'
total_births = total_births.append(df[df['Region'].isin(region_columns)].groupby('Sector')['Births'].sum().reset_index())
total_births['Region'] = 'East of England'
total_births = total_births.groupby(['Region', 'Sector']).sum().reset_index()
total_births = total_births.pivot(index='Sector', columns='Region', values='Births').reset_index()
total_births = total_births.melt(id_vars='Sector', var_name='Region', value_name='Births')
total_births = total_births[total_births['Region'].isin(region_columns)]
total_births = total_births.groupby(['Sector', 'Region']).sum().reset_index()
total_births = total_births.pivot(index='Sector', columns='Region', values='Births').reset_index()
total_births['Total'] = total_births['East Midlands'] + total_births['East of England']
total_births = total_births[['Sector', 'Total']]
total_births = total_births.sort_values('Total', ascending=False)
plt.figure(figsize=(10, 6))
plt.bar(total_births['Sector'], total_births['Total'], color='skyblue')
plt.title('Total Number of New Business Births Across All Sectors in East Midlands and East of England')
plt.xlabel('Sector')
plt.ylabel('Total Births')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

Python Error: "None of [Index(['East Midlands', 'East of England', 'Sector'], dtype='object')] are in the [columns]"
  [Single] Query 436: {'ECR': False, 'Pass': False} (79.34s)
Checkpoint saved: 432 queries processed

============================================================
Batch 219/1536: Processing 2 queries
============================================================
Predictions:  ['software computer games electronic publishing']
Answer:  ['craft']
Predictions:  ['software computer games electronic publishing']
Answer:  ['craft']
  [Batch] Query 438: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.97s avg)
  Warning: Large text input (111422 tokens)
Processing batches:  14%|█▍        | 219/1536 [57:41<19:16:49, 52.70s/it]Processing batches:  14%|█▍        | 220/1536 [57:47<14:09:32, 38.73s/it]Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/data/pan/4xin/datasets/RealHiTBench/tables/economy-table13.xlsx')
regions = ['East Midlands', 'East of England', 'London', 'North East', 'North West', 'South East', 'South West', 'West Midlands', 'Yorkshire and the Humber', 'England']
sector = 'Creative'
data = df[df['Sector'] == sector].iloc[:, 1:].T.reset_index()
data.columns = ['Region', 'Births', '2009 Stock']
data = data.set_index('Region')
data = data.drop('Sector', axis=1)
plt.figure(figsize=(10, 6))
plt.plot(data.index, data['Births'], marker='o', linestyle='-', color='blue')
plt.title('Trends in the Number of New Business Births in the Creative Sector Across All Regions')
plt.xlabel('Region')
plt.ylabel('Number of New Business Births')
plt.xticks(rotation=45)
plt.grid(True)
plt.tight_layout()
plt.show()

Python Error: 'Sector'
  [Single] Query 437: {'ECR': False, 'Pass': False} (54.19s)
Checkpoint saved: 434 queries processed

============================================================
Batch 220/1536: Processing 2 queries
============================================================
Predictions:  ['137848 138208', 'growing']
Answer:  ['2006', 'growing']
Predictions:  ['137848 138208']
Answer:  ['2006']
  [Batch] Query 439: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.92s avg)
Predictions:  ['growing']
Answer:  ['growing']
  [Batch] Query 440: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (2.92s avg)
Checkpoint saved: 436 queries processed

============================================================
Batch 221/1536: Processing 2 queries
============================================================
Predictions:  ['854061 1334197 4586670 426074 1417274 2572853 1378479 1058143 1098349 14877264']
Answer:  ['2960336']
Predictions:  ['854061 1334197 4586670 426074 1417274 2572853 1378479 1058143 1098349 14877264']
Answer:  ['2960336']
  [Batch] Query 441: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (8.97s avg)
  Warning: Large text input (17180 tokens)
Processing batches:  14%|█▍        | 221/1536 [58:08<12:11:57, 33.40s/it]Processing batches:  14%|█▍        | 222/1536 [58:18<9:36:43, 26.33s/it] Processing batches:  15%|█▍        | 223/1536 [58:26<7:40:26, 21.04s/it]Processing batches:  15%|█▍        | 224/1536 [58:34<6:12:52, 17.05s/it]Processing batches:  15%|█▍        | 225/1536 [58:38<4:43:45, 12.99s/it]Processing batches:  15%|█▍        | 226/1536 [58:41<3:44:39, 10.29s/it]Processing batches:  15%|█▍        | 227/1536 [58:45<2:58:31,  8.18s/it]Processing batches:  15%|█▍        | 228/1536 [58:57<3:23:02,  9.31s/it]  [Single] Query 442: {'GPT_EVAL': 'N/A (no eval_api_key)'} (11.83s)
Checkpoint saved: 438 queries processed

============================================================
Batch 222/1536: Processing 2 queries
============================================================
Predictions:  ['south west', '200708 200506']
Answer:  ['south east', '200708']
Predictions:  ['south west']
Answer:  ['south east']
  [Batch] Query 443: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (4.78s avg)
Predictions:  ['200708 200506']
Answer:  ['200708']
  [Batch] Query 444: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (4.78s avg)
Checkpoint saved: 440 queries processed

============================================================
Batch 223/1536: Processing 2 queries
============================================================
Predictions:  ['north east', 'increase 889']
Answer:  ['none', 'increasing']
Predictions:  ['north east']
Answer:  ['none']
  [Batch] Query 445: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.20s avg)
Predictions:  ['increase 889']
Answer:  ['increasing']
  [Batch] Query 446: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.20s avg)
Checkpoint saved: 442 queries processed

============================================================
Batch 224/1536: Processing 2 queries
============================================================
Predictions:  ['strong positive correlation 10', 'london']
Answer:  ['strong positive correlation 10', 'south east']
Predictions:  ['strong positive correlation 10']
Answer:  ['strong positive correlation 10']
  [Batch] Query 447: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (3.72s avg)
Predictions:  ['london']
Answer:  ['south east']
  [Batch] Query 448: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.72s avg)
Checkpoint saved: 444 queries processed

============================================================
Batch 225/1536: Processing 2 queries
============================================================
Predictions:  ['200708', 'increasing trend']
Answer:  ['200708', 'increase']
Predictions:  ['200708']
Answer:  ['200708']
  [Batch] Query 449: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.63s avg)
Predictions:  ['increasing trend']
Answer:  ['increase']
  [Batch] Query 450: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.63s avg)
Checkpoint saved: 446 queries processed

============================================================
Batch 226/1536: Processing 2 queries
============================================================
Predictions:  ['increasing trend', 'strong positive correlation 10']
Answer:  ['increasing', 'strong positive correlation 08']
Predictions:  ['increasing trend']
Answer:  ['increasing']
  [Batch] Query 451: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (1.87s avg)
Predictions:  ['strong positive correlation 10']
Answer:  ['strong positive correlation 08']
  [Batch] Query 452: {'F1': 75.0, 'EM': 0.0, 'ROUGE-L': 75.0, 'SacreBLEU': 59.46} (1.87s avg)
Checkpoint saved: 448 queries processed

============================================================
Batch 227/1536: Processing 2 queries
============================================================
Predictions:  ['78 92', 'east midlands']
Answer:  ['78 92', 'west midlands']
Predictions:  ['78 92']
Answer:  ['78 92']
  [Batch] Query 453: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.51s avg)
Predictions:  ['east midlands']
Answer:  ['west midlands']
  [Batch] Query 454: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (1.51s avg)
Checkpoint saved: 450 queries processed

============================================================
Batch 228/1536: Processing 2 queries
============================================================
Predictions:  ['east midlands london south west west midlands yorkshire and humber', '440 440 440 440 440 440 440 440 440 440 440 440 440 440 440 440 440 440 440 440']
Answer:  ['2', '476']
Predictions:  ['east midlands london south west west midlands yorkshire and humber']
Answer:  ['2']
  [Batch] Query 455: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (5.85s avg)
Predictions:  ['440 440 440 440 440 440 440 440 440 440 440 440 440 440 440 440 440 440 440 440']
Answer:  ['476']
  [Batch] Query 456: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (5.85s avg)
Checkpoint saved: 452 queries processed

============================================================
Batch 229/1536: Processing 2 queries
============================================================
Predictions:  ['1000000 1000']
Answer:  ['no']
Predictions:  ['1000000 1000']
Answer:  ['no']
  [Batch] Query 458: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.74s avg)
  Warning: Large text input (10120 tokens)
Processing batches:  15%|█▍        | 229/1536 [59:10<3:49:10, 10.52s/it]  [Single] Query 457: {'GPT_EVAL': 'N/A (no eval_api_key)'} (8.47s)
Checkpoint saved: 454 queries processed

============================================================
Batch 230/1536: Processing 2 queries
============================================================
Predictions:  ['mega']
Answer:  ['mega']
Predictions:  ['mega']
Answer:  ['mega']
  [Batch] Query 459: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (4.01s avg)
  Warning: Large text input (27876 tokens)
Processing batches:  15%|█▍        | 230/1536 [59:26<4:25:48, 12.21s/it]Processing batches:  15%|█▌        | 231/1536 [59:38<4:24:27, 12.16s/it]Processing batches:  15%|█▌        | 232/1536 [59:50<4:23:27, 12.12s/it]Processing batches:  15%|█▌        | 233/1536 [1:00:00<4:05:32, 11.31s/it]Processing batches:  15%|█▌        | 234/1536 [1:00:32<6:24:40, 17.73s/it]Processing batches:  15%|█▌        | 235/1536 [1:01:19<9:33:50, 26.46s/it]Processing batches:  15%|█▌        | 236/1536 [1:02:06<11:44:14, 32.50s/it]  [Single] Query 460: {'GPT_EVAL': 'N/A (no eval_api_key)'} (12.02s)
Checkpoint saved: 456 queries processed

============================================================
Batch 231/1536: Processing 2 queries
============================================================
Predictions:  ['303', '198 206']
Answer:  ['303', 'decrease']
Predictions:  ['303']
Answer:  ['303']
  [Batch] Query 461: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (5.89s avg)
Predictions:  ['198 206']
Answer:  ['decrease']
  [Batch] Query 462: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (5.89s avg)
Checkpoint saved: 458 queries processed

============================================================
Batch 232/1536: Processing 2 queries
============================================================
Predictions:  ['6470 1879', '37']
Answer:  ['8349', '37']
Predictions:  ['6470 1879']
Answer:  ['8349']
  [Batch] Query 463: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (5.89s avg)
Predictions:  ['37']
Answer:  ['37']
  [Batch] Query 464: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (5.89s avg)
Checkpoint saved: 460 queries processed

============================================================
Batch 233/1536: Processing 2 queries
============================================================
Predictions:  ['19031', '31']
Answer:  ['19031', '31']
Predictions:  ['19031']
Answer:  ['19031']
  [Batch] Query 465: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (4.58s avg)
Predictions:  ['31']
Answer:  ['31']
  [Batch] Query 466: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (4.58s avg)
Checkpoint saved: 462 queries processed

============================================================
Batch 234/1536: Processing 2 queries
============================================================
Predictions:  ['natural gas crude oil', 'white black asian and minority ethnic']
Answer:  ['resource natural gas', 'white']
Predictions:  ['natural gas crude oil']
Answer:  ['resource natural gas']
  [Batch] Query 467: {'F1': 57.14, 'EM': 0.0, 'ROUGE-L': 57.14, 'SacreBLEU': 31.95} (16.02s avg)
Predictions:  ['white black asian and minority ethnic']
Answer:  ['white']
  [Batch] Query 468: {'F1': 28.57, 'EM': 0.0, 'ROUGE-L': 28.57, 'SacreBLEU': 8.12} (16.02s avg)
Checkpoint saved: 464 queries processed

============================================================
Batch 235/1536: Processing 2 queries
============================================================
Predictions:  ['140 230', '15 20']
Answer:  ['80', 'increase']
Predictions:  ['140 230']
Answer:  ['80']
  [Batch] Query 469: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (23.30s avg)
Predictions:  ['15 20']
Answer:  ['increase']
  [Batch] Query 470: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (23.30s avg)
Checkpoint saved: 466 queries processed

============================================================
Batch 236/1536: Processing 2 queries
============================================================
Predictions:  ['10 10', 'decrease decrease']
Answer:  ['15', 'increasing trend']
Predictions:  ['10 10']
Answer:  ['15']
  [Batch] Query 471: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (23.17s avg)
Predictions:  ['decrease decrease']
Answer:  ['increasing trend']
  [Batch] Query 472: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (23.17s avg)
Checkpoint saved: 468 queries processed

============================================================
Batch 237/1536: Processing 2 queries
============================================================
Predictions:  ['australia austria']
Answer:  ['australia']
Predictions:  ['australia austria']
Answer:  ['australia']
  [Batch] Query 474: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (3.27s avg)
  Warning: Large text input (87135 tokens)
Processing batches:  15%|█▌        | 237/1536 [1:02:36<11:25:44, 31.67s/it]Processing batches:  15%|█▌        | 238/1536 [1:02:42<8:41:50, 24.12s/it]   [Single] Query 473: {'GPT_EVAL': 'N/A (no eval_api_key)'} (26.33s)
Checkpoint saved: 470 queries processed

============================================================
Batch 238/1536: Processing 2 queries
============================================================
Predictions:  ['no', '9901719 11887063']
Answer:  ['no', '2019179']
Predictions:  ['no']
Answer:  ['no']
  [Batch] Query 475: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (3.12s avg)
Predictions:  ['9901719 11887063']
Answer:  ['2019179']
  [Batch] Query 476: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.12s avg)
Checkpoint saved: 472 queries processed

============================================================
Batch 239/1536: Processing 2 queries
============================================================
Predictions:  ['5109132 5466175']
Answer:  ['91290']
Predictions:  ['5109132 5466175']
Answer:  ['91290']
  [Batch] Query 478: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.87s avg)
  Warning: Large text input (20362 tokens)
Processing batches:  16%|█▌        | 239/1536 [1:02:53<7:18:52, 20.30s/it]Processing batches:  16%|█▌        | 240/1536 [1:02:59<5:44:35, 15.95s/it]Processing batches:  16%|█▌        | 241/1536 [1:03:05<4:36:05, 12.79s/it]  [Single] Query 477: {'GPT_EVAL': 'N/A (no eval_api_key)'} (7.39s)
Checkpoint saved: 474 queries processed

============================================================
Batch 240/1536: Processing 2 queries
============================================================
Predictions:  ['220727 204824', 'no']
Answer:  ['319727', 'no']
Predictions:  ['220727 204824']
Answer:  ['319727']
  [Batch] Query 479: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.78s avg)
Predictions:  ['no']
Answer:  ['no']
  [Batch] Query 480: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (2.78s avg)
Checkpoint saved: 476 queries processed

============================================================
Batch 241/1536: Processing 2 queries
============================================================
Predictions:  ['1315870', '1198930']
Answer:  ['1340179', '1186698']
Predictions:  ['1315870']
Answer:  ['1340179']
  [Batch] Query 481: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.58s avg)
Predictions:  ['1198930']
Answer:  ['1186698']
  [Batch] Query 482: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.58s avg)
Checkpoint saved: 478 queries processed

============================================================
Batch 242/1536: Processing 2 queries
============================================================
Predictions:  ['türkiye32663']
Answer:  ['united states 70405']
Predictions:  ['türkiye32663']
Answer:  ['united states 70405']
  [Batch] Query 484: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.23s avg)
  Warning: Large text input (16976 tokens)
Processing batches:  16%|█▌        | 242/1536 [1:03:13<4:05:57, 11.40s/it]Processing batches:  16%|█▌        | 243/1536 [1:03:24<4:04:11, 11.33s/it]  [Single] Query 483: {'GPT_EVAL': 'N/A (no eval_api_key)'} (3.81s)
Checkpoint saved: 480 queries processed

============================================================
Batch 243/1536: Processing 2 queries
============================================================
Predictions:  ['1724 1822 1860 1965 2055', 'germany sweden']
Answer:  ['9426', 'australia luxembourg netherlands austria chile czechia estonia finland france germany hungary ireland korea latvia lithuania portugal spain türkiye croatia']
Predictions:  ['1724 1822 1860 1965 2055']
Answer:  ['9426']
  [Batch] Query 485: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (5.45s avg)
Predictions:  ['germany sweden']
Answer:  ['australia luxembourg netherlands austria chile czechia estonia finland france germany hungary ireland korea latvia lithuania portugal spain türkiye croatia']
  [Batch] Query 486: {'F1': 9.52, 'EM': 0.0, 'ROUGE-L': 9.09, 'SacreBLEU': 0.0} (5.45s avg)
Checkpoint saved: 482 queries processed

============================================================
Batch 244/1536: Processing 2 queries
============================================================
Predictions:  ['20770 1485']
Answer:  ['19976 1633']
Predictions:  ['20770 1485']
Answer:  ['19976 1633']
  [Batch] Query 488: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.87s avg)
  Warning: Large text input (27336 tokens)
Processing batches:  16%|█▌        | 244/1536 [1:03:41<4:42:57, 13.14s/it]Processing batches:  16%|█▌        | 245/1536 [1:03:52<4:28:34, 12.48s/it]Processing batches:  16%|█▌        | 246/1536 [1:04:02<4:13:15, 11.78s/it]Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/data/pan/4xin/datasets/RealHiTBench/tables/health-table04.xlsx')
australia_icu = df[df['Reference area'] == 'Australia']['ICU beds'].dropna().reset_index(drop=True)
years = ['2015', '2016', '2017', '2018', '2019', '2020', '2021', '2022', '2023']
plt.plot(years, australia_icu, marker='o')
plt.title('Trend of ICU Beds in Australia from 2015 to 2023')
plt.xlabel('Year')
plt.ylabel('ICU Beds')
plt.grid(True)
plt.show()

Python Error: 'Reference area'
  [Single] Query 487: {'ECR': False, 'Pass': False} (12.36s)
Checkpoint saved: 484 queries processed

============================================================
Batch 245/1536: Processing 2 queries
============================================================
Predictions:  ['united states', 'united states germany france']
Answer:  ['united states', 'united kingdom chile austria']
Predictions:  ['united states']
Answer:  ['united states']
  [Batch] Query 489: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (5.35s avg)
Predictions:  ['united states germany france']
Answer:  ['united kingdom chile austria']
  [Batch] Query 490: {'F1': 25.0, 'EM': 0.0, 'ROUGE-L': 25.0, 'SacreBLEU': 15.97} (5.35s avg)
Checkpoint saved: 486 queries processed

============================================================
Batch 246/1536: Processing 2 queries
============================================================
Predictions:  ['australia 2170', 'ireland']
Answer:  ['australia 18611', 'italy']
Predictions:  ['australia 2170']
Answer:  ['australia 18611']
  [Batch] Query 491: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (4.95s avg)
Predictions:  ['ireland']
Answer:  ['italy']
  [Batch] Query 492: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.95s avg)
Checkpoint saved: 488 queries processed

============================================================
Batch 247/1536: Processing 2 queries
============================================================
Predictions:  ['415665 415665']
Answer:  ['382405']
Predictions:  ['415665 415665']
Answer:  ['382405']
  [Batch] Query 493: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (5.89s avg)
  Warning: Large text input (32895 tokens)
Processing batches:  16%|█▌        | 247/1536 [1:04:19<4:45:16, 13.28s/it]Processing batches:  16%|█▌        | 248/1536 [1:04:25<3:53:23, 10.87s/it]Processing batches:  16%|█▌        | 249/1536 [1:10:24<41:16:41, 115.46s/it]Processing batches:  16%|█▋        | 250/1536 [1:10:33<29:50:39, 83.55s/it] Processing batches:  16%|█▋        | 251/1536 [1:10:42<21:47:52, 61.07s/it]Processing batches:  16%|█▋        | 252/1536 [1:11:04<17:39:11, 49.49s/it]Processing batches:  16%|█▋        | 253/1536 [1:11:22<14:17:11, 40.09s/it]Processing batches:  17%|█▋        | 254/1536 [1:11:27<10:28:59, 29.44s/it]  [Single] Query 494: {'GPT_EVAL': 'N/A (no eval_api_key)'} (10.76s)
Checkpoint saved: 490 queries processed

============================================================
Batch 248/1536: Processing 2 queries
============================================================
Predictions:  ['09', 'japan']
Answer:  ['09', 'belgium']
Predictions:  ['09']
Answer:  ['09']
  [Batch] Query 495: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (2.50s avg)
Predictions:  ['japan']
Answer:  ['belgium']
  [Batch] Query 496: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.50s avg)
Checkpoint saved: 492 queries processed

============================================================
Batch 249/1536: Processing 2 queries
============================================================
Predictions:  ['yes', '08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08']
Answer:  ['yes', '09']
Predictions:  ['yes']
Answer:  ['yes']
  [Batch] Query 497: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (179.63s avg)
Predictions:  ['08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08 08']
Answer:  ['09']
  [Batch] Query 498: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (179.63s avg)
Checkpoint saved: 494 queries processed

============================================================
Batch 250/1536: Processing 2 queries
============================================================
Predictions:  ['13 increasing trend', '28270240026']
Answer:  ['14', '28270240026']
Predictions:  ['13 increasing trend']
Answer:  ['14']
  [Batch] Query 499: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.41s avg)
Predictions:  ['28270240026']
Answer:  ['28270240026']
  [Batch] Query 500: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (4.41s avg)
Checkpoint saved: 496 queries processed

============================================================
Batch 251/1536: Processing 2 queries
============================================================
Predictions:  ['germany', 'germany belgium']
Answer:  ['germany', 'germany']
Predictions:  ['germany']
Answer:  ['germany']
  [Batch] Query 501: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (4.19s avg)
Predictions:  ['germany belgium']
Answer:  ['germany']
  [Batch] Query 502: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (4.19s avg)
Checkpoint saved: 498 queries processed

============================================================
Batch 252/1536: Processing 2 queries
============================================================
Predictions:  ['60', '3510']
Answer:  ['60', '3510']
Predictions:  ['60']
Answer:  ['60']
  [Batch] Query 503: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (11.12s avg)
Predictions:  ['3510']
Answer:  ['3510']
  [Batch] Query 504: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (11.12s avg)
Checkpoint saved: 500 queries processed

============================================================
Batch 253/1536: Processing 2 queries
============================================================
Predictions:  ['10', '192617']
Answer:  ['10', '192617']
Predictions:  ['10']
Answer:  ['10']
  [Batch] Query 505: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (8.94s avg)
Predictions:  ['192617']
Answer:  ['192617']
  [Batch] Query 506: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (8.94s avg)
Checkpoint saved: 502 queries processed

============================================================
Batch 254/1536: Processing 2 queries
============================================================
Predictions:  ['male intermediate government', 'female male']
Answer:  ['female', 'no female']
Predictions:  ['male intermediate government']
Answer:  ['female']
  [Batch] Query 507: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.17s avg)
Predictions:  ['female male']
Answer:  ['no female']
  [Batch] Query 508: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (2.17s avg)
Checkpoint saved: 504 queries processed

============================================================
Batch 255/1536: Processing 2 queries
============================================================
Predictions:  ['2248275']
Answer:  ['3747245']
Predictions:  ['2248275']
Answer:  ['3747245']
  [Batch] Query 509: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.60s avg)
  Warning: Large text input (15719 tokens)
Processing batches:  17%|█▋        | 255/1536 [1:11:39<8:36:43, 24.20s/it] Processing batches:  17%|█▋        | 256/1536 [1:11:53<7:32:28, 21.21s/it]Processing batches:  17%|█▋        | 257/1536 [1:12:08<6:52:30, 19.35s/it]Processing batches:  17%|█▋        | 258/1536 [1:12:19<5:58:43, 16.84s/it]Processing batches:  17%|█▋        | 259/1536 [1:12:22<4:32:03, 12.78s/it]Processing batches:  17%|█▋        | 260/1536 [1:12:26<3:34:10, 10.07s/it]  [Single] Query 510: {'GPT_EVAL': 'N/A (no eval_api_key)'} (9.26s)
Checkpoint saved: 506 queries processed

============================================================
Batch 256/1536: Processing 2 queries
============================================================
Predictions:  ['30 sep 16 31 mar 14', '220 180']
Answer:  ['sep 30 2016', '400']
Predictions:  ['30 sep 16 31 mar 14']
Answer:  ['sep 30 2016']
  [Batch] Query 511: {'F1': 44.44, 'EM': 0.0, 'ROUGE-L': 22.22, 'SacreBLEU': 9.65} (6.99s avg)
Predictions:  ['220 180']
Answer:  ['400']
  [Batch] Query 512: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (6.99s avg)
Checkpoint saved: 508 queries processed

============================================================
Batch 257/1536: Processing 2 queries
============================================================
Predictions:  ['march 31 2016 march 31 2013', '68 increasing trend']
Answer:  ['31 mar 16', '68']
Predictions:  ['march 31 2016 march 31 2013']
Answer:  ['31 mar 16']
  [Batch] Query 513: {'F1': 22.22, 'EM': 0.0, 'ROUGE-L': 22.22, 'SacreBLEU': 8.12} (7.38s avg)
Predictions:  ['68 increasing trend']
Answer:  ['68']
  [Batch] Query 514: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (7.38s avg)
Checkpoint saved: 510 queries processed

============================================================
Batch 258/1536: Processing 2 queries
============================================================
Predictions:  ['no correlation 00', 'solid wall insulation']
Answer:  ['less', 'solar pv']
Predictions:  ['no correlation 00']
Answer:  ['less']
  [Batch] Query 515: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (5.37s avg)
Predictions:  ['solid wall insulation']
Answer:  ['solar pv']
  [Batch] Query 516: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (5.37s avg)
Checkpoint saved: 512 queries processed

============================================================
Batch 259/1536: Processing 2 queries
============================================================
Predictions:  ['condensing boiler solid wall insulation', 'loft insulation 26']
Answer:  ['solid wall insulation', 'condensing boiler 26']
Predictions:  ['condensing boiler solid wall insulation']
Answer:  ['solid wall insulation']
  [Batch] Query 517: {'F1': 75.0, 'EM': 0.0, 'ROUGE-L': 75.0, 'SacreBLEU': 39.76} (1.53s avg)
Predictions:  ['loft insulation 26']
Answer:  ['condensing boiler 26']
  [Batch] Query 518: {'F1': 33.33, 'EM': 0.0, 'ROUGE-L': 33.33, 'SacreBLEU': 0.0} (1.53s avg)
Checkpoint saved: 514 queries processed

============================================================
Batch 260/1536: Processing 2 queries
============================================================
Predictions:  ['400 1200 1000 300 300', '400 1300 1100 400 300']
Answer:  ['640', '700']
Predictions:  ['400 1200 1000 300 300']
Answer:  ['640']
  [Batch] Query 519: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.75s avg)
Predictions:  ['400 1300 1100 400 300']
Answer:  ['700']
  [Batch] Query 520: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.75s avg)
Checkpoint saved: 516 queries processed

============================================================
Batch 261/1536: Processing 2 queries
============================================================
Predictions:  ['condensing boiler solid wall insulation']
Answer:  ['solid wall insulation']
Predictions:  ['condensing boiler solid wall insulation']
Answer:  ['solid wall insulation']
  [Batch] Query 521: {'F1': 75.0, 'EM': 0.0, 'ROUGE-L': 75.0, 'SacreBLEU': 39.76} (1.72s avg)
  Warning: Large text input (9732 tokens)
Processing batches:  17%|█▋        | 261/1536 [1:12:38<3:43:09, 10.50s/it]Processing batches:  17%|█▋        | 262/1536 [1:12:45<3:25:09,  9.66s/it]Processing batches:  17%|█▋        | 263/1536 [1:12:52<3:07:27,  8.84s/it]Processing batches:  17%|█▋        | 264/1536 [1:13:00<2:57:13,  8.36s/it]Processing batches:  17%|█▋        | 265/1536 [1:13:07<2:49:07,  7.98s/it]  [Single] Query 522: {'GPT_EVAL': 'N/A (no eval_api_key)'} (9.66s)
Checkpoint saved: 518 queries processed

============================================================
Batch 262/1536: Processing 2 queries
============================================================
Predictions:  ['1451890 1474420', '2019 1663520']
Answer:  ['2926310', '2020 1861550']
Predictions:  ['1451890 1474420']
Answer:  ['2926310']
  [Batch] Query 523: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.73s avg)
Predictions:  ['2019 1663520']
Answer:  ['2020 1861550']
  [Batch] Query 524: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.73s avg)
Checkpoint saved: 520 queries processed

============================================================
Batch 263/1536: Processing 2 queries
============================================================
Predictions:  ['1612160', 'increasing increasing']
Answer:  ['1612160', 'increasing trend']
Predictions:  ['1612160']
Answer:  ['1612160']
  [Batch] Query 525: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (3.33s avg)
Predictions:  ['increasing increasing']
Answer:  ['increasing trend']
  [Batch] Query 526: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (3.33s avg)
Checkpoint saved: 522 queries processed

============================================================
Batch 264/1536: Processing 2 queries
============================================================
Predictions:  ['strong positive correlation 09', '1765110 933440']
Answer:  ['negative impact', '2698550']
Predictions:  ['strong positive correlation 09']
Answer:  ['negative impact']
  [Batch] Query 527: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.50s avg)
Predictions:  ['1765110 933440']
Answer:  ['2698550']
  [Batch] Query 528: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.50s avg)
Checkpoint saved: 524 queries processed

============================================================
Batch 265/1536: Processing 2 queries
============================================================
Predictions:  ['2007 6120', '2009 2008 2007 2006 2005']
Answer:  ['2007 6720', '2009 2008 2006 2007 2005']
Predictions:  ['2007 6120']
Answer:  ['2007 6720']
  [Batch] Query 529: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (3.43s avg)
Predictions:  ['2009 2008 2007 2006 2005']
Answer:  ['2009 2008 2006 2007 2005']
  [Batch] Query 530: {'F1': 100.0, 'EM': 0.0, 'ROUGE-L': 80.0, 'SacreBLEU': 26.86} (3.43s avg)
Checkpoint saved: 526 queries processed

============================================================
Batch 266/1536: Processing 2 queries
============================================================
  Warning: Large text input (17020 tokens)
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/data/pan/4xin/datasets/RealHiTBench/tables/environment-table07.xlsx')
years = df['Year'][0:5]
dwellings_50_or_less = df['50 or less'][0:5]
plt.plot(years, dwellings_50_or_less, marker='o')
plt.title('Trend in the Number of Dwellings in the “50 or less” Category from 2005 to 2009')
plt.xlabel('Year')
plt.ylabel('Number of Dwellings')
plt.xticks(years)
plt.grid(True)
plt.show()

OUTPUT VALUE: [[365760, 411120, 417840, 422810, 425230]]

  [Single] Query 531: {'ECR': True, 'Pass': True} (8.95s)
  Warning: Large text input (17033 tokens)
Processing batches:  17%|█▋        | 266/1536 [1:13:26<4:02:31, 11.46s/it]Processing batches:  17%|█▋        | 267/1536 [1:13:33<3:31:17,  9.99s/it]Processing batches:  17%|█▋        | 268/1536 [1:13:43<3:33:14, 10.09s/it]Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel("/data/pan/4xin/datasets/RealHiTBench/tables/environment-table07.xlsx")
data_2009 = df[df['Year'] == 2009][['50 or less', '51 to 100', '101 to 150']]
data_2009 = data_2009.dropna().iloc[0]
labels = data_2009.index
sizes = data_2009.values
plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140)
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
plt.title('Percentage Distribution of Dwellings (2009)')
plt.show()

OUTPUT VALUE: [0.14, 0.57, 0.3]

  [Single] Query 532: {'ECR': True, 'Pass': False} (10.60s)
Checkpoint saved: 528 queries processed

============================================================
Batch 267/1536: Processing 2 queries
============================================================
Predictions:  ['2022 9416770', '301030 345650']
Answer:  ['2020 9893110', '44620']
Predictions:  ['2022 9416770']
Answer:  ['2020 9893110']
  [Batch] Query 533: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.16s avg)
Predictions:  ['301030 345650']
Answer:  ['44620']
  [Batch] Query 534: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.16s avg)
Checkpoint saved: 530 queries processed

============================================================
Batch 268/1536: Processing 2 queries
============================================================
Predictions:  ['2005 10370', '13455200 14021500 15265900 14371000 13787200']
Answer:  ['2005 10370', '1395876']
Predictions:  ['2005 10370']
Answer:  ['2005 10370']
  [Batch] Query 535: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (5.04s avg)
Predictions:  ['13455200 14021500 15265900 14371000 13787200']
Answer:  ['1395876']
  [Batch] Query 536: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (5.04s avg)
Checkpoint saved: 532 queries processed

============================================================
Batch 269/1536: Processing 2 queries
============================================================
Predictions:  ['1970 63']
Answer:  ['1983 65']
Predictions:  ['1970 63']
Answer:  ['1983 65']
  [Batch] Query 538: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.44s avg)
  Warning: Large text input (19247 tokens)
Processing batches:  18%|█▊        | 269/1536 [1:13:57<3:56:52, 11.22s/it]Processing batches:  18%|█▊        | 270/1536 [1:14:20<5:14:27, 14.90s/it]Processing batches:  18%|█▊        | 271/1536 [1:14:27<4:22:38, 12.46s/it]Processing batches:  18%|█▊        | 272/1536 [1:14:31<3:28:46,  9.91s/it]Processing batches:  18%|█▊        | 273/1536 [1:14:36<2:53:56,  8.26s/it]  [Single] Query 537: {'GPT_EVAL': 'N/A (no eval_api_key)'} (10.28s)
Checkpoint saved: 534 queries processed

============================================================
Batch 270/1536: Processing 2 queries
============================================================
Predictions:  ['197019711972197319741975197619771978197919801981198219831984198519861987198819891990199119921993199419951996199719981999200020012002200320042005200620072008', '1973 1972 1971 1970']
Answer:  ['6', '1970']
Predictions:  ['197019711972197319741975197619771978197919801981198219831984198519861987198819891990199119921993199419951996199719981999200020012002200320042005200620072008']
Answer:  ['6']
  [Batch] Query 539: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (11.63s avg)
Predictions:  ['1973 1972 1971 1970']
Answer:  ['1970']
  [Batch] Query 540: {'F1': 40.0, 'EM': 0.0, 'ROUGE-L': 40.0, 'SacreBLEU': 15.97} (11.63s avg)
Checkpoint saved: 536 queries processed

============================================================
Batch 271/1536: Processing 2 queries
============================================================
Predictions:  ['decreasing trend 63', 'strong positive correlation 10']
Answer:  ['decreasing trend', 'strong positive correlation 09']
Predictions:  ['decreasing trend 63']
Answer:  ['decreasing trend']
  [Batch] Query 541: {'F1': 80.0, 'EM': 0.0, 'ROUGE-L': 80.0, 'SacreBLEU': 0.0} (3.25s avg)
Predictions:  ['strong positive correlation 10']
Answer:  ['strong positive correlation 09']
  [Batch] Query 542: {'F1': 75.0, 'EM': 0.0, 'ROUGE-L': 75.0, 'SacreBLEU': 59.46} (3.25s avg)
Checkpoint saved: 538 queries processed

============================================================
Batch 272/1536: Processing 2 queries
============================================================
Predictions:  ['publishing', 'video film photography']
Answer:  ['publishing', 'video film photography']
Predictions:  ['publishing']
Answer:  ['publishing']
  [Batch] Query 543: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.86s avg)
Predictions:  ['video film photography']
Answer:  ['video film photography']
  [Batch] Query 544: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.86s avg)
Checkpoint saved: 540 queries processed

============================================================
Batch 273/1536: Processing 2 queries
============================================================
Predictions:  ['art antiques advertising', 'north west']
Answer:  ['advertising', 'north east']
Predictions:  ['art antiques advertising']
Answer:  ['advertising']
  [Batch] Query 545: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (2.08s avg)
Predictions:  ['north west']
Answer:  ['north east']
  [Batch] Query 546: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (2.08s avg)
Checkpoint saved: 542 queries processed

============================================================
Batch 274/1536: Processing 2 queries
============================================================
Predictions:  ['12950']
Answer:  ['25900']
Predictions:  ['12950']
Answer:  ['25900']
  [Batch] Query 548: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.33s avg)
  Warning: Large text input (14750 tokens)
Processing batches:  18%|█▊        | 274/1536 [1:14:54<3:59:42, 11.40s/it]Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/data/pan/4xin/datasets/RealHiTBench/tables/employment-table30.xlsx', sheet_name='Avg Emp - Creative')
regions = ['North East', 'North West', 'Yorkshire and the Humber', 'East Midlands', 'West Midlands', 'East of England', 'London', 'South East', 'South West', 'England']
subsectors = ['Advertising', 'Architecture']
years = [2005, 2009]
data = []
for region in regions:
for subsector in subsectors:
row_data = []
for year in years:
for col in df.columns:
if col.startswith(region) and col.endswith(str(year)) and subsector in col:
row_data.append(df[col][df['Sub-sector'] == subsector].iloc[0])
data.append(row_data)
df_plot = pd.DataFrame(data, columns=['Advertising_2005', 'Advertising_2009', 'Architecture_2005', 'Architecture_2009'], index=regions)
df_plot.plot(kind='line', marker='o')
plt.title('Employment Trend in Advertising and Architecture Sub-sectors (2005-2009)')
plt.xlabel('Region')
plt.ylabel('Employment')
plt.xticks(rotation=45)
plt.legend(['Advertising', 'Architecture'])
plt.tight_layout()
plt.show()

Python Error: expected an indented block after 'for' statement on line 10 (<string>, line 11)
  [Single] Query 547: {'ECR': False, 'Pass': False} (16.25s)
Checkpoint saved: 544 queries processed

============================================================
Batch 275/1536: Processing 2 queries
============================================================
Predictions:  ['london']
Answer:  ['england']
Predictions:  ['london']
Answer:  ['england']
  [Batch] Query 549: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.06s avg)
  Warning: Large text input (15246 tokens)
Processing batches:  18%|█▊        | 275/1536 [1:15:04<3:46:12, 10.76s/it]  [Single] Query 550: {'GPT_EVAL': 'N/A (no eval_api_key)'} (7.09s)
Checkpoint saved: 546 queries processed

============================================================
Batch 276/1536: Processing 2 queries
============================================================
Predictions:  ['london north east']
Answer:  ['london']
Predictions:  ['london north east']
Answer:  ['london']
  [Batch] Query 552: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (1.54s avg)
  Warning: Large text input (15227 tokens)
Processing batches:  18%|█▊        | 276/1536 [1:15:08<3:06:37,  8.89s/it]Processing batches:  18%|█▊        | 277/1536 [1:15:12<2:32:26,  7.27s/it]  [Single] Query 551: {'GPT_EVAL': 'N/A (no eval_api_key)'} (2.83s)
Checkpoint saved: 548 queries processed

============================================================
Batch 277/1536: Processing 2 queries
============================================================
Predictions:  ['south east south west north east', '3600 3600']
Answer:  ['south east south west north west', '39036']
Predictions:  ['south east south west north east']
Answer:  ['south east south west north west']
  [Batch] Query 553: {'F1': 83.33, 'EM': 0.0, 'ROUGE-L': 83.33, 'SacreBLEU': 75.98} (1.62s avg)
Predictions:  ['3600 3600']
Answer:  ['39036']
  [Batch] Query 554: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.62s avg)
Checkpoint saved: 550 queries processed

============================================================
Batch 278/1536: Processing 2 queries
============================================================
Predictions:  ['17950 increasing trend']
Answer:  ['23025']
Predictions:  ['17950 increasing trend']
Answer:  ['23025']
  [Batch] Query 555: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.88s avg)
  Warning: Large text input (10041 tokens)
Processing batches:  18%|█▊        | 278/1536 [1:15:16<2:16:17,  6.50s/it]Processing batches:  18%|█▊        | 279/1536 [1:15:20<2:01:05,  5.78s/it]Processing batches:  18%|█▊        | 280/1536 [1:15:24<1:49:47,  5.25s/it]Processing batches:  18%|█▊        | 281/1536 [1:15:34<2:16:19,  6.52s/it]Processing batches:  18%|█▊        | 282/1536 [1:15:54<3:40:28, 10.55s/it]  [Single] Query 556: {'GPT_EVAL': 'N/A (no eval_api_key)'} (2.70s)
Checkpoint saved: 552 queries processed

============================================================
Batch 279/1536: Processing 2 queries
============================================================
Predictions:  ['257285', '62656 61305']
Answer:  ['257285', '77']
Predictions:  ['257285']
Answer:  ['257285']
  [Batch] Query 557: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.93s avg)
Predictions:  ['62656 61305']
Answer:  ['77']
  [Batch] Query 558: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.93s avg)
Checkpoint saved: 554 queries processed

============================================================
Batch 280/1536: Processing 2 queries
============================================================
Predictions:  ['decrease', '14877264']
Answer:  ['increase', '29603364']
Predictions:  ['decrease']
Answer:  ['increase']
  [Batch] Query 559: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.87s avg)
Predictions:  ['14877264']
Answer:  ['29603364']
  [Batch] Query 560: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.87s avg)
Checkpoint saved: 556 queries processed

============================================================
Batch 281/1536: Processing 2 queries
============================================================
Predictions:  ['29931 decreasing trend', '4092 4169']
Answer:  ['18262', '4092 4169 77']
Predictions:  ['29931 decreasing trend']
Answer:  ['18262']
  [Batch] Query 561: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.62s avg)
Predictions:  ['4092 4169']
Answer:  ['4092 4169 77']
  [Batch] Query 562: {'F1': 80.0, 'EM': 0.0, 'ROUGE-L': 80.0, 'SacreBLEU': 0.0} (4.62s avg)
Checkpoint saved: 558 queries processed

============================================================
Batch 282/1536: Processing 2 queries
============================================================
Predictions:  ['1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983', '1974 153']
Answer:  ['2', '1974 259']
Predictions:  ['1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983']
Answer:  ['2']
  [Batch] Query 563: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (9.85s avg)
Predictions:  ['1974 153']
Answer:  ['1974 259']
  [Batch] Query 564: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (9.85s avg)
Checkpoint saved: 560 queries processed

============================================================
Batch 283/1536: Processing 2 queries
============================================================
  Warning: Large text input (31996 tokens)
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/data/pan/4xin/datasets/RealHiTBench/tables/environment-table10.xlsx')
years = df['Year'][0:5]
all_fuels = df['All fuels'][0:5]
plt.plot(years, all_fuels, marker='o')
plt.title('Total Energy Demand (All Fuels) from 1970 to 1974')
plt.xlabel('Year')
plt.ylabel('Total Energy Demand (All Fuels)')
plt.xticks(years)
plt.grid(True)
plt.show()

Python Error: 'All fuels'
  [Single] Query 565: {'ECR': False, 'Pass': False} (10.72s)
  Warning: Large text input (31989 tokens)
Processing batches:  18%|█▊        | 283/1536 [1:16:13<4:34:02, 13.12s/it]Processing batches:  18%|█▊        | 284/1536 [1:16:42<6:16:02, 18.02s/it]Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel("/data/pan/4xin/datasets/RealHiTBench/tables/environment-table10.xlsx")
df = df.dropna(subset=['Gas', 'Electric'])
plt.scatter(df['Gas'], df['Electric'])
plt.xlabel('Gas')
plt.ylabel('Electric')
plt.title('Relationship between Gas and Electric Energy Demand')
plt.show()

Python Error: ['Gas']
  [Single] Query 566: {'ECR': False, 'Pass': False} (8.40s)
Checkpoint saved: 562 queries processed

============================================================
Batch 284/1536: Processing 2 queries
============================================================
Predictions:  ['48200 48600', '26400']
Answer:  ['48200 48600', '65200']
Predictions:  ['48200 48600']
Answer:  ['48200 48600']
  [Batch] Query 567: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (14.60s avg)
Predictions:  ['26400']
Answer:  ['65200']
  [Batch] Query 568: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (14.60s avg)
Checkpoint saved: 564 queries processed

============================================================
Batch 285/1536: Processing 2 queries
============================================================
Predictions:  ['north west']
Answer:  ['none']
Predictions:  ['north west']
Answer:  ['none']
  [Batch] Query 569: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (12.86s avg)
  Warning: Large text input (64822 tokens)
Processing batches:  19%|█▊        | 285/1536 [1:17:17<7:59:07, 22.98s/it]  [Single] Query 570: {'GPT_EVAL': 'N/A (no eval_api_key)'} (21.56s)
Checkpoint saved: 566 queries processed

============================================================
Batch 286/1536: Processing 2 queries
============================================================
Predictions:  ['643']
Answer:  ['643']
Predictions:  ['643']
Answer:  ['643']
  [Batch] Query 572: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (7.68s avg)
  Warning: Large text input (64799 tokens)
Processing batches:  19%|█▊        | 286/1536 [1:17:38<7:45:34, 22.35s/it]Processing batches:  19%|█▊        | 287/1536 [1:17:55<7:11:13, 20.72s/it]  [Single] Query 571: {'GPT_EVAL': 'N/A (no eval_api_key)'} (13.06s)
Checkpoint saved: 568 queries processed

============================================================
Batch 287/1536: Processing 2 queries
============================================================
Predictions:  ['building closer relationships safe high quality coordinated care', 'building closer relationships 808']
Answer:  ['building closer relationships', 'clean friendly comfortable place to be 822']
Predictions:  ['building closer relationships safe high quality coordinated care']
Answer:  ['building closer relationships']
  [Batch] Query 573: {'F1': 54.55, 'EM': 0.0, 'ROUGE-L': 54.55, 'SacreBLEU': 20.56} (8.33s avg)
Predictions:  ['building closer relationships 808']
Answer:  ['clean friendly comfortable place to be 822']
  [Batch] Query 574: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (8.33s avg)
Checkpoint saved: 570 queries processed

============================================================
Batch 288/1536: Processing 2 queries
============================================================
Predictions:  ['decreasing trend']
Answer:  ['decreasing trend']
Predictions:  ['decreasing trend']
Answer:  ['decreasing trend']
  [Batch] Query 576: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (7.44s avg)
  Warning: Large text input (43054 tokens)
Processing batches:  19%|█▉        | 288/1536 [1:18:17<7:20:17, 21.17s/it]Processing batches:  19%|█▉        | 289/1536 [1:18:22<5:37:01, 16.22s/it]  [Single] Query 575: {'GPT_EVAL': 'N/A (no eval_api_key)'} (14.65s)
Checkpoint saved: 572 queries processed

============================================================
Batch 289/1536: Processing 2 queries
============================================================
Predictions:  ['building closer relationships access waiting clean friendly comfortable place to be better information more choice safe high quality coordinated care', 'better information more choice safe high quality coordinated care']
Answer:  ['building closer relationships access waiting clean friendly comfortable place to be better information more choice safe high quality coordinated care', 'better information more choice']
Predictions:  ['building closer relationships access waiting clean friendly comfortable place to be better information more choice safe high quality coordinated care']
Answer:  ['building closer relationships access waiting clean friendly comfortable place to be better information more choice safe high quality coordinated care']
  [Batch] Query 577: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (2.21s avg)
Predictions:  ['better information more choice safe high quality coordinated care']
Answer:  ['better information more choice']
  [Batch] Query 578: {'F1': 61.54, 'EM': 0.0, 'ROUGE-L': 61.54, 'SacreBLEU': 29.85} (2.21s avg)
Checkpoint saved: 574 queries processed

============================================================
Batch 290/1536: Processing 2 queries
============================================================
Predictions:  ['access waiting building closer relationships']
Answer:  ['2']
Predictions:  ['access waiting building closer relationships']
Answer:  ['2']
  [Batch] Query 579: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.67s avg)
  Warning: Large text input (9961 tokens)
Processing batches:  19%|█▉        | 290/1536 [1:18:34<5:12:35, 15.05s/it]Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/data/pan/4xin/datasets/RealHiTBench/tables/health-table09.xlsx')
years = ['2007-08', '2008-09', '2009-10', '2010-11', '2011-12', '2012-13']
access_scores = [83.8, 84.9, 85.0, 84.2, 83.8, 84.3]
plt.figure(figsize=(10, 6))
plt.plot(years, access_scores, marker='o', linestyle='-', color='blue')
plt.title('Trend of Scores for "Access & waiting" from 2007-08 to 2012-13')
plt.xlabel('Year')
plt.ylabel('Score')
plt.grid(True)
plt.xticks(years)
plt.show()

Python Error: [Errno 2] No such file or directory: '/data/pan/4xin/datasets/RealHiTBench/tables/health-table09.xlsx'
  [Single] Query 580: {'ECR': False, 'Pass': False} (10.54s)
Checkpoint saved: 576 queries processed

============================================================
Batch 291/1536: Processing 2 queries
============================================================
Predictions:  ['15143']
Answer:  ['15143']
Predictions:  ['15143']
Answer:  ['15143']
  [Batch] Query 582: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (2.35s avg)
  Warning: Large text input (9949 tokens)
Processing batches:  19%|█▉        | 291/1536 [1:18:47<4:57:52, 14.36s/it]Processing batches:  19%|█▉        | 292/1536 [1:18:52<4:00:13, 11.59s/it]Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/data/pan/4xin/datasets/RealHiTBench/tables/health-table09.xlsx')
years = ['2007-08', '2008-09', '2009-10', '2010-11', '2011-12', '2012-13']
categories = df.iloc[4:10, 0].dropna().tolist()
scores_2012_13 = df.iloc[4:10, 15].dropna().tolist()
plt.figure(figsize=(10,6))
plt.bar(categories, scores_2012_13, color='blue')
plt.xlabel('Categories')
plt.ylabel('Scores')
plt.title('Scores of All Categories in the Year 2012-13')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

Python Error: [Errno 2] No such file or directory: '/data/pan/4xin/datasets/RealHiTBench/tables/health-table09.xlsx'
  [Single] Query 581: {'ECR': False, 'Pass': False} (10.25s)
Checkpoint saved: 578 queries processed

============================================================
Batch 292/1536: Processing 2 queries
============================================================
Predictions:  ['main dependants', '11311 14328']
Answer:  ['main', '25639']
Predictions:  ['main dependants']
Answer:  ['main']
  [Batch] Query 583: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (2.44s avg)
Predictions:  ['11311 14328']
Answer:  ['25639']
  [Batch] Query 584: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.44s avg)
Checkpoint saved: 580 queries processed

============================================================
Batch 293/1536: Processing 2 queries
============================================================
Predictions:  ['yes increasing trend']
Answer:  ['increasing trend']
Predictions:  ['yes increasing trend']
Answer:  ['increasing trend']
  [Batch] Query 586: {'F1': 80.0, 'EM': 0.0, 'ROUGE-L': 80.0, 'SacreBLEU': 0.0} (2.26s avg)
  Warning: Large text input (15463 tokens)
Processing batches:  19%|█▉        | 293/1536 [1:19:05<4:10:49, 12.11s/it]Processing batches:  19%|█▉        | 294/1536 [1:19:09<3:19:13,  9.62s/it]  [Single] Query 585: {'GPT_EVAL': 'N/A (no eval_api_key)'} (10.93s)
Checkpoint saved: 582 queries processed

============================================================
Batch 294/1536: Processing 2 queries
============================================================
Predictions:  ['711 724', 'building closer relationships safe highquality coordinated care']
Answer:  ['718', 'access waiting']
Predictions:  ['711 724']
Answer:  ['718']
  [Batch] Query 587: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.79s avg)
Predictions:  ['building closer relationships safe highquality coordinated care']
Answer:  ['access waiting']
  [Batch] Query 588: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.79s avg)
Checkpoint saved: 584 queries processed

============================================================
Batch 295/1536: Processing 2 queries
============================================================
Predictions:  ['access waiting safe high quality coordinated care better information more choice building closer relationships']
Answer:  ['2']
Predictions:  ['access waiting safe high quality coordinated care better information more choice building closer relationships']
Answer:  ['2']
  [Batch] Query 589: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.52s avg)
  Warning: Large text input (11501 tokens)
Processing batches:  19%|█▉        | 295/1536 [1:19:23<3:47:35, 11.00s/it]Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/data/pan/4xin/datasets/RealHiTBench/tables/health-table10.xlsx')
categories = df.iloc[4:8, 0].tolist()
scores_2011_12 = df.iloc[4:8, 5].tolist()
scores_2012_13 = df.iloc[4:8, 7].tolist()
x = categories
y1 = scores_2011_12
y2 = scores_2012_13
plt.bar(x, y1, label='2011-12', alpha=0.7)
plt.bar(x, y2, bottom=y1, label='2012-13', alpha=0.7)
plt.xlabel('Categories')
plt.ylabel('Scores')
plt.title('Comparison of Scores for All Categories in 2011-12 and 2012-13')
plt.legend()
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

Python Error: 'value' must be an instance of str or bytes, not a float
  [Single] Query 590: {'ECR': False, 'Pass': False} (11.57s)
Checkpoint saved: 586 queries processed

============================================================
Batch 296/1536: Processing 2 queries
============================================================
Predictions:  ['building closer relationships better information more choice']
Answer:  ['building closer relationships']
Predictions:  ['building closer relationships better information more choice']
Answer:  ['building closer relationships']
  [Batch] Query 592: {'F1': 60.0, 'EM': 0.0, 'ROUGE-L': 60.0, 'SacreBLEU': 24.45} (4.42s avg)
  Warning: Large text input (11515 tokens)
Processing batches:  19%|█▉        | 296/1536 [1:19:39<4:18:23, 12.50s/it]Processing batches:  19%|█▉        | 297/1536 [1:19:49<3:58:35, 11.55s/it]Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/data/pan/4xin/datasets/RealHiTBench/tables/health-table10.xlsx')
years = ['2011-12', '2012-13']
categories = ['Access & waiting', 'Safe, high quality, coordinated care']
scores = df[df['column0'].isin(categories)].set_index('column0')[[f'column{col}' for col in [5,7]]].T
scores.columns = years
scores = scores.reset_index().rename(columns={'index': 'Category'})
plt.figure(figsize=(10,6))
for category in categories:
score_row = scores[scores['Category'] == category]
plt.plot(years, score_row[years].values[0], marker='o', label=category)
plt.title('Trends in Scores for Access & waiting and Safe, high-quality, coordinated care')
plt.xlabel('Year')
plt.ylabel('Score')
plt.legend()
plt.xticks(years)
plt.grid(True)
plt.show()

Python Error: expected an indented block after 'for' statement on line 12 (<string>, line 13)
  [Single] Query 591: {'ECR': False, 'Pass': False} (11.44s)
Checkpoint saved: 588 queries processed

============================================================
Batch 297/1536: Processing 2 queries
============================================================
Predictions:  ['safe high quality coordinated care building closer relationships', '57']
Answer:  ['safe high quality coordinated care building closer relationships', '59']
Predictions:  ['safe high quality coordinated care building closer relationships']
Answer:  ['safe high quality coordinated care building closer relationships']
  [Batch] Query 593: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (4.55s avg)
Predictions:  ['57']
Answer:  ['59']
  [Batch] Query 594: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.55s avg)
Checkpoint saved: 590 queries processed

============================================================
Batch 298/1536: Processing 2 queries
============================================================
Predictions:  ['715']
Answer:  ['716']
Predictions:  ['715']
Answer:  ['716']
  [Batch] Query 595: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.29s avg)
  Warning: Large text input (27781 tokens)
Processing batches:  19%|█▉        | 298/1536 [1:20:01<4:02:23, 11.75s/it]  [Single] Query 596: {'GPT_EVAL': 'N/A (no eval_api_key)'} (7.77s)
Checkpoint saved: 592 queries processed

============================================================
Batch 299/1536: Processing 2 queries
============================================================
Predictions:  ['78 89']
Answer:  ['09']
Predictions:  ['78 89']
Answer:  ['09']
  [Batch] Query 597: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.01s avg)
  Warning: Large text input (12133 tokens)
Processing batches:  19%|█▉        | 299/1536 [1:20:06<3:23:11,  9.86s/it]  [Single] Query 598: {'GPT_EVAL': 'N/A (no eval_api_key)'} (3.30s)
Checkpoint saved: 594 queries processed

============================================================
Batch 300/1536: Processing 2 queries
============================================================
Predictions:  ['pet spa 2']
Answer:  ['pet spa 2']
Predictions:  ['pet spa 2']
Answer:  ['pet spa 2']
  [Batch] Query 599: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.86s avg)
  Warning: Large text input (12231 tokens)
invalid visualization_answer: import pandas as pd 
 import matplotlib.pyplot as plt 
 df = pd.read_excel('/data/pan/4xin/datasets/RealHiTBench/tables/economy-table50.xlsx')
 amenity_types = df.iloc[0:1, 0].values[0]
 amenity_data = df.iloc[1:, 0].values
 tower_counts = df.iloc[1:, 11].values
 amenity_types = [amenity_types[0]] + [amenity_types[i] for i in range(2, len(amenity_types))]
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if pd.notna(amenity_types[i])]
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != 'Luxury Amenities']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != 'Expected (Must Haves)']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for i in range(len(amenity_types)) if amenity_types[i] != '']
 amenity_types = [amenity_types[i] for
Processing batches:  20%|█▉        | 300/1536 [1:23:32<23:36:17, 68.75s/it]Processing batches:  20%|█▉        | 301/1536 [1:23:37<16:57:22, 49.43s/it]Processing batches:  20%|█▉        | 302/1536 [1:23:40<12:14:44, 35.72s/it]Processing batches:  20%|█▉        | 303/1536 [1:23:45<9:01:02, 26.33s/it] Processing batches:  20%|█▉        | 304/1536 [1:23:51<6:57:49, 20.35s/it]Processing batches:  20%|█▉        | 305/1536 [1:23:56<5:18:56, 15.55s/it]
Code: 

Python Error: expected an indented block after 'if' statement on line 2 (<string>, line 3)
  [Single] Query 600: {'ECR': False, 'Pass': False} (204.19s)
Checkpoint saved: 596 queries processed

============================================================
Batch 301/1536: Processing 2 queries
============================================================
Predictions:  ['tower 1 tower 2 tower 4 tower 6', 'pre heating pump testing internet cable laying fiber tank pump control issue']
Answer:  ['tower 1 tower 2 tower 4 tower 6', 'pre heating pump testing']
Predictions:  ['tower 1 tower 2 tower 4 tower 6']
Answer:  ['tower 1 tower 2 tower 4 tower 6']
  [Batch] Query 601: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (2.04s avg)
Predictions:  ['pre heating pump testing internet cable laying fiber tank pump control issue']
Answer:  ['pre heating pump testing']
  [Batch] Query 602: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 21.2} (2.04s avg)
Checkpoint saved: 598 queries processed

============================================================
Batch 302/1536: Processing 2 queries
============================================================
Predictions:  ['1 hour', '24 oct 24']
Answer:  ['1 hour', '20241024 000000']
Predictions:  ['1 hour']
Answer:  ['1 hour']
  [Batch] Query 603: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.75s avg)
Predictions:  ['24 oct 24']
Answer:  ['20241024 000000']
  [Batch] Query 604: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.75s avg)
Checkpoint saved: 600 queries processed

============================================================
Batch 303/1536: Processing 2 queries
============================================================
Predictions:  ['10', '750 1000']
Answer:  ['13', '05']
Predictions:  ['10']
Answer:  ['13']
  [Batch] Query 605: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.07s avg)
Predictions:  ['750 1000']
Answer:  ['05']
  [Batch] Query 606: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.07s avg)
Checkpoint saved: 602 queries processed

============================================================
Batch 304/1536: Processing 2 queries
============================================================
Predictions:  ['installation of jl1s pre heating pump in jl4 maintenance of club house absorption hot water pump 1 2 maintenance centrifugal chiller no 4 pms', 'admin department']
Answer:  ['installation of jl1s pre heating pump in jl4 maintenance of club house absorption hot water pump 1 2 maintenance centrifugal chiller no 4 pms', 'admin departmentautomation department']
Predictions:  ['installation of jl1s pre heating pump in jl4 maintenance of club house absorption hot water pump 1 2 maintenance centrifugal chiller no 4 pms']
Answer:  ['installation of jl1s pre heating pump in jl4 maintenance of club house absorption hot water pump 1 2 maintenance centrifugal chiller no 4 pms']
  [Batch] Query 607: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (3.07s avg)
Predictions:  ['admin department']
Answer:  ['admin departmentautomation department']
  [Batch] Query 608: {'F1': 80.0, 'EM': 0.0, 'ROUGE-L': 80.0, 'SacreBLEU': 0.0} (3.07s avg)
Checkpoint saved: 604 queries processed

============================================================
Batch 305/1536: Processing 2 queries
============================================================
Predictions:  ['25 oct 24', '5 13']
Answer:  ['25 oct 24', '6']
Predictions:  ['25 oct 24']
Answer:  ['25 oct 24']
  [Batch] Query 609: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (2.04s avg)
Predictions:  ['5 13']
Answer:  ['6']
  [Batch] Query 610: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.04s avg)
Checkpoint saved: 606 queries processed

============================================================
Batch 306/1536: Processing 2 queries
============================================================
Predictions:  ['bayern munich 65']
Answer:  ['bayern munich 1']
Predictions:  ['bayern munich 65']
Answer:  ['bayern munich 1']
  [Batch] Query 612: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (2.52s avg)
  Warning: Large text input (13791 tokens)
Processing batches:  20%|█▉        | 306/1536 [1:24:07<4:55:01, 14.39s/it]Processing batches:  20%|█▉        | 307/1536 [1:24:13<4:01:59, 11.81s/it]Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel("/data/pan/4xin/datasets/RealHiTBench/tables/labor-table02.xlsx")
df = df.dropna(subset=["Expected Time to Complete", "Job Assigning Date"])
df["Expected Time to Complete"] = pd.to_numeric(df["Expected Time to Complete"].str.replace(" days", "").str.replace(" hours", ""))
df["Job Assigning Date"] = pd.to_datetime(df["Job Assigning Date"])
plt.scatter(df["Job Assigning Date"], df["Expected Time to Complete"])
plt.xlabel("Job Assigning Date")
plt.ylabel("Expected Time to Complete")
plt.title("Scatter Plot of Expected Time to Complete vs Job Assigning Date")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

Python Error: ['Expected Time to Complete', 'Job Assigning Date']
  [Single] Query 611: {'ECR': False, 'Pass': False} (9.05s)
Checkpoint saved: 608 queries processed

============================================================
Batch 307/1536: Processing 2 queries
============================================================
Predictions:  ['1 6', '1 2 3']
Answer:  ['1 2', '6']
Predictions:  ['1 6']
Answer:  ['1 2']
  [Batch] Query 613: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (2.77s avg)
Predictions:  ['1 2 3']
Answer:  ['6']
  [Batch] Query 614: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.77s avg)
Checkpoint saved: 610 queries processed

============================================================
Batch 308/1536: Processing 2 queries
============================================================
Predictions:  ['100 48']
Answer:  ['95 53']
Predictions:  ['100 48']
Answer:  ['95 53']
  [Batch] Query 616: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.83s avg)
  Warning: Large text input (17061 tokens)
Processing batches:  20%|██        | 308/1536 [1:24:22<3:42:01, 10.85s/it]Processing batches:  20%|██        | 309/1536 [1:24:25<2:57:04,  8.66s/it]Processing batches:  20%|██        | 310/1536 [1:24:29<2:28:15,  7.26s/it]  [Single] Query 615: {'GPT_EVAL': 'N/A (no eval_api_key)'} (5.63s)
Checkpoint saved: 612 queries processed

============================================================
Batch 309/1536: Processing 2 queries
============================================================
Predictions:  ['arsenal newcastle', '37']
Answer:  ['arsenal newcastle', '43']
Predictions:  ['arsenal newcastle']
Answer:  ['arsenal newcastle']
  [Batch] Query 617: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.65s avg)
Predictions:  ['37']
Answer:  ['43']
  [Batch] Query 618: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.65s avg)
Checkpoint saved: 614 queries processed

============================================================
Batch 310/1536: Processing 2 queries
============================================================
Predictions:  ['away home', 'weak positive correlation 03']
Answer:  ['away', 'negative impact 01']
Predictions:  ['away home']
Answer:  ['away']
  [Batch] Query 619: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (1.87s avg)
Predictions:  ['weak positive correlation 03']
Answer:  ['negative impact 01']
  [Batch] Query 620: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.87s avg)
Checkpoint saved: 616 queries processed

============================================================
Batch 311/1536: Processing 2 queries
============================================================
Predictions:  ['30 122']
Answer:  ['152']
Predictions:  ['30 122']
Answer:  ['152']
  [Batch] Query 622: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.83s avg)
  Warning: Large text input (12555 tokens)
Processing batches:  20%|██        | 311/1536 [1:24:39<2:41:27,  7.91s/it]Processing batches:  20%|██        | 312/1536 [1:24:41<2:09:55,  6.37s/it]Processing batches:  20%|██        | 313/1536 [1:24:45<1:50:21,  5.41s/it]Processing batches:  20%|██        | 314/1536 [1:24:47<1:33:22,  4.58s/it]Processing batches:  21%|██        | 315/1536 [1:24:50<1:20:34,  3.96s/it]Processing batches:  21%|██        | 316/1536 [1:24:57<1:42:52,  5.06s/it]Processing batches:  21%|██        | 317/1536 [1:25:00<1:27:28,  4.31s/it]Processing batches:  21%|██        | 318/1536 [1:25:03<1:19:21,  3.91s/it]Processing batches:  21%|██        | 319/1536 [1:25:06<1:12:32,  3.58s/it]Processing batches:  21%|██        | 320/1536 [1:25:09<1:07:51,  3.35s/it]Processing batches:  21%|██        | 321/1536 [1:25:11<1:03:29,  3.14s/it]Processing batches:  21%|██        | 322/1536 [1:25:14<1:00:32,  2.99s/it]Processing batches:  21%|██        | 323/1536 [1:25:17<1:04:31,  3.19s/it]Processing batches:  21%|██        | 324/1536 [1:25:21<1:09:06,  3.42s/it]  [Single] Query 621: {'GPT_EVAL': 'N/A (no eval_api_key)'} (7.47s)
Checkpoint saved: 618 queries processed

============================================================
Batch 312/1536: Processing 2 queries
============================================================
Predictions:  ['butter m eggs', 'chop sticks 00']
Answer:  ['eggs', 'butter t 00']
Predictions:  ['butter m eggs']
Answer:  ['eggs']
  [Batch] Query 623: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (1.26s avg)
Predictions:  ['chop sticks 00']
Answer:  ['butter t 00']
  [Batch] Query 624: {'F1': 33.33, 'EM': 0.0, 'ROUGE-L': 33.33, 'SacreBLEU': 0.0} (1.26s avg)
Checkpoint saved: 620 queries processed

============================================================
Batch 313/1536: Processing 2 queries
============================================================
Predictions:  ['125']
Answer:  ['134']
Predictions:  ['125']
Answer:  ['134']
  [Batch] Query 625: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.37s avg)
  [Single] Query 626: {'GPT_EVAL': 'N/A (no eval_api_key)'} (1.68s)
Checkpoint saved: 622 queries processed

============================================================
Batch 314/1536: Processing 2 queries
============================================================
Predictions:  ['number of focus point effective pixels', 'parameter body sensor image boosted optics focus screen']
Answer:  ['max resolution', 'boosted']
Predictions:  ['number of focus point effective pixels']
Answer:  ['max resolution']
  [Batch] Query 627: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.20s avg)
Predictions:  ['parameter body sensor image boosted optics focus screen']
Answer:  ['boosted']
  [Batch] Query 628: {'F1': 22.22, 'EM': 0.0, 'ROUGE-L': 22.22, 'SacreBLEU': 5.52} (1.20s avg)
Checkpoint saved: 624 queries processed

============================================================
Batch 315/1536: Processing 2 queries
============================================================
Predictions:  ['magnesium magnesium', '4480 1856']
Answer:  ['yes', '24092672']
Predictions:  ['magnesium magnesium']
Answer:  ['yes']
  [Batch] Query 629: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.12s avg)
Predictions:  ['4480 1856']
Answer:  ['24092672']
  [Batch] Query 630: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.12s avg)
Checkpoint saved: 626 queries processed

============================================================
Batch 316/1536: Processing 2 queries
============================================================
Predictions:  ['a7 a7c a7iii a7riii a7siii']
Answer:  ['5']
Predictions:  ['a7 a7c a7iii a7riii a7siii']
Answer:  ['5']
  [Batch] Query 632: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.80s avg)
  [Single] Query 631: {'GPT_EVAL': 'N/A (no eval_api_key)'} (5.69s)
Checkpoint saved: 628 queries processed

============================================================
Batch 317/1536: Processing 2 queries
============================================================
Predictions:  ['a7c a7riii a7siii', 'minimum maximum wb presets image stabilization']
Answer:  ['a7c', 'minimum maximum wb presets image stabilization']
Predictions:  ['a7c a7riii a7siii']
Answer:  ['a7c']
  [Batch] Query 633: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (1.14s avg)
Predictions:  ['minimum maximum wb presets image stabilization']
Answer:  ['minimum maximum wb presets image stabilization']
  [Batch] Query 634: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (1.14s avg)
Checkpoint saved: 630 queries processed

============================================================
Batch 318/1536: Processing 2 queries
============================================================
Predictions:  ['a7riii a7 a7iii a7c a7siii', 'yes 6000 x 4000']
Answer:  ['a7riii a7 a7c a7iii a7siii', 'yes 6000 x 4000']
Predictions:  ['a7riii a7 a7iii a7c a7siii']
Answer:  ['a7riii a7 a7c a7iii a7siii']
  [Batch] Query 635: {'F1': 100.0, 'EM': 0.0, 'ROUGE-L': 80.0, 'SacreBLEU': 26.86} (1.36s avg)
Predictions:  ['yes 6000 x 4000']
Answer:  ['yes 6000 x 4000']
  [Batch] Query 636: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (1.36s avg)
Checkpoint saved: 632 queries processed

============================================================
Batch 319/1536: Processing 2 queries
============================================================
Predictions:  ['r6 r5 m5 m50 m50 ii', 'max resolution image ratio effective pixels sensor size']
Answer:  ['r6 r5 m5 m50 m50 ii', 'max resolution image ratio effective pixels sensor size']
Predictions:  ['r6 r5 m5 m50 m50 ii']
Answer:  ['r6 r5 m5 m50 m50 ii']
  [Batch] Query 637: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (1.27s avg)
Predictions:  ['max resolution image ratio effective pixels sensor size']
Answer:  ['max resolution image ratio effective pixels sensor size']
  [Batch] Query 638: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (1.27s avg)
Checkpoint saved: 634 queries processed

============================================================
Batch 320/1536: Processing 2 queries
============================================================
Predictions:  ['m50 m50 ii', 'a01203 39588720']
Answer:  ['2', 'a01203 39588720']
Predictions:  ['m50 m50 ii']
Answer:  ['2']
  [Batch] Query 639: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.28s avg)
Predictions:  ['a01203 39588720']
Answer:  ['a01203 39588720']
  [Batch] Query 640: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.28s avg)
Checkpoint saved: 636 queries processed

============================================================
Batch 321/1536: Processing 2 queries
============================================================
Predictions:  ['yes', 'a01203 a01202']
Answer:  ['138488394', 'a01203 a01101']
Predictions:  ['yes']
Answer:  ['138488394']
  [Batch] Query 641: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.19s avg)
Predictions:  ['a01203 a01202']
Answer:  ['a01203 a01101']
  [Batch] Query 642: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (1.19s avg)
Checkpoint saved: 638 queries processed

============================================================
Batch 322/1536: Processing 2 queries
============================================================
Predictions:  ['a01202 a01101', 'strong positive correlation 10']
Answer:  ['a01202', 'similar distributions slightly higher variability in category b']
Predictions:  ['a01202 a01101']
Answer:  ['a01202']
  [Batch] Query 643: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (1.20s avg)
Predictions:  ['strong positive correlation 10']
Answer:  ['similar distributions slightly higher variability in category b']
  [Batch] Query 644: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.20s avg)
Checkpoint saved: 640 queries processed

============================================================
Batch 323/1536: Processing 2 queries
============================================================
Predictions:  ['3482', 'yes']
Answer:  ['3482', 'yes']
Predictions:  ['3482']
Answer:  ['3482']
  [Batch] Query 645: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.70s avg)
Predictions:  ['yes']
Answer:  ['yes']
  [Batch] Query 646: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.70s avg)
Checkpoint saved: 642 queries processed

============================================================
Batch 324/1536: Processing 2 queries
============================================================
Predictions:  ['15', '3482 967']
Answer:  ['37', '4449']
Predictions:  ['15']
Answer:  ['37']
  [Batch] Query 647: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.85s avg)
Predictions:  ['3482 967']
Answer:  ['4449']
  [Batch] Query 648: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.85s avg)
Checkpoint saved: 644 queries processed

============================================================
Batch 325/1536: Processing 2 queries
============================================================
Predictions:  ['12', 'chilli chocolate chefs roshgold staff']
Processing batches:  21%|██        | 325/1536 [1:25:44<3:03:27,  9.09s/it]Processing batches:  21%|██        | 326/1536 [1:26:06<4:21:48, 12.98s/it]Answer:  ['12', 'roshgold staff']
Predictions:  ['12']
Answer:  ['12']
  [Batch] Query 649: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (11.03s avg)
Predictions:  ['chilli chocolate chefs roshgold staff']
Answer:  ['roshgold staff']
  [Batch] Query 650: {'F1': 57.14, 'EM': 0.0, 'ROUGE-L': 57.14, 'SacreBLEU': 21.36} (11.03s avg)
Checkpoint saved: 646 queries processed

============================================================
Batch 326/1536: Processing 2 queries
============================================================
Predictions:  ['chilli chocolate chefs roshgold', '10200']
Answer:  ['staff roshgold', '1020']
Predictions:  ['chilli chocolate chefs roshgold']
Answer:  ['staff roshgold']
  [Batch] Query 651: {'F1': 33.33, 'EM': 0.0, 'ROUGE-L': 33.33, 'SacreBLEU': 15.97} (10.91s avg)
Predictions:  ['10200']
Answer:  ['1020']
  [Batch] Query 652: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (10.91s avg)
Checkpoint saved: 648 queries processed

============================================================
Batch 327/1536: Processing 2 queries
============================================================
Predictions:  ['6mm black toughened lacobel 6mm dark grey toughened lacobel']
Answer:  ['6mm black toughened lacobel']
Predictions:  ['6mm black toughened lacobel 6mm dark grey toughened lacobel']
Answer:  ['6mm black toughened lacobel']
  [Batch] Query 654: {'F1': 61.54, 'EM': 0.0, 'ROUGE-L': 61.54, 'SacreBLEU': 29.85} (2.48s avg)
  Warning: Large text input (55059 tokens)
Processing batches:  21%|██▏       | 327/1536 [1:26:18<4:19:22, 12.87s/it]Processing batches:  21%|██▏       | 328/1536 [1:26:22<3:21:01,  9.98s/it]  [Single] Query 653: {'GPT_EVAL': 'N/A (no eval_api_key)'} (10.00s)
Checkpoint saved: 650 queries processed

============================================================
Batch 328/1536: Processing 2 queries
============================================================
Predictions:  ['3', '4']
Answer:  ['3', '4']
Predictions:  ['3']
Answer:  ['3']
  [Batch] Query 655: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.50s avg)
Predictions:  ['4']
Answer:  ['4']
  [Batch] Query 656: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.50s avg)
Checkpoint saved: 652 queries processed

============================================================
Batch 329/1536: Processing 2 queries
============================================================
Predictions:  ['yes']
Answer:  ['jones']
Predictions:  ['yes']
Answer:  ['jones']
  [Batch] Query 658: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.57s avg)
  Warning: Large text input (11531 tokens)
Processing batches:  21%|██▏       | 329/1536 [1:26:33<3:28:44, 10.38s/it]Processing batches:  21%|██▏       | 330/1536 [1:26:35<2:37:16,  7.82s/it]Processing batches:  22%|██▏       | 331/1536 [1:26:36<1:59:48,  5.97s/it]Processing batches:  22%|██▏       | 332/1536 [1:26:46<2:18:53,  6.92s/it]Processing batches:  22%|██▏       | 333/1536 [1:26:50<2:05:07,  6.24s/it]  [Single] Query 657: {'GPT_EVAL': 'N/A (no eval_api_key)'} (9.59s)
Checkpoint saved: 654 queries processed

============================================================
Batch 330/1536: Processing 2 queries
============================================================
Predictions:  ['elena kazakevic mallory mckewen hannah mcgroarty erin ball', 'nude pink']
Answer:  ['4', 'nude pink']
Predictions:  ['elena kazakevic mallory mckewen hannah mcgroarty erin ball']
Answer:  ['4']
  [Batch] Query 659: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (0.81s avg)
Predictions:  ['nude pink']
Answer:  ['nude pink']
  [Batch] Query 660: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (0.81s avg)
Checkpoint saved: 656 queries processed

============================================================
Batch 331/1536: Processing 2 queries
============================================================
Predictions:  ['nude pink grape', 'elena kazakevic walter isaacson']
Answer:  ['nude pink', '2']
Predictions:  ['nude pink grape']
Answer:  ['nude pink']
  [Batch] Query 661: {'F1': 80.0, 'EM': 0.0, 'ROUGE-L': 80.0, 'SacreBLEU': 0.0} (0.69s avg)
Predictions:  ['elena kazakevic walter isaacson']
Answer:  ['2']
  [Batch] Query 662: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (0.69s avg)
Checkpoint saved: 658 queries processed

============================================================
Batch 332/1536: Processing 2 queries
============================================================
Predictions:  ['988 140 1533']
Answer:  ['2661']
Predictions:  ['988 140 1533']
Answer:  ['2661']
  [Batch] Query 664: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.52s avg)
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/data/pan/4xin/datasets/RealHiTBench/tables/economy-table129.xlsx')
nude_pink_count = df[df['Colour'] == 'Nude Pink'].shape[0]
yellow_count = df[df['Colour'] == 'Yellow'].shape[0]
colors = ['Nude Pink', 'Yellow']
counts = [nude_pink_count, yellow_count]
plt.bar(colors, counts)
plt.xlabel('Colour')
plt.ylabel('Total Number of Names')
plt.title('Comparison of Total Number of Names for Nude Pink and Yellow')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

Python Error: Failed to convert value(s) to axis units: ['Nude Pink', 'Yellow']
  [Single] Query 663: {'ECR': False, 'Pass': False} (6.49s)
Checkpoint saved: 660 queries processed

============================================================
Batch 333/1536: Processing 2 queries
============================================================
Predictions:  ['578 eclaire', '373 diamo 597moisant 433 mosaic meemo sparrow']
Answer:  ['578 eclaire', '2']
Predictions:  ['578 eclaire']
Answer:  ['578 eclaire']
  [Batch] Query 665: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (2.20s avg)
Predictions:  ['373 diamo 597moisant 433 mosaic meemo sparrow']
Answer:  ['2']
  [Batch] Query 666: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.20s avg)
Checkpoint saved: 662 queries processed

============================================================
Batch 334/1536: Processing 2 queries
============================================================
Predictions:  ['08 07 07']
Answer:  ['07']
Predictions:  ['08 07 07']
Answer:  ['07']
  [Batch] Query 667: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (2.23s avg)
  Warning: Large text input (10500 tokens)
Processing batches:  22%|██▏       | 334/1536 [1:26:57<2:07:12,  6.35s/it]Processing batches:  22%|██▏       | 335/1536 [1:27:00<1:45:19,  5.26s/it]Processing batches:  22%|██▏       | 336/1536 [1:27:04<1:40:36,  5.03s/it]Processing batches:  22%|██▏       | 337/1536 [1:27:27<3:29:48, 10.50s/it]Processing batches:  22%|██▏       | 338/1536 [1:27:37<3:24:19, 10.23s/it]Processing batches:  22%|██▏       | 339/1536 [1:27:47<3:21:06, 10.08s/it]Processing batches:  22%|██▏       | 340/1536 [1:27:51<2:49:14,  8.49s/it]Processing batches:  22%|██▏       | 341/1536 [1:27:56<2:22:48,  7.17s/it]  [Single] Query 668: {'GPT_EVAL': 'N/A (no eval_api_key)'} (4.24s)
Checkpoint saved: 664 queries processed

============================================================
Batch 335/1536: Processing 2 queries
============================================================
Predictions:  ['51492', 'product 1 product 8 product 10']
Answer:  ['51492', 'product 2 product 3 product 4 product 5 product 6 product 9']
Predictions:  ['51492']
Answer:  ['51492']
  [Batch] Query 669: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.23s avg)
Predictions:  ['product 1 product 8 product 10']
Answer:  ['product 2 product 3 product 4 product 5 product 6 product 9']
  [Batch] Query 670: {'F1': 33.33, 'EM': 0.0, 'ROUGE-L': 33.33, 'SacreBLEU': 3.93} (1.23s avg)
Checkpoint saved: 666 queries processed

============================================================
Batch 336/1536: Processing 2 queries
============================================================
Predictions:  ['no', 'product 8 product 2 product 1 product 10 product 4 product 3 product 7 product 5 product 6 product 9']
Answer:  ['false', 'product 2 product 8 product 5 product 7 product 10 product 4 product 9 product 1 product 3 product 6']
Predictions:  ['no']
Answer:  ['false']
  [Batch] Query 671: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.12s avg)
Predictions:  ['product 8 product 2 product 1 product 10 product 4 product 3 product 7 product 5 product 6 product 9']
Answer:  ['product 2 product 8 product 5 product 7 product 10 product 4 product 9 product 1 product 3 product 6']
  [Batch] Query 672: {'F1': 100.0, 'EM': 0.0, 'ROUGE-L': 65.0, 'SacreBLEU': 48.59} (2.12s avg)
Checkpoint saved: 668 queries processed

============================================================
Batch 337/1536: Processing 2 queries
============================================================
Predictions:  ['49871 447379 51492', '116970 20000 4777890 28710 87925 91447 28950 902409 71860 750420 139760 2300 42900 12336920 32 40576 30100 144175 14050 114720']
Answer:  ['72578', '19742113']
Predictions:  ['49871 447379 51492']
Answer:  ['72578']
  [Batch] Query 673: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (11.50s avg)
Predictions:  ['116970 20000 4777890 28710 87925 91447 28950 902409 71860 750420 139760 2300 42900 12336920 32 40576 30100 144175 14050 114720']
Answer:  ['19742113']
  [Batch] Query 674: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (11.50s avg)
Checkpoint saved: 670 queries processed

============================================================
Batch 338/1536: Processing 2 queries
============================================================
Predictions:  ['rent paid', '2032910 116970']
Answer:  ['travelling expenses', '43876883']
Predictions:  ['rent paid']
Answer:  ['travelling expenses']
  [Batch] Query 675: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.68s avg)
Predictions:  ['2032910 116970']
Answer:  ['43876883']
  [Batch] Query 676: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.68s avg)
Checkpoint saved: 672 queries processed

============================================================
Batch 339/1536: Processing 2 queries
============================================================
Predictions:  ['mar18 apr17', '4975314 increasing trend']
Answer:  ['march 2018', '28396432']
Predictions:  ['mar18 apr17']
Answer:  ['march 2018']
  [Batch] Query 677: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.49s avg)
Predictions:  ['4975314 increasing trend']
Answer:  ['28396432']
  [Batch] Query 678: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.49s avg)
Checkpoint saved: 674 queries processed

============================================================
Batch 340/1536: Processing 2 queries
============================================================
Predictions:  ['thermostate switch change on dg2', 'jl1 muffler room']
Answer:  ['thermostate switch change on dg2', 'jl1 muffler room']
Predictions:  ['thermostate switch change on dg2']
Answer:  ['thermostate switch change on dg2']
  [Batch] Query 679: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (2.21s avg)
Predictions:  ['jl1 muffler room']
Answer:  ['jl1 muffler room']
  [Batch] Query 680: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (2.21s avg)
Checkpoint saved: 676 queries processed

============================================================
Batch 341/1536: Processing 2 queries
============================================================
Predictions:  ['2 hours work in progress', 'electrical department mechanical department']
Answer:  ['2 hours work in progress', 'electrical department']
Predictions:  ['2 hours work in progress']
Answer:  ['2 hours work in progress']
  [Batch] Query 681: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (1.92s avg)
Predictions:  ['electrical department mechanical department']
Answer:  ['electrical department']
  [Batch] Query 682: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 31.95} (1.92s avg)
Checkpoint saved: 678 queries processed

============================================================
Batch 342/1536: Processing 2 queries
============================================================
Predictions:  ['mark davies']
Answer:  ['marc hilton']
Predictions:  ['mark davies']
Answer:  ['marc hilton']
  [Batch] Query 684: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.70s avg)
  Warning: Large text input (12531 tokens)
Processing batches:  22%|██▏       | 342/1536 [1:28:03<2:27:12,  7.40s/it]  [Single] Query 683: {'GPT_EVAL': 'N/A (no eval_api_key)'} (6.09s)
Checkpoint saved: 680 queries processed

============================================================
Batch 343/1536: Processing 2 queries
============================================================
Predictions:  ['mark davies marc hilton']
Answer:  ['jeff lynch']
Predictions:  ['mark davies marc hilton']
Answer:  ['jeff lynch']
  [Batch] Query 685: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.98s avg)
  Warning: Large text input (11313 tokens)
Processing batches:  22%|██▏       | 343/1536 [1:28:16<2:55:06,  8.81s/it]Processing batches:  22%|██▏       | 344/1536 [1:28:20<2:27:34,  7.43s/it]Processing batches:  22%|██▏       | 345/1536 [1:28:24<2:09:43,  6.54s/it]  [Single] Query 686: {'GPT_EVAL': 'N/A (no eval_api_key)'} (9.97s)
Checkpoint saved: 682 queries processed

============================================================
Batch 344/1536: Processing 2 queries
============================================================
Predictions:  ['55 increasing trend', 'brighton west ham united']
Answer:  ['55', 'brentford vs crystal palace']
Predictions:  ['55 increasing trend']
Answer:  ['55']
  [Batch] Query 687: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (1.98s avg)
Predictions:  ['brighton west ham united']
Answer:  ['brentford vs crystal palace']
  [Batch] Query 688: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.98s avg)
Checkpoint saved: 684 queries processed

============================================================
Batch 345/1536: Processing 2 queries
============================================================
Predictions:  ['saturday 100', '40 70']
Answer:  ['2', '40 50']
Predictions:  ['saturday 100']
Answer:  ['2']
  [Batch] Query 689: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.10s avg)
Predictions:  ['40 70']
Answer:  ['40 50']
  [Batch] Query 690: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (2.10s avg)
Checkpoint saved: 686 queries processed

============================================================
Batch 346/1536: Processing 2 queries
============================================================
Predictions:  ['veg']
Answer:  ['gross sales roots']
Predictions:  ['veg']
Answer:  ['gross sales roots']
  [Batch] Query 692: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (0.99s avg)
  Warning: Large text input (13770 tokens)
Processing batches:  23%|██▎       | 346/1536 [1:28:32<2:14:54,  6.80s/it]Processing batches:  23%|██▎       | 347/1536 [1:28:34<1:49:48,  5.54s/it]Processing batches:  23%|██▎       | 348/1536 [1:28:37<1:31:44,  4.63s/it]Processing batches:  23%|██▎       | 349/1536 [1:28:43<1:38:11,  4.96s/it]Processing batches:  23%|██▎       | 350/1536 [1:28:56<2:26:17,  7.40s/it]  [Single] Query 691: {'GPT_EVAL': 'N/A (no eval_api_key)'} (6.30s)
Checkpoint saved: 688 queries processed

============================================================
Batch 347/1536: Processing 2 queries
============================================================
Predictions:  ['5000 5000', '4500 4500']
Answer:  ['13750', '15000']
Predictions:  ['5000 5000']
Answer:  ['13750']
  [Batch] Query 693: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.17s avg)
Predictions:  ['4500 4500']
Answer:  ['15000']
  [Batch] Query 694: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.17s avg)
Checkpoint saved: 690 queries processed

============================================================
Batch 348/1536: Processing 2 queries
============================================================
Predictions:  ['auto manual', 'strong positive correlation 10']
Answer:  ['auto', 'strong positive correlation 08']
Predictions:  ['auto manual']
Answer:  ['auto']
  [Batch] Query 695: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (1.13s avg)
Predictions:  ['strong positive correlation 10']
Answer:  ['strong positive correlation 08']
  [Batch] Query 696: {'F1': 75.0, 'EM': 0.0, 'ROUGE-L': 75.0, 'SacreBLEU': 59.46} (1.13s avg)
Checkpoint saved: 692 queries processed

============================================================
Batch 349/1536: Processing 2 queries
============================================================
Predictions:  ['carl mackinson 1', 'carl mackinson mark davies']
Answer:  ['john cross 2', '4']
Predictions:  ['carl mackinson 1']
Answer:  ['john cross 2']
  [Batch] Query 697: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.72s avg)
Predictions:  ['carl mackinson mark davies']
Answer:  ['4']
  [Batch] Query 698: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.72s avg)
Checkpoint saved: 694 queries processed

============================================================
Batch 350/1536: Processing 2 queries
============================================================
Predictions:  ['john cross carl mackinson barry travis mark davies marc hilton dave griffiths jack cross mick tootle brian griffiths thomas evans james dake jack davies dean richards kevin riley daniel hudspeth callum ashcroft jeff lynch mark evans kev thompson', '2 0']
Answer:  ['5', '2']
Predictions:  ['john cross carl mackinson barry travis mark davies marc hilton dave griffiths jack cross mick tootle brian griffiths thomas evans james dake jack davies dean richards kevin riley daniel hudspeth callum ashcroft jeff lynch mark evans kev thompson']
Answer:  ['5']
  [Batch] Query 699: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (6.41s avg)
Predictions:  ['2 0']
Answer:  ['2']
  [Batch] Query 700: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (6.41s avg)
Checkpoint saved: 696 queries processed

============================================================
Batch 351/1536: Processing 2 queries
============================================================
Predictions:  ['105 cap 10']
Answer:  ['w valley 26']
Predictions:  ['105 cap 10']
Answer:  ['w valley 26']
  [Batch] Query 702: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.83s avg)
  Warning: Large text input (16845 tokens)
Processing batches:  23%|██▎       | 351/1536 [1:29:05<2:40:36,  8.13s/it]Processing batches:  23%|██▎       | 352/1536 [1:29:10<2:20:35,  7.12s/it]  [Single] Query 701: {'GPT_EVAL': 'N/A (no eval_api_key)'} (7.87s)
Checkpoint saved: 698 queries processed

============================================================
Batch 352/1536: Processing 2 queries
============================================================
Predictions:  ['37 40', '305 364 330 423 243']
Answer:  ['40', '274']
Predictions:  ['37 40']
Answer:  ['40']
  [Batch] Query 703: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (2.26s avg)
Predictions:  ['305 364 330 423 243']
Answer:  ['274']
  [Batch] Query 704: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.26s avg)
Checkpoint saved: 700 queries processed

============================================================
Batch 353/1536: Processing 2 queries
============================================================
Predictions:  ['ridge cap deluxe ridge cap w valley']
Answer:  ['ridge cap 231 deluxe ridge cap 168 172 cap 118']
Predictions:  ['ridge cap deluxe ridge cap w valley']
Answer:  ['ridge cap 231 deluxe ridge cap 168 172 cap 118']
  [Batch] Query 705: {'F1': 58.82, 'EM': 0.0, 'ROUGE-L': 58.82, 'SacreBLEU': 20.02} (2.02s avg)
  Warning: Large text input (9431 tokens)
Processing batches:  23%|██▎       | 353/1536 [1:29:15<2:09:24,  6.56s/it]Processing batches:  23%|██▎       | 354/1536 [1:29:23<2:13:59,  6.80s/it]Processing batches:  23%|██▎       | 355/1536 [1:34:50<33:46:16, 102.94s/it]Processing batches:  23%|██▎       | 356/1536 [1:34:55<24:06:01, 73.53s/it] Processing batches:  23%|██▎       | 357/1536 [1:34:57<17:00:36, 51.94s/it]Processing batches:  23%|██▎       | 358/1536 [1:34:58<12:04:50, 36.92s/it]  [Single] Query 706: {'GPT_EVAL': 'N/A (no eval_api_key)'} (3.09s)
Checkpoint saved: 702 queries processed

============================================================
Batch 354/1536: Processing 2 queries
============================================================
Predictions:  ['foggy peter langdon paul garcia robert', '20210620 canadian firm looks to make more 3dprinted medical devices in st louis 1677 science and technology berger kathleen']
Answer:  ['foggy peter', '20210614 arts and faith 2021 1672 arts foggy peter']
Predictions:  ['foggy peter langdon paul garcia robert']
Answer:  ['foggy peter']
  [Batch] Query 707: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 16.23} (3.55s avg)
Predictions:  ['20210620 canadian firm looks to make more 3dprinted medical devices in st louis 1677 science and technology berger kathleen']
Answer:  ['20210614 arts and faith 2021 1672 arts foggy peter']
  [Batch] Query 708: {'F1': 7.14, 'EM': 0.0, 'ROUGE-L': 7.14, 'SacreBLEU': 2.02} (3.55s avg)
Checkpoint saved: 704 queries processed

============================================================
Batch 355/1536: Processing 2 queries
============================================================
Predictions:  ['1725 7050 1725 2250 600 150 600 120 600 1080 450 600 300 150 300 150 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300', 'package rate producing package rate editing']
Answer:  ['12675', 'package rate producing']
Predictions:  ['1725 7050 1725 2250 600 150 600 120 600 1080 450 600 300 150 300 150 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300 300']
Answer:  ['12675']
  [Batch] Query 709: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (163.51s avg)
Predictions:  ['package rate producing package rate editing']
Answer:  ['package rate producing']
  [Batch] Query 710: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 30.21} (163.51s avg)
Checkpoint saved: 706 queries processed

============================================================
Batch 356/1536: Processing 2 queries
============================================================
Predictions:  ['10 perfect positive correlation', 'rome']
Answer:  ['strong positive correlation 09', 'cairo']
Predictions:  ['10 perfect positive correlation']
Answer:  ['strong positive correlation 09']
  [Batch] Query 711: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 31.95} (2.11s avg)
Predictions:  ['rome']
Answer:  ['cairo']
  [Batch] Query 712: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.11s avg)
Checkpoint saved: 708 queries processed

============================================================
Batch 357/1536: Processing 2 queries
============================================================
Predictions:  ['yes', 'taylor drew']
Answer:  ['yes', 'drew']
Predictions:  ['yes']
Answer:  ['yes']
  [Batch] Query 713: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (0.66s avg)
Predictions:  ['taylor drew']
Answer:  ['drew']
  [Batch] Query 714: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (0.66s avg)
Checkpoint saved: 710 queries processed

============================================================
Batch 358/1536: Processing 2 queries
============================================================
Predictions:  ['taylor morgan drew']
Answer:  ['taylor drew morgan']
Predictions:  ['taylor morgan drew']
Answer:  ['taylor drew morgan']
  [Batch] Query 715: {'F1': 100.0, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (0.93s avg)
  [Single] Query 716: {'GPT_EVAL': 'N/A (no eval_api_key)'} (0.80s)
Checkpoint saved: 712 queries processed

============================================================
Batch 359/1536: Processing 2 queries
============================================================Processing batches:  23%|██▎       | 359/1536 [1:35:04<8:58:50, 27.47s/it] Processing batches:  23%|██▎       | 360/1536 [1:35:09<6:45:28, 20.69s/it]
Predictions:  ['aqpaf00nnjjcaf', 'elbow 90 deg sw cl6000 asme b1611 astm a105']
Answer:  ['aqpaf00ttjjcaf', 'elbow 90 deg sw cl6000 asme b1611 astm a105']
Predictions:  ['aqpaf00nnjjcaf']
Answer:  ['aqpaf00ttjjcaf']
  [Batch] Query 717: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.58s avg)
Predictions:  ['elbow 90 deg sw cl6000 asme b1611 astm a105']
Answer:  ['elbow 90 deg sw cl6000 asme b1611 astm a105']
  [Batch] Query 718: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (2.58s avg)
Checkpoint saved: 714 queries processed

============================================================
Batch 360/1536: Processing 2 queries
============================================================
Predictions:  ['aqnph0ccceecaf aqnph0cccffkaa', 'aqpaf00nnjjcaf']
Answer:  ['aqnph0ccceekaa aqpaf00ccvvkaa', 'aqpaf00nnjjcaf']
Predictions:  ['aqnph0ccceecaf aqnph0cccffkaa']
Answer:  ['aqnph0ccceekaa aqpaf00ccvvkaa']
  [Batch] Query 719: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.30s avg)
Predictions:  ['aqpaf00nnjjcaf']
Answer:  ['aqpaf00nnjjcaf']
  [Batch] Query 720: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (2.30s avg)
Checkpoint saved: 716 queries processed

============================================================
Batch 361/1536: Processing 2 queries
============================================================
Predictions:  ['80 00']
Answer:  ['8']
Predictions:  ['80 00']
Answer:  ['8']
  [Batch] Query 722: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.77s avg)
  Warning: Large text input (13118 tokens)
Processing batches:  24%|██▎       | 361/1536 [1:35:23<6:06:04, 18.69s/it]Processing batches:  24%|██▎       | 362/1536 [1:35:36<5:33:49, 17.06s/it]  [Single] Query 721: {'GPT_EVAL': 'N/A (no eval_api_key)'} (9.13s)
Checkpoint saved: 718 queries processed

============================================================
Batch 362/1536: Processing 2 queries
============================================================
Predictions:  ['jerlyn thompson human resources department', '1014 1015 1016 1023 1024 1025']
Answer:  ['jerlyn thompson human resources department', '6']
Predictions:  ['jerlyn thompson human resources department']
Answer:  ['jerlyn thompson human resources department']
  [Batch] Query 723: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (6.50s avg)
Predictions:  ['1014 1015 1016 1023 1024 1025']
Answer:  ['6']
  [Batch] Query 724: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (6.50s avg)
Checkpoint saved: 720 queries processed

============================================================
Batch 363/1536: Processing 2 queries
============================================================
Predictions:  ['80 80 80 00 00 80 80 80 00 00']
Answer:  ['38']
Predictions:  ['80 80 80 00 00 80 80 80 00 00']
Answer:  ['38']
  [Batch] Query 725: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (7.82s avg)
  Warning: Large text input (28844 tokens)
Processing batches:  24%|██▎       | 363/1536 [1:35:50<5:16:09, 16.17s/it]Processing batches:  24%|██▎       | 364/1536 [1:35:52<3:54:34, 12.01s/it]Processing batches:  24%|██▍       | 365/1536 [1:35:56<3:03:08,  9.38s/it]Processing batches:  24%|██▍       | 366/1536 [1:36:02<2:44:06,  8.42s/it]Processing batches:  24%|██▍       | 367/1536 [1:36:04<2:07:45,  6.56s/it]Processing batches:  24%|██▍       | 368/1536 [1:36:13<2:20:45,  7.23s/it]Processing batches:  24%|██▍       | 369/1536 [1:36:21<2:24:07,  7.41s/it]Processing batches:  24%|██▍       | 370/1536 [1:36:30<2:33:05,  7.88s/it]  [Single] Query 726: {'GPT_EVAL': 'N/A (no eval_api_key)'} (6.14s)
Checkpoint saved: 722 queries processed

============================================================
Batch 364/1536: Processing 2 queries
============================================================
Predictions:  ['no', 'product 1 180']
Answer:  ['no', 'product 1 180']
Predictions:  ['no']
Answer:  ['no']
  [Batch] Query 727: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.02s avg)
Predictions:  ['product 1 180']
Answer:  ['product 1 180']
  [Batch] Query 728: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.02s avg)
Checkpoint saved: 724 queries processed

============================================================
Batch 365/1536: Processing 2 queries
============================================================
Predictions:  ['product 3 product 1']
Answer:  ['product 3']
Predictions:  ['product 3 product 1']
Answer:  ['product 3']
  [Batch] Query 729: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 31.95} (1.22s avg)
  [Single] Query 730: {'GPT_EVAL': 'N/A (no eval_api_key)'} (1.90s)
Checkpoint saved: 726 queries processed

============================================================
Batch 366/1536: Processing 2 queries
============================================================
Predictions:  ['yes 250']
Answer:  ['yes 250']
Predictions:  ['yes 250']
Answer:  ['yes 250']
  [Batch] Query 732: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (0.99s avg)
  [Single] Query 731: {'GPT_EVAL': 'N/A (no eval_api_key)'} (5.03s)
Checkpoint saved: 728 queries processed

============================================================
Batch 367/1536: Processing 2 queries
============================================================
Predictions:  ['qr9785666 2990', 'qr9785666 2235']
Answer:  ['cpp7892531 11000', 'qr9785666 2235']
Predictions:  ['qr9785666 2990']
Answer:  ['cpp7892531 11000']
  [Batch] Query 733: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (0.98s avg)
Predictions:  ['qr9785666 2235']
Answer:  ['qr9785666 2235']
  [Batch] Query 734: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (0.98s avg)
Checkpoint saved: 730 queries processed

============================================================
Batch 368/1536: Processing 2 queries
============================================================
Predictions:  ['qr9785666 cpp7892531 kp78952']
Answer:  ['cpp7892531 kp78952 glp0111234']
Predictions:  ['qr9785666 cpp7892531 kp78952']
Answer:  ['cpp7892531 kp78952 glp0111234']
  [Batch] Query 735: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (1.74s avg)
  [Single] Query 736: {'GPT_EVAL': 'N/A (no eval_api_key)'} (6.93s)
Checkpoint saved: 732 queries processed

============================================================
Batch 369/1536: Processing 2 queries
============================================================
Predictions:  ['28 24', 'no']
Answer:  ['february 2012 had 20 more hours than january 2012', 'no']
Predictions:  ['28 24']
Answer:  ['february 2012 had 20 more hours than january 2012']
  [Batch] Query 737: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.79s avg)
Predictions:  ['no']
Answer:  ['no']
  [Batch] Query 738: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (3.79s avg)
Checkpoint saved: 734 queries processed

============================================================
Batch 370/1536: Processing 2 queries
============================================================
Predictions:  ['231956 2013', '24 48']
Answer:  ['29985 march 2013 3060', '2012 4']
Predictions:  ['231956 2013']
Answer:  ['29985 march 2013 3060']
  [Batch] Query 739: {'F1': 33.33, 'EM': 0.0, 'ROUGE-L': 33.33, 'SacreBLEU': 0.0} (4.35s avg)
Predictions:  ['24 48']
Answer:  ['2012 4']
  [Batch] Query 740: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.35s avg)
Checkpoint saved: 736 queries processed

============================================================
Batch 371/1536: Processing 2 queries
============================================================
Predictions:  ['lenovo desktop samsung monitor']
Answer:  ['lenovo desktop']
Predictions:  ['lenovo desktop samsung monitor']
Answer:  ['lenovo desktop']
  [Batch] Query 742: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 31.95} (10.95s avg)
  Warning: Large text input (24906 tokens)
Processing batches:  24%|██▍       | 371/1536 [1:36:48<3:33:34, 11.00s/it]Processing batches:  24%|██▍       | 372/1536 [1:37:13<4:57:33, 15.34s/it]  [Single] Query 741: {'GPT_EVAL': 'N/A (no eval_api_key)'} (7.19s)
Checkpoint saved: 738 queries processed

============================================================
Batch 372/1536: Processing 2 queries
============================================================
Predictions:  ['tcm 1', 'dell latitude 3480 dell latitude 3460']
Answer:  ['silvertron business technologies 1', 'xerox printer dell laptop']
Predictions:  ['tcm 1']
Answer:  ['silvertron business technologies 1']
  [Batch] Query 743: {'F1': 33.33, 'EM': 0.0, 'ROUGE-L': 33.33, 'SacreBLEU': 0.0} (12.60s avg)
Predictions:  ['dell latitude 3480 dell latitude 3460']
Answer:  ['xerox printer dell laptop']
  [Batch] Query 744: {'F1': 20.0, 'EM': 0.0, 'ROUGE-L': 20.0, 'SacreBLEU': 8.12} (12.60s avg)
Checkpoint saved: 740 queries processed

============================================================
Batch 373/1536: Processing 2 queries
============================================================
Predictions:  ['3']
Answer:  ['7']
Predictions:  ['3']
Answer:  ['7']
  [Batch] Query 745: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (10.76s avg)
  Warning: Large text input (57744 tokens)
Processing batches:  24%|██▍       | 373/1536 [1:37:46<6:36:31, 20.46s/it]Processing batches:  24%|██▍       | 374/1536 [1:37:54<5:24:15, 16.74s/it]Processing batches:  24%|██▍       | 375/1536 [1:38:02<4:34:07, 14.17s/it]  [Single] Query 746: {'GPT_EVAL': 'N/A (no eval_api_key)'} (21.50s)
Checkpoint saved: 742 queries processed

============================================================
Batch 374/1536: Processing 2 queries
============================================================
Predictions:  ['45 9', '867']
Answer:  ['false', '851']
Predictions:  ['45 9']
Answer:  ['false']
  [Batch] Query 747: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.91s avg)
Predictions:  ['867']
Answer:  ['851']
  [Batch] Query 748: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.91s avg)
Checkpoint saved: 744 queries processed

============================================================
Batch 375/1536: Processing 2 queries
============================================================
Predictions:  ['2 90', 'post sc4']
Answer:  ['2 9', 'post']
Predictions:  ['2 90']
Answer:  ['2 9']
  [Batch] Query 749: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (3.95s avg)
Predictions:  ['post sc4']
Answer:  ['post']
  [Batch] Query 750: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (3.95s avg)
Checkpoint saved: 746 queries processed

============================================================
Batch 376/1536: Processing 2 queries
============================================================
Predictions:  ['z6 z5']
Answer:  ['z6 z5']
Predictions:  ['z6 z5']
Answer:  ['z6 z5']
  [Batch] Query 752: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.01s avg)
  Warning: Large text input (25386 tokens)
Processing batches:  24%|██▍       | 376/1536 [1:38:18<4:44:06, 14.70s/it]Processing batches:  25%|██▍       | 377/1536 [1:38:20<3:29:39, 10.85s/it]Processing batches:  25%|██▍       | 378/1536 [1:38:26<3:01:53,  9.42s/it]Processing batches:  25%|██▍       | 379/1536 [1:38:28<2:20:21,  7.28s/it]Processing batches:  25%|██▍       | 380/1536 [1:38:35<2:18:11,  7.17s/it]Processing batches:  25%|██▍       | 381/1536 [1:38:47<2:45:17,  8.59s/it]Processing batches:  25%|██▍       | 382/1536 [1:38:53<2:27:26,  7.67s/it]  [Single] Query 751: {'GPT_EVAL': 'N/A (no eval_api_key)'} (14.79s)
Checkpoint saved: 748 queries processed

============================================================
Batch 377/1536: Processing 2 queries
============================================================
Predictions:  ['z6 z5', 'yes 64']
Answer:  ['z6 z5', 'z6 64']
Predictions:  ['z6 z5']
Answer:  ['z6 z5']
  [Batch] Query 753: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (0.82s avg)
Predictions:  ['yes 64']
Answer:  ['z6 64']
  [Batch] Query 754: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (0.82s avg)
Checkpoint saved: 750 queries processed

============================================================
Batch 378/1536: Processing 2 queries
============================================================
Predictions:  ['z6 z5']
Answer:  ['2']
Predictions:  ['z6 z5']
Answer:  ['2']
  [Batch] Query 755: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.13s avg)
  [Single] Query 756: {'GPT_EVAL': 'N/A (no eval_api_key)'} (4.82s)
Checkpoint saved: 752 queries processed

============================================================
Batch 379/1536: Processing 2 queries
============================================================
Predictions:  ['em1x 86', 'yes']
Answer:  ['em1x 86', 'no']
Predictions:  ['em1x 86']
Answer:  ['em1x 86']
  [Batch] Query 757: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.01s avg)
Predictions:  ['yes']
Answer:  ['no']
  [Batch] Query 758: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.01s avg)
Checkpoint saved: 754 queries processed

============================================================
Batch 380/1536: Processing 2 queries
============================================================
Predictions:  ['em1 em10 em1x em5 fake']
Answer:  ['em1 em10 em1x em5 fake']
Predictions:  ['em1 em10 em1x em5 fake']
Answer:  ['em1 em10 em1x em5 fake']
  [Batch] Query 759: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (1.79s avg)
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/data/pan/4xin/datasets/RealHiTBench/tables/manufacture-table07.xlsx')
cameras = df.columns[2:7]
max_resolution = df.iloc[5, 2:7].tolist()
plt.bar(cameras, max_resolution)
plt.xlabel('Camera Model')
plt.ylabel('Maximum Resolution')
plt.title('Comparison of Maximum Resolution for Each Camera')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

Python Error: Failed to convert value(s) to axis units: Index(['E-M1', 'E-M10', 'E-M1X', 'E-M5', 'Fake'], dtype='object')
  [Single] Query 760: {'ECR': False, 'Pass': False} (4.99s)
Checkpoint saved: 756 queries processed

============================================================
Batch 381/1536: Processing 2 queries
============================================================
Predictions:  ['7000 9000']
Answer:  ['12000']
Predictions:  ['7000 9000']
Answer:  ['12000']
  [Batch] Query 762: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.45s avg)
  [Single] Query 761: {'GPT_EVAL': 'N/A (no eval_api_key)'} (9.30s)
Checkpoint saved: 758 queries processed

============================================================
Batch 382/1536: Processing 2 queries
============================================================
Predictions:  ['2200', 'eon grand i10 xcent elite i20 active verna santa fe']
Answer:  ['2200', '6']
Predictions:  ['2200']
Answer:  ['2200']
  [Batch] Query 763: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (2.63s avg)
Predictions:  ['eon grand i10 xcent elite i20 active verna santa fe']
Answer:  ['6']
  [Batch] Query 764: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.63s avg)
Checkpoint saved: 760 queries processed

============================================================
Batch 383/1536: Processing 2 queries
============================================================
Predictions:  ['yes']
Answer:  ['yes']
Predictions:  ['yes']
Answer:  ['yes']
  [Batch] Query 766: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.21s avg)
  Warning: Large text input (14411 tokens)
Processing batches:  25%|██▍       | 383/1536 [1:39:04<2:50:59,  8.90s/it]Processing batches:  25%|██▌       | 384/1536 [1:39:07<2:15:01,  7.03s/it]  [Single] Query 765: {'GPT_EVAL': 'N/A (no eval_api_key)'} (10.42s)
Checkpoint saved: 762 queries processed

============================================================
Batch 384/1536: Processing 2 queries
============================================================
Predictions:  ['yes', '32 8 32']
Answer:  ['no', '68']
Predictions:  ['yes']
Answer:  ['no']
  [Batch] Query 767: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.21s avg)
Predictions:  ['32 8 32']
Answer:  ['68']
  [Batch] Query 768: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.21s avg)
Checkpoint saved: 764 queries processed

============================================================
Batch 385/1536: Processing 2 queries
============================================================
Predictions:  ['2']
Answer:  ['2']
Predictions:  ['2']
Answer:  ['2']
  [Batch] Query 769: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.25s avg)
  Warning: Large text input (8339 tokens)
Processing batches:  25%|██▌       | 385/1536 [1:39:16<2:23:45,  7.49s/it]Processing batches:  25%|██▌       | 386/1536 [1:39:19<2:01:10,  6.32s/it]Processing batches:  25%|██▌       | 387/1536 [1:39:23<1:46:57,  5.59s/it]Processing batches:  25%|██▌       | 388/1536 [1:39:27<1:35:55,  5.01s/it]Processing batches:  25%|██▌       | 389/1536 [1:39:30<1:25:48,  4.49s/it]Processing batches:  25%|██▌       | 390/1536 [1:39:33<1:20:10,  4.20s/it]Processing batches:  25%|██▌       | 391/1536 [1:39:38<1:24:24,  4.42s/it]Processing batches:  26%|██▌       | 392/1536 [1:39:44<1:28:46,  4.66s/it]  [Single] Query 770: {'GPT_EVAL': 'N/A (no eval_api_key)'} (7.18s)
Checkpoint saved: 766 queries processed

============================================================
Batch 386/1536: Processing 2 queries
============================================================
Predictions:  ['1 2', '42 18']
Answer:  ['false', '43']
Predictions:  ['1 2']
Answer:  ['false']
  [Batch] Query 771: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.67s avg)
Predictions:  ['42 18']
Answer:  ['43']
  [Batch] Query 772: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.67s avg)
Checkpoint saved: 768 queries processed

============================================================
Batch 387/1536: Processing 2 queries
============================================================
Predictions:  ['1 2', 'imd dom psc wwm io']
Answer:  ['2', '2']
Predictions:  ['1 2']
Answer:  ['2']
  [Batch] Query 773: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (1.80s avg)
Predictions:  ['imd dom psc wwm io']
Answer:  ['2']
  [Batch] Query 774: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.80s avg)
Checkpoint saved: 770 queries processed

============================================================
Batch 388/1536: Processing 2 queries
============================================================
Predictions:  ['18', '2 1 0']
Answer:  ['18', '2']
Predictions:  ['18']
Answer:  ['18']
  [Batch] Query 775: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.71s avg)
Predictions:  ['2 1 0']
Answer:  ['2']
  [Batch] Query 776: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (1.71s avg)
Checkpoint saved: 772 queries processed

============================================================
Batch 389/1536: Processing 2 queries
============================================================
Predictions:  ['panama venezuela panama bolivia', '5 6']
Answer:  ['5', '5']
Predictions:  ['panama venezuela panama bolivia']
Answer:  ['5']
  [Batch] Query 777: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.51s avg)
Predictions:  ['5 6']
Answer:  ['5']
  [Batch] Query 778: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (1.51s avg)
Checkpoint saved: 774 queries processed

============================================================
Batch 390/1536: Processing 2 queries
============================================================
Predictions:  ['venezuela 4', 'stable performance no clear trend']
Answer:  ['4', 'increasing trend']
Predictions:  ['venezuela 4']
Answer:  ['4']
  [Batch] Query 779: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (1.63s avg)
Predictions:  ['stable performance no clear trend']
Answer:  ['increasing trend']
  [Batch] Query 780: {'F1': 28.57, 'EM': 0.0, 'ROUGE-L': 28.57, 'SacreBLEU': 10.68} (1.63s avg)
Checkpoint saved: 776 queries processed

============================================================
Batch 391/1536: Processing 2 queries
============================================================
Predictions:  ['158 55', 'yes']
Answer:  ['212', 'no']
Predictions:  ['158 55']
Answer:  ['212']
  [Batch] Query 781: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.35s avg)
Predictions:  ['yes']
Answer:  ['no']
  [Batch] Query 782: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.35s avg)
Checkpoint saved: 778 queries processed

============================================================
Batch 392/1536: Processing 2 queries
============================================================
Predictions:  ['06', '212017 243']
Answer:  ['04', '20170206 256']
Predictions:  ['06']
Answer:  ['04']
  [Batch] Query 783: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.47s avg)
Predictions:  ['212017 243']
Answer:  ['20170206 256']
  [Batch] Query 784: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.47s avg)
Checkpoint saved: 780 queries processed

============================================================
Batch 393/1536: Processing 2 queries
============================================================
Predictions:  ['2']
Answer:  ['2']
Predictions:  ['2']
Answer:  ['2']
  [Batch] Query 786: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.04s avg)
  Warning: Large text input (15129 tokens)
Processing batches:  26%|██▌       | 393/1536 [1:39:55<2:09:35,  6.80s/it]Processing batches:  26%|██▌       | 394/1536 [1:39:58<1:42:47,  5.40s/it]Processing batches:  26%|██▌       | 395/1536 [1:40:00<1:27:13,  4.59s/it]Processing batches:  26%|██▌       | 396/1536 [1:40:04<1:20:58,  4.26s/it]Processing batches:  26%|██▌       | 397/1536 [1:40:10<1:30:49,  4.78s/it]  [Single] Query 785: {'GPT_EVAL': 'N/A (no eval_api_key)'} (10.64s)
Checkpoint saved: 782 queries processed

============================================================
Batch 394/1536: Processing 2 queries
============================================================
Predictions:  ['no', 'yes']
Answer:  ['no', 'yes']
Predictions:  ['no']
Answer:  ['no']
  [Batch] Query 787: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (0.88s avg)
Predictions:  ['yes']
Answer:  ['yes']
  [Batch] Query 788: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (0.88s avg)
Checkpoint saved: 784 queries processed

============================================================
Batch 395/1536: Processing 2 queries
============================================================
Predictions:  ['answering machine no answer', '136 129']
Answer:  ['no answer answering machine call completed busy dial error callback operator intercept do not call abandon hangup regret', '265']
Predictions:  ['answering machine no answer']
Answer:  ['no answer answering machine call completed busy dial error callback operator intercept do not call abandon hangup regret']
  [Batch] Query 789: {'F1': 36.36, 'EM': 0.0, 'ROUGE-L': 18.18, 'SacreBLEU': 1.36} (1.22s avg)
Predictions:  ['136 129']
Answer:  ['265']
  [Batch] Query 790: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.22s avg)
Checkpoint saved: 786 queries processed

============================================================
Batch 396/1536: Processing 2 queries
============================================================
Predictions:  ['yes', '39 1']
Answer:  ['yes', '391']
Predictions:  ['yes']
Answer:  ['yes']
  [Batch] Query 791: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.62s avg)
Predictions:  ['39 1']
Answer:  ['391']
  [Batch] Query 792: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.62s avg)
Checkpoint saved: 788 queries processed

============================================================
Batch 397/1536: Processing 2 queries
============================================================
Predictions:  ['116 194 176', 'is your organisation meeting its own expectations as regards managing its own information does your organisation have knowledge and information management kim strategy have costs and resource needs for kim been determined']
Answer:  ['yes', '1 strategic management “does your organisation have knowledge and information management kim strategy” 2 business objectives “are there performance measures for kim” 3 business objectives “if so has business critical information been included in business continuity plan”']
Predictions:  ['116 194 176']
Answer:  ['yes']
  [Batch] Query 793: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.88s avg)
Predictions:  ['is your organisation meeting its own expectations as regards managing its own information does your organisation have knowledge and information management kim strategy have costs and resource needs for kim been determined']
Answer:  ['1 strategic management “does your organisation have knowledge and information management kim strategy” 2 business objectives “are there performance measures for kim” 3 business objectives “if so has business critical information been included in business continuity plan”']
  [Batch] Query 794: {'F1': 31.88, 'EM': 0.0, 'ROUGE-L': 37.68, 'SacreBLEU': 19.46} (2.88s avg)
Checkpoint saved: 790 queries processed

============================================================
Batch 398/1536: Processing 2 queries
============================================================
Predictions:  ['80 80']
Answer:  ['yes']
Predictions:  ['80 80']
Answer:  ['yes']
  [Batch] Query 796: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.05s avg)
  Warning: Large text input (11478 tokens)
Processing batches:  26%|██▌       | 398/1536 [1:40:14<1:26:57,  4.59s/it]Processing batches:  26%|██▌       | 399/1536 [1:40:24<2:01:01,  6.39s/it]  [Single] Query 795: {'GPT_EVAL': 'N/A (no eval_api_key)'} (1.93s)
Checkpoint saved: 792 queries processed

============================================================
Batch 399/1536: Processing 2 queries
============================================================
Predictions:  ['fba47672 3622', '129 123 107 88 64 71 51 43 38 37 37 31 29 19 15 13 13 13 12 11 10 10 10 9 9 8 8 7 7']
Answer:  ['7', '1002']
Predictions:  ['fba47672 3622']
Answer:  ['7']
  [Batch] Query 797: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (5.17s avg)
Predictions:  ['129 123 107 88 64 71 51 43 38 37 37 31 29 19 15 13 13 13 12 11 10 10 10 9 9 8 8 7 7']
Answer:  ['1002']
  [Batch] Query 798: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (5.17s avg)
Checkpoint saved: 794 queries processed

============================================================
Batch 400/1536: Processing 2 queries
============================================================
Predictions:  ['15580 increasing trend']
Answer:  ['9471']
Predictions:  ['15580 increasing trend']
Answer:  ['9471']
  [Batch] Query 799: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.05s avg)
  Warning: Large text input (11278 tokens)
Processing batches:  26%|██▌       | 400/1536 [1:40:33<2:11:01,  6.92s/it]Processing batches:  26%|██▌       | 401/1536 [1:40:44<2:34:45,  8.18s/it]Processing batches:  26%|██▌       | 402/1536 [1:40:57<3:04:10,  9.74s/it]  [Single] Query 800: {'GPT_EVAL': 'N/A (no eval_api_key)'} (5.97s)
Checkpoint saved: 796 queries processed

============================================================
Batch 401/1536: Processing 2 queries
============================================================
Predictions:  ['walmart 3141 supercenter', 'yes']
Answer:  ['walmart 3141 supercenter', 'yes']
Predictions:  ['walmart 3141 supercenter']
Answer:  ['walmart 3141 supercenter']
  [Batch] Query 801: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (5.43s avg)
Predictions:  ['yes']
Answer:  ['yes']
  [Batch] Query 802: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (5.43s avg)
Checkpoint saved: 798 queries processed

============================================================
Batch 402/1536: Processing 2 queries
============================================================
Predictions:  ['166', 'walmart 1107 supercentre fortinos 81 sobeys 6730']
Answer:  ['273', 'walmart 1107 supercentre fortinos 58 fortinos 81']
Predictions:  ['166']
Answer:  ['273']
  [Batch] Query 803: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (6.57s avg)
Predictions:  ['walmart 1107 supercentre fortinos 81 sobeys 6730']
Answer:  ['walmart 1107 supercentre fortinos 58 fortinos 81']
  [Batch] Query 804: {'F1': 71.43, 'EM': 0.0, 'ROUGE-L': 71.43, 'SacreBLEU': 46.71} (6.57s avg)
Checkpoint saved: 800 queries processed

============================================================
Batch 403/1536: Processing 2 queries
============================================================
Predictions:  ['ae ae']
Answer:  ['yes']
Predictions:  ['ae ae']
Answer:  ['yes']
  [Batch] Query 806: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.47s avg)
  Warning: Large text input (32203 tokens)
Processing batches:  26%|██▌       | 403/1536 [1:41:15<3:50:14, 12.19s/it]Processing batches:  26%|██▋       | 404/1536 [1:41:24<3:32:44, 11.28s/it]  [Single] Query 805: {'GPT_EVAL': 'N/A (no eval_api_key)'} (14.29s)
Checkpoint saved: 802 queries processed

============================================================
Batch 404/1536: Processing 2 queries
============================================================
Predictions:  ['chabb aeflc', 'igb525 igb255 igb535 igb615']
Answer:  ['aeflc', 'yes']
Predictions:  ['chabb aeflc']
Answer:  ['aeflc']
  [Batch] Query 807: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (4.44s avg)
Predictions:  ['igb525 igb255 igb535 igb615']
Answer:  ['yes']
  [Batch] Query 808: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.44s avg)
Checkpoint saved: 804 queries processed

============================================================
Batch 405/1536: Processing 2 queries
============================================================
Predictions:  ['abb schweiz ag power grids']
Answer:  ['abb industries fz discrete']
Predictions:  ['abb schweiz ag power grids']
Answer:  ['abb industries fz discrete']
  [Batch] Query 809: {'F1': 22.22, 'EM': 0.0, 'ROUGE-L': 22.22, 'SacreBLEU': 10.68} (3.75s avg)
  Warning: Large text input (24146 tokens)
Processing batches:  26%|██▋       | 405/1536 [1:41:47<4:38:28, 14.77s/it]Processing batches:  26%|██▋       | 406/1536 [1:42:03<4:46:09, 15.19s/it]Processing batches:  26%|██▋       | 407/1536 [1:42:39<6:39:19, 21.22s/it]  [Single] Query 810: {'GPT_EVAL': 'N/A (no eval_api_key)'} (19.04s)
Checkpoint saved: 806 queries processed

============================================================
Batch 406/1536: Processing 2 queries
============================================================
Predictions:  ['kurewe', 'no no no']
Answer:  ['kurtz', 'no']
Predictions:  ['kurewe']
Answer:  ['kurtz']
  [Batch] Query 811: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (7.96s avg)
Predictions:  ['no no no']
Answer:  ['no']
  [Batch] Query 812: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (7.96s avg)
Checkpoint saved: 808 queries processed

============================================================
Batch 407/1536: Processing 2 queries
============================================================
Predictions:  ['gray b konopka beckett canuck choboe crane diehard dom drakkhan hawx inquisitor j araj joe johnson lekner lincoln lou m baker m tolbert metal miyoka n brenner nara nicholsen noneck phillips phantom price ragtagguy riker ryan seer shocktroop spud svendor tally toxic waverly welsh', '13 15']
Answer:  ['18', 'first week']
Predictions:  ['gray b konopka beckett canuck choboe crane diehard dom drakkhan hawx inquisitor j araj joe johnson lekner lincoln lou m baker m tolbert metal miyoka n brenner nara nicholsen noneck phillips phantom price ragtagguy riker ryan seer shocktroop spud svendor tally toxic waverly welsh']
Answer:  ['18']
  [Batch] Query 813: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (17.51s avg)
Predictions:  ['13 15']
Answer:  ['first week']
  [Batch] Query 814: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (17.51s avg)
Checkpoint saved: 810 queries processed

============================================================
Batch 408/1536: Processing 2 queries
============================================================
Predictions:  ['1 1']
Answer:  ['1']
Predictions:  ['1 1']
Answer:  ['1']
  [Batch] Query 816: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (4.73s avg)
  Warning: Large text input (44901 tokens)
Processing batches:  27%|██▋       | 408/1536 [1:42:56<6:15:26, 19.97s/it]Processing batches:  27%|██▋       | 409/1536 [1:43:06<5:23:22, 17.22s/it]  [Single] Query 815: {'GPT_EVAL': 'N/A (no eval_api_key)'} (12.18s)
Checkpoint saved: 812 queries processed

============================================================
Batch 409/1536: Processing 2 queries
============================================================
Predictions:  ['fleece', 'polo shirts fleece safety boots safety shoes']
Answer:  ['polo shirts', 'polo shirts fleece safety shoes safety boots']
Predictions:  ['fleece']
Answer:  ['polo shirts']
  [Batch] Query 817: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (5.27s avg)
Predictions:  ['polo shirts fleece safety boots safety shoes']
Answer:  ['polo shirts fleece safety shoes safety boots']
  [Batch] Query 818: {'F1': 100.0, 'EM': 0.0, 'ROUGE-L': 71.43, 'SacreBLEU': 53.73} (5.27s avg)
Checkpoint saved: 814 queries processed

============================================================
Batch 410/1536: Processing 2 queries
============================================================
Predictions:  ['s m l xl 2xl 3xl 4xl']
Answer:  ['yes']
Predictions:  ['s m l xl 2xl 3xl 4xl']
Answer:  ['yes']
  [Batch] Query 819: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (5.52s avg)
  Warning: Large text input (30563 tokens)
Processing batches:  27%|██▋       | 410/1536 [1:43:23<5:17:05, 16.90s/it]Processing batches:  27%|██▋       | 411/1536 [1:43:30<4:25:17, 14.15s/it]Processing batches:  27%|██▋       | 412/1536 [1:43:37<3:43:51, 11.95s/it]  [Single] Query 820: {'GPT_EVAL': 'N/A (no eval_api_key)'} (10.50s)
Checkpoint saved: 816 queries processed

============================================================
Batch 411/1536: Processing 2 queries
============================================================
Predictions:  ['29', 'colwyn staplehurst']
Answer:  ['29', 'colwyn']
Predictions:  ['29']
Answer:  ['29']
  [Batch] Query 821: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (3.74s avg)
Predictions:  ['colwyn staplehurst']
Answer:  ['colwyn']
  [Batch] Query 822: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (3.74s avg)
Checkpoint saved: 818 queries processed

============================================================
Batch 412/1536: Processing 2 queries
============================================================
Predictions:  ['1', 'colwyn aylesbury']
Answer:  ['3', 'bexhill colwyn']
Predictions:  ['1']
Answer:  ['3']
  [Batch] Query 823: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.28s avg)
Predictions:  ['colwyn aylesbury']
Answer:  ['bexhill colwyn']
  [Batch] Query 824: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (3.28s avg)
Checkpoint saved: 820 queries processed

============================================================
Batch 413/1536: Processing 2 queries
============================================================
Predictions:  ['146 167']
Answer:  ['146 167']
Predictions:  ['146 167']
Answer:  ['146 167']
  [Batch] Query 826: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.35s avg)
  Warning: Large text input (21614 tokens)
Processing batches:  27%|██▋       | 413/1536 [1:43:52<4:00:52, 12.87s/it]Processing batches:  27%|██▋       | 414/1536 [1:43:54<3:00:46,  9.67s/it]Processing batches:  27%|██▋       | 415/1536 [1:44:06<3:12:14, 10.29s/it]Processing batches:  27%|██▋       | 416/1536 [1:44:10<2:35:28,  8.33s/it]Processing batches:  27%|██▋       | 417/1536 [1:44:13<2:08:42,  6.90s/it]  [Single] Query 825: {'GPT_EVAL': 'N/A (no eval_api_key)'} (13.52s)
Checkpoint saved: 822 queries processed

============================================================
Batch 414/1536: Processing 2 queries
============================================================
Predictions:  ['513132', '142 144']
Answer:  ['477850', '144']
Predictions:  ['513132']
Answer:  ['477850']
  [Batch] Query 827: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (0.97s avg)
Predictions:  ['142 144']
Answer:  ['144']
  [Batch] Query 828: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (0.97s avg)
Checkpoint saved: 824 queries processed

============================================================
Batch 415/1536: Processing 2 queries
============================================================
Predictions:  ['142']
Answer:  ['3']
Predictions:  ['142']
Answer:  ['3']
  [Batch] Query 829: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.00s avg)
  [Single] Query 830: {'GPT_EVAL': 'N/A (no eval_api_key)'} (10.60s)
Checkpoint saved: 826 queries processed

============================================================
Batch 416/1536: Processing 2 queries
============================================================
Predictions:  ['1400156613 aeflc', '5']
Answer:  ['1400156613 chabb', '12']
Predictions:  ['1400156613 aeflc']
Answer:  ['1400156613 chabb']
  [Batch] Query 831: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (1.75s avg)
Predictions:  ['5']
Answer:  ['12']
  [Batch] Query 832: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.75s avg)
Checkpoint saved: 828 queries processed

============================================================
Batch 417/1536: Processing 2 queries
============================================================
Predictions:  ['czabb chabb aeflc', 'czabb 123525']
Answer:  ['3', 'czabb 5038817']
Predictions:  ['czabb chabb aeflc']
Answer:  ['3']
  [Batch] Query 833: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.66s avg)
Predictions:  ['czabb 123525']
Answer:  ['czabb 5038817']
  [Batch] Query 834: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (1.66s avg)
Checkpoint saved: 830 queries processed

============================================================
Batch 418/1536: Processing 2 queries
============================================================
Predictions:  ['5 13']
Answer:  ['5 16']
Predictions:  ['5 13']
Answer:  ['5 16']
  [Batch] Query 836: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (1.17s avg)
  Warning: Large text input (10031 tokens)
Processing batches:  27%|██▋       | 418/1536 [1:44:35<3:29:49, 11.26s/it]Processing batches:  27%|██▋       | 419/1536 [1:44:37<2:40:34,  8.63s/it]Processing batches:  27%|██▋       | 420/1536 [1:44:44<2:29:35,  8.04s/it]Processing batches:  27%|██▋       | 421/1536 [1:44:49<2:09:54,  6.99s/it]Processing batches:  27%|██▋       | 422/1536 [1:44:54<2:01:00,  6.52s/it]  [Single] Query 835: {'GPT_EVAL': 'N/A (no eval_api_key)'} (20.12s)
Checkpoint saved: 832 queries processed

============================================================
Batch 419/1536: Processing 2 queries
============================================================
Predictions:  ['monday', 'monday tuesday wednesday thursday friday saturday']
Answer:  ['monday', '4']
Predictions:  ['monday']
Answer:  ['monday']
  [Batch] Query 837: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.11s avg)
Predictions:  ['monday tuesday wednesday thursday friday saturday']
Answer:  ['4']
  [Batch] Query 838: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.11s avg)
Checkpoint saved: 834 queries processed

============================================================
Batch 420/1536: Processing 2 queries
============================================================
Predictions:  ['week1 week2']
Answer:  ['week 1']
Predictions:  ['week1 week2']
Answer:  ['week 1']
  [Batch] Query 839: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.18s avg)
  [Single] Query 840: {'GPT_EVAL': 'N/A (no eval_api_key)'} (5.37s)
Checkpoint saved: 836 queries processed

============================================================
Batch 421/1536: Processing 2 queries
============================================================
Predictions:  ['2016100320161009', 'tuesday']
Answer:  ['20161003 20161009', 'tuesday']
Predictions:  ['2016100320161009']
Answer:  ['20161003 20161009']
  [Batch] Query 841: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.14s avg)
Predictions:  ['tuesday']
Answer:  ['tuesday']
  [Batch] Query 842: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (2.14s avg)
Checkpoint saved: 838 queries processed

============================================================
Batch 422/1536: Processing 2 queries
============================================================
Predictions:  ['1000am 130pm 200pm 540pm 800pm', 'wednesday']
Answer:  ['800pm', 'thursday 6']
Predictions:  ['1000am 130pm 200pm 540pm 800pm']
Answer:  ['800pm']
  [Batch] Query 843: {'F1': 33.33, 'EM': 0.0, 'ROUGE-L': 33.33, 'SacreBLEU': 10.68} (2.58s avg)
Predictions:  ['wednesday']
Answer:  ['thursday 6']
  [Batch] Query 844: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.58s avg)
Checkpoint saved: 840 queries processed

============================================================
Batch 423/1536: Processing 2 queries
============================================================
Predictions:  ['thu 78']
Answer:  ['thursday n 08']
Predictions:  ['thu 78']
Answer:  ['thursday n 08']
  [Batch] Query 846: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.70s avg)
  Warning: Large text input (11252 tokens)
Processing batches:  28%|██▊       | 423/1536 [1:45:07<2:37:04,  8.47s/it]Processing batches:  28%|██▊       | 424/1536 [1:45:18<2:48:55,  9.11s/it]  [Single] Query 845: {'GPT_EVAL': 'N/A (no eval_api_key)'} (10.17s)
Checkpoint saved: 842 queries processed

============================================================
Batch 424/1536: Processing 2 queries
============================================================
Predictions:  ['726 726 726 726 726 726 726 726 726 726 726', '3']
Answer:  ['553', '2']
Predictions:  ['726 726 726 726 726 726 726 726 726 726 726']
Answer:  ['553']
  [Batch] Query 847: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.97s avg)
Predictions:  ['3']
Answer:  ['2']
  [Batch] Query 848: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.97s avg)
Checkpoint saved: 844 queries processed

============================================================
Batch 425/1536: Processing 2 queries
============================================================
Predictions:  ['560 124']
Answer:  ['563 168']
Predictions:  ['560 124']
Answer:  ['563 168']
  [Batch] Query 849: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.08s avg)
  Warning: Large text input (18067 tokens)
Processing batches:  28%|██▊       | 425/1536 [1:45:32<3:17:40, 10.68s/it]Processing batches:  28%|██▊       | 426/1536 [1:45:35<2:36:51,  8.48s/it]Processing batches:  28%|██▊       | 427/1536 [1:45:38<2:07:16,  6.89s/it]Processing batches:  28%|██▊       | 428/1536 [1:45:47<2:18:54,  7.52s/it]Processing batches:  28%|██▊       | 429/1536 [1:45:57<2:30:02,  8.13s/it]Processing batches:  28%|██▊       | 430/1536 [1:46:07<2:40:41,  8.72s/it]Processing batches:  28%|██▊       | 431/1536 [1:46:13<2:24:54,  7.87s/it]  [Single] Query 850: {'GPT_EVAL': 'N/A (no eval_api_key)'} (11.11s)
Checkpoint saved: 846 queries processed

============================================================
Batch 426/1536: Processing 2 queries
============================================================
Predictions:  ['17 13', 'no']
Answer:  ['no', 'yes']
Predictions:  ['17 13']
Answer:  ['no']
  [Batch] Query 851: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.55s avg)
Predictions:  ['no']
Answer:  ['yes']
  [Batch] Query 852: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.55s avg)
Checkpoint saved: 848 queries processed

============================================================
Batch 427/1536: Processing 2 queries
============================================================
Predictions:  ['yes', '1']
Answer:  ['yes', '6']
Predictions:  ['yes']
Answer:  ['yes']
  [Batch] Query 853: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.38s avg)
Predictions:  ['1']
Answer:  ['6']
  [Batch] Query 854: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.38s avg)
Checkpoint saved: 850 queries processed

============================================================
Batch 428/1536: Processing 2 queries
============================================================
Predictions:  ['570 10', 'monday tuesday wednesday thursday friday saturday sunday']
Answer:  ['576 14', 'weekseparator']
Predictions:  ['570 10']
Answer:  ['576 14']
  [Batch] Query 855: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.37s avg)
Predictions:  ['monday tuesday wednesday thursday friday saturday sunday']
Answer:  ['weekseparator']
  [Batch] Query 856: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.37s avg)
Checkpoint saved: 852 queries processed

============================================================
Batch 429/1536: Processing 2 queries
============================================================
Predictions:  ['no', 'b']
Answer:  ['no', 'no']
Predictions:  ['no']
Answer:  ['no']
  [Batch] Query 857: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (4.65s avg)
Predictions:  ['b']
Answer:  ['no']
  [Batch] Query 858: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.65s avg)
Checkpoint saved: 854 queries processed

============================================================
Batch 430/1536: Processing 2 queries
============================================================
Predictions:  ['14 13', 'crew crew c']
Answer:  ['crew c', 'crew']
Predictions:  ['14 13']
Answer:  ['crew c']
  [Batch] Query 859: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.91s avg)
Predictions:  ['crew crew c']
Answer:  ['crew']
  [Batch] Query 860: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (4.91s avg)
Checkpoint saved: 856 queries processed

============================================================
Batch 431/1536: Processing 2 queries
============================================================
Predictions:  ['anderson 66 75 42', 'jackson']
Answer:  ['moore 950 890 840', 'johnson 3350']
Predictions:  ['anderson 66 75 42']
Answer:  ['moore 950 890 840']
  [Batch] Query 861: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.81s avg)
Predictions:  ['jackson']
Answer:  ['johnson 3350']
  [Batch] Query 862: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.81s avg)
Checkpoint saved: 858 queries processed

============================================================
Batch 432/1536: Processing 2 queries
============================================================
Predictions:  ['moore johnson smith jones white jackson brown harris smith smith brown taylor thomas miller davis moore johnson thomas anderson white harris anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis', '55 24']
Answer:  ['10', '75']
Predictions:  ['moore johnson smith jones white jackson brown harris smith smith brown taylor thomas miller davis moore johnson thomas anderson white harris anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis moore johnson thomas anderson jackson davis']Processing batches:  28%|██▊       | 432/1536 [1:52:15<34:58:41, 114.06s/it]
Answer:  ['10']
  [Batch] Query 863: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (180.78s avg)
Predictions:  ['55 24']
Answer:  ['75']
  [Batch] Query 864: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (180.78s avg)
Checkpoint saved: 860 queries processed

============================================================
Batch 433/1536: Processing 2 queries
============================================================
Predictions:  ['cherry tomatoes']
Answer:  ['cherry tomatoes']
Predictions:  ['cherry tomatoes']
Answer:  ['cherry tomatoes']
  [Batch] Query 866: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (0.71s avg)
  Warning: Large text input (17688 tokens)
Processing batches:  28%|██▊       | 433/1536 [1:52:24<25:18:46, 82.62s/it] Processing batches:  28%|██▊       | 434/1536 [1:52:26<17:50:44, 58.30s/it]Processing batches:  28%|██▊       | 435/1536 [1:52:31<13:00:01, 42.51s/it]Processing batches:  28%|██▊       | 436/1536 [1:52:39<9:48:55, 32.12s/it] Processing batches:  28%|██▊       | 437/1536 [1:52:47<7:35:08, 24.85s/it]  [Single] Query 865: {'GPT_EVAL': 'N/A (no eval_api_key)'} (8.40s)
Checkpoint saved: 862 queries processed

============================================================
Batch 434/1536: Processing 2 queries
============================================================
Predictions:  ['40', 'shredded cheese']
Answer:  ['4', '1']
Predictions:  ['40']
Answer:  ['4']
  [Batch] Query 867: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (0.65s avg)
Predictions:  ['shredded cheese']
Answer:  ['1']
  [Batch] Query 868: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (0.65s avg)
Checkpoint saved: 864 queries processed

============================================================
Batch 435/1536: Processing 2 queries
============================================================
Predictions:  ['butter honey mozzarella']
Answer:  ['basil butter mozzarella']
Predictions:  ['butter honey mozzarella']
Answer:  ['basil butter mozzarella']
  [Batch] Query 869: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (0.90s avg)
  [Single] Query 870: {'GPT_EVAL': 'N/A (no eval_api_key)'} (4.63s)
Checkpoint saved: 866 queries processed

============================================================
Batch 436/1536: Processing 2 queries
============================================================
Predictions:  ['rv63625', 'rv63766 rv63769']
Answer:  ['rv63625', 'rv63766']
Predictions:  ['rv63625']
Answer:  ['rv63625']
  [Batch] Query 871: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (3.82s avg)
Predictions:  ['rv63766 rv63769']
Answer:  ['rv63766']
  [Batch] Query 872: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (3.82s avg)
Checkpoint saved: 868 queries processed

============================================================
Batch 437/1536: Processing 2 queries
============================================================
Predictions:  ['6', 'rv63768 rv63755']
Answer:  ['3', 'rv63696 rv63625']
Predictions:  ['6']
Answer:  ['3']
  [Batch] Query 873: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.80s avg)
Predictions:  ['rv63768 rv63755']
Answer:  ['rv63696 rv63625']
  [Batch] Query 874: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.80s avg)
Checkpoint saved: 870 queries processed

============================================================
Batch 438/1536: Processing 2 queries
============================================================
Predictions:  ['1000 146 0']
Answer:  ['1269']
Predictions:  ['1000 146 0']
Answer:  ['1269']
  [Batch] Query 876: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.84s avg)
  Warning: Large text input (23283 tokens)
Processing batches:  29%|██▊       | 438/1536 [1:53:01<6:32:41, 21.46s/it]Processing batches:  29%|██▊       | 439/1536 [1:53:03<4:49:54, 15.86s/it]Processing batches:  29%|██▊       | 440/1536 [1:53:12<4:11:42, 13.78s/it]Processing batches:  29%|██▊       | 441/1536 [1:53:15<3:12:06, 10.53s/it]Processing batches:  29%|██▉       | 442/1536 [1:53:18<2:29:52,  8.22s/it]  [Single] Query 875: {'GPT_EVAL': 'N/A (no eval_api_key)'} (11.57s)
Checkpoint saved: 872 queries processed

============================================================
Batch 439/1536: Processing 2 queries
============================================================
Predictions:  ['mon wed sat', '113 2403']
Answer:  ['20151105 000000', '20151103 2403']
Predictions:  ['mon wed sat']
Answer:  ['20151105 000000']
  [Batch] Query 877: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.26s avg)
Predictions:  ['113 2403']
Answer:  ['20151103 2403']
  [Batch] Query 878: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (1.26s avg)
Checkpoint saved: 874 queries processed

============================================================
Batch 440/1536: Processing 2 queries
============================================================
Predictions:  ['3']
Answer:  ['5']
Predictions:  ['3']
Answer:  ['5']
  [Batch] Query 879: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.12s avg)
  [Single] Query 880: {'GPT_EVAL': 'N/A (no eval_api_key)'} (7.67s)
Checkpoint saved: 876 queries processed

============================================================
Batch 441/1536: Processing 2 queries
============================================================
Predictions:  ['no', 'black 33']
Answer:  ['yes', 'black 330']
Predictions:  ['no']
Answer:  ['yes']
  [Batch] Query 881: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.29s avg)
Predictions:  ['black 33']
Answer:  ['black 330']
  [Batch] Query 882: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (1.29s avg)
Checkpoint saved: 878 queries processed

============================================================
Batch 442/1536: Processing 2 queries
============================================================
Predictions:  ['safety green evergreen', 'black safety green']
Answer:  ['5', 'black 5040']
Predictions:  ['safety green evergreen']
Answer:  ['5']
  [Batch] Query 883: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.29s avg)
Predictions:  ['black safety green']
Answer:  ['black 5040']
  [Batch] Query 884: {'F1': 40.0, 'EM': 0.0, 'ROUGE-L': 40.0, 'SacreBLEU': 0.0} (1.29s avg)
Checkpoint saved: 880 queries processed

============================================================
Batch 443/1536: Processing 2 queries
============================================================
Predictions:  ['384 stoke ac']
Answer:  ['384 stoke ac']
Predictions:  ['384 stoke ac']
Answer:  ['384 stoke ac']
  [Batch] Query 886: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.29s avg)
  Warning: Large text input (8979 tokens)
Processing batches:  29%|██▉       | 443/1536 [1:53:32<3:01:55,  9.99s/it]Processing batches:  29%|██▉       | 444/1536 [1:53:34<2:19:00,  7.64s/it]Processing batches:  29%|██▉       | 445/1536 [1:53:46<2:38:16,  8.70s/it]Processing batches:  29%|██▉       | 446/1536 [1:53:49<2:12:17,  7.28s/it]Processing batches:  29%|██▉       | 447/1536 [1:53:54<1:57:32,  6.48s/it]  [Single] Query 885: {'GPT_EVAL': 'N/A (no eval_api_key)'} (12.68s)
Checkpoint saved: 882 queries processed

============================================================
Batch 444/1536: Processing 2 queries
============================================================
Predictions:  ['5 413', 'jimmy craig nick treitl']
Answer:  ['50 413', '3']
Predictions:  ['5 413']
Answer:  ['50 413']
  [Batch] Query 887: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (0.95s avg)
Predictions:  ['jimmy craig nick treitl']
Answer:  ['3']
  [Batch] Query 888: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (0.95s avg)
Checkpoint saved: 884 queries processed

============================================================
Batch 445/1536: Processing 2 queries
============================================================
Predictions:  ['5']
Answer:  ['5']
Predictions:  ['5']
Answer:  ['5']
  [Batch] Query 889: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.34s avg)
  [Single] Query 890: {'GPT_EVAL': 'N/A (no eval_api_key)'} (9.71s)
Checkpoint saved: 886 queries processed

============================================================
Batch 446/1536: Processing 2 queries
============================================================
Predictions:  ['1943', 'inbound week 2 schedule week 2']
Answer:  ['1943', 'schedule week 2 694']
Predictions:  ['1943']
Answer:  ['1943']
  [Batch] Query 891: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.85s avg)
Predictions:  ['inbound week 2 schedule week 2']
Answer:  ['schedule week 2 694']
  [Batch] Query 892: {'F1': 60.0, 'EM': 0.0, 'ROUGE-L': 60.0, 'SacreBLEU': 30.21} (1.85s avg)
Checkpoint saved: 888 queries processed

============================================================
Batch 447/1536: Processing 2 queries
============================================================
Predictions:  ['inbound fc followup cwr followup ref genration expert helpdesk', 'fc followup week 1 outbond week 2']
Answer:  ['3', 'outbond week 2 05']
Predictions:  ['inbound fc followup cwr followup ref genration expert helpdesk']
Answer:  ['3']
  [Batch] Query 893: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.17s avg)
Predictions:  ['fc followup week 1 outbond week 2']
Answer:  ['outbond week 2 05']
  [Batch] Query 894: {'F1': 54.55, 'EM': 0.0, 'ROUGE-L': 54.55, 'SacreBLEU': 24.45} (2.17s avg)
Checkpoint saved: 890 queries processed

============================================================
Batch 448/1536: Processing 2 queries
============================================================
Predictions:  ['2011']
Answer:  ['2011']
Predictions:  ['2011']
Answer:  ['2011']
  [Batch] Query 896: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.50s avg)
  Warning: Large text input (12158 tokens)
Processing batches:  29%|██▉       | 448/1536 [1:54:07<2:34:01,  8.49s/it]Processing batches:  29%|██▉       | 449/1536 [1:54:10<2:04:10,  6.85s/it]  [Single] Query 895: {'GPT_EVAL': 'N/A (no eval_api_key)'} (11.56s)
Checkpoint saved: 892 queries processed

============================================================
Batch 449/1536: Processing 2 queries
============================================================
Predictions:  ['2008', '31 57']
Answer:  ['1989', '36']
Predictions:  ['2008']
Answer:  ['1989']
  [Batch] Query 897: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.38s avg)
Predictions:  ['31 57']
Answer:  ['36']
  [Batch] Query 898: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.38s avg)
Checkpoint saved: 894 queries processed

============================================================
Batch 450/1536: Processing 2 queries
============================================================
Predictions:  ['2010']
Answer:  ['1992']
Predictions:  ['2010']
Answer:  ['1992']
  [Batch] Query 899: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.52s avg)
  Warning: Large text input (9338 tokens)
Processing batches:  29%|██▉       | 450/1536 [1:54:20<2:20:32,  7.77s/it]Processing batches:  29%|██▉       | 451/1536 [1:54:28<2:18:48,  7.68s/it]Processing batches:  29%|██▉       | 452/1536 [1:54:35<2:14:40,  7.45s/it]  [Single] Query 900: {'GPT_EVAL': 'N/A (no eval_api_key)'} (8.23s)
Checkpoint saved: 896 queries processed

============================================================
Batch 451/1536: Processing 2 queries
============================================================
Predictions:  ['feb0115 feb0715', '00']
Answer:  ['feb0115 feb0715', '13']
Predictions:  ['feb0115 feb0715']
Answer:  ['feb0115 feb0715']
  [Batch] Query 901: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (3.60s avg)
Predictions:  ['00']
Answer:  ['13']
  [Batch] Query 902: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.60s avg)
Checkpoint saved: 898 queries processed

============================================================
Batch 452/1536: Processing 2 queries
============================================================
Predictions:  ['mongoose wild', '97275']
Answer:  ['wild mongoose', '43275']
Predictions:  ['mongoose wild']
Answer:  ['wild mongoose']
  [Batch] Query 903: {'F1': 100.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (3.34s avg)
Predictions:  ['97275']
Answer:  ['43275']
  [Batch] Query 904: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.34s avg)
Checkpoint saved: 900 queries processed

============================================================
Batch 453/1536: Processing 2 queries
============================================================
Predictions:  ['chain up']
Answer:  ['chain up']
Predictions:  ['chain up']
Answer:  ['chain up']
  [Batch] Query 906: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (3.09s avg)
  Warning: Large text input (21896 tokens)
Processing batches:  29%|██▉       | 453/1536 [1:54:49<2:53:20,  9.60s/it]Processing batches:  30%|██▉       | 454/1536 [1:54:56<2:37:20,  8.73s/it]  [Single] Query 905: {'GPT_EVAL': 'N/A (no eval_api_key)'} (11.39s)
Checkpoint saved: 902 queries processed

============================================================
Batch 454/1536: Processing 2 queries
============================================================
Predictions:  ['mburger', 'ebt wild']
Answer:  ['mburger', 'ebt wild']
Predictions:  ['mburger']
Answer:  ['mburger']
  [Batch] Query 907: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (3.21s avg)
Predictions:  ['ebt wild']
Answer:  ['ebt wild']
  [Batch] Query 908: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (3.21s avg)
Checkpoint saved: 904 queries processed

============================================================
Batch 455/1536: Processing 2 queries
============================================================
Predictions:  ['7']
Answer:  ['10']
Predictions:  ['7']
Answer:  ['10']
  [Batch] Query 909: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.07s avg)
  Warning: Large text input (22083 tokens)
Processing batches:  30%|██▉       | 455/1536 [1:55:13<3:19:58, 11.10s/it]Processing batches:  30%|██▉       | 456/1536 [1:55:25<3:28:56, 11.61s/it]Processing batches:  30%|██▉       | 457/1536 [1:55:35<3:18:12, 11.02s/it]Processing batches:  30%|██▉       | 458/1536 [1:55:46<3:18:25, 11.04s/it]Processing batches:  30%|██▉       | 459/1536 [2:00:13<26:13:55, 87.68s/it]  [Single] Query 910: {'GPT_EVAL': 'N/A (no eval_api_key)'} (13.42s)
Checkpoint saved: 906 queries processed

============================================================
Batch 456/1536: Processing 2 queries
============================================================
Predictions:  ['10000 10000 10000 10000 10000 10000', '240002400017000195001950019500']
Answer:  ['104400', '546800']
Predictions:  ['10000 10000 10000 10000 10000 10000']
Answer:  ['104400']
  [Batch] Query 911: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (6.26s avg)
Predictions:  ['240002400017000195001950019500']
Answer:  ['546800']
  [Batch] Query 912: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (6.26s avg)
Checkpoint saved: 908 queries processed

============================================================
Batch 457/1536: Processing 2 queries
============================================================
Predictions:  ['belgravia chelsea maida vale selfridges', 'chelsea maida vale']
Answer:  ['3', 'chelsea']
Predictions:  ['belgravia chelsea maida vale selfridges']
Answer:  ['3']
  [Batch] Query 913: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.70s avg)
Predictions:  ['chelsea maida vale']
Answer:  ['chelsea']
  [Batch] Query 914: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (4.70s avg)
Checkpoint saved: 910 queries processed

============================================================
Batch 458/1536: Processing 2 queries
============================================================
Predictions:  ['110000', 'arthur horton valerio schmid rogelio melf randy torres jessi staples ruben hunter john cambra']
Answer:  ['107333', 'arthur horton rogelio melf randy torres jessi staples john cambra randy boyd']
Predictions:  ['110000']
Answer:  ['107333']
  [Batch] Query 915: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (5.42s avg)
Predictions:  ['arthur horton valerio schmid rogelio melf randy torres jessi staples ruben hunter john cambra']
Answer:  ['arthur horton rogelio melf randy torres jessi staples john cambra randy boyd']
  [Batch] Query 916: {'F1': 76.92, 'EM': 0.0, 'ROUGE-L': 76.92, 'SacreBLEU': 43.24} (5.42s avg)
Checkpoint saved: 912 queries processed

============================================================
Batch 459/1536: Processing 2 queries
============================================================
Predictions:  ['15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 1', 'sente hammond hewitt field jones marks smith kitt horton sever cambra green hunter staples torres melf jart eacret boyd riblet']
Answer:  ['12', 'shane hewitt']
Predictions:  ['15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 1']
Answer:  ['12']
  [Batch] Query 917: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (133.13s avg)
Predictions:  ['sente hammond hewitt field jones marks smith kitt horton sever cambra green hunter staples torres melf jart eacret boyd riblet']
Answer:  ['shane hewitt']
  [Batch] Query 918: {'F1': 9.09, 'EM': 0.0, 'ROUGE-L': 9.09, 'SacreBLEU': 1.91} (133.13s avg)
Checkpoint saved: 914 queries processed

============================================================
Batch 460/1536: Processing 2 queries
============================================================
Predictions:  ['teresa field', 'arthur horton rogelio melf ruben hunter john cambra']
Answer:  Processing batches:  30%|██▉       | 460/1536 [2:00:16<18:40:06, 62.46s/it]Processing batches:  30%|███       | 461/1536 [2:00:19<13:16:06, 44.43s/it]Processing batches:  30%|███       | 462/1536 [2:00:21<9:31:10, 31.91s/it] Processing batches:  30%|███       | 463/1536 [2:00:24<6:53:34, 23.13s/it]['arthur horton', 'arthur horton rogelio melf randy torres jessi staples john cambra randy boyd']
Predictions:  ['teresa field']
Answer:  ['arthur horton']
  [Batch] Query 919: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.67s avg)
Predictions:  ['arthur horton rogelio melf ruben hunter john cambra']
Answer:  ['arthur horton rogelio melf randy torres jessi staples john cambra randy boyd']
  [Batch] Query 920: {'F1': 60.0, 'EM': 0.0, 'ROUGE-L': 60.0, 'SacreBLEU': 24.94} (1.67s avg)
Checkpoint saved: 916 queries processed

============================================================
Batch 461/1536: Processing 2 queries
============================================================
Predictions:  ['no']
Answer:  ['no']
Predictions:  ['no']
Answer:  ['no']
  [Batch] Query 922: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.25s avg)
  [Single] Query 921: {'GPT_EVAL': 'N/A (no eval_api_key)'} (0.98s)
Checkpoint saved: 918 queries processed

============================================================
Batch 462/1536: Processing 2 queries
============================================================
Predictions:  ['bill billings', 'done in progress']
Answer:  ['bill billings', 'done']
Predictions:  ['bill billings']
Answer:  ['bill billings']
  [Batch] Query 923: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.22s avg)
Predictions:  ['done in progress']
Answer:  ['done']
  [Batch] Query 924: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (1.22s avg)
Checkpoint saved: 920 queries processed

============================================================
Batch 463/1536: Processing 2 queries
============================================================
Predictions:  ['charlie cadsworth', 'no']
Answer:  ['bill billings', 'no']
Predictions:  ['charlie cadsworth']
Answer:  ['bill billings']
  [Batch] Query 925: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.19s avg)
Predictions:  ['no']
Answer:  ['no']
  [Batch] Query 926: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.19s avg)
Checkpoint saved: 922 queries processed

============================================================
Batch 464/1536: Processing 2 queries
============================================================
Predictions:  ['feb2014 jan2014']
Answer:  ['february']
Predictions:  ['feb2014 jan2014']
Answer:  ['february']
  [Batch] Query 928: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.69s avg)
  Warning: Large text input (8712 tokens)
Processing batches:  30%|███       | 464/1536 [2:00:36<5:55:42, 19.91s/it]Processing batches:  30%|███       | 465/1536 [2:00:44<4:50:02, 16.25s/it]  [Single] Query 927: {'GPT_EVAL': 'N/A (no eval_api_key)'} (8.57s)
Checkpoint saved: 924 queries processed

============================================================
Batch 465/1536: Processing 2 queries
============================================================
Predictions:  ['nov', '4800 2833']
Answer:  ['oct 2014', '3667']
Predictions:  ['nov']
Answer:  ['oct 2014']
  [Batch] Query 929: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.73s avg)
Predictions:  ['4800 2833']
Answer:  ['3667']
  [Batch] Query 930: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.73s avg)
Checkpoint saved: 926 queries processed

============================================================
Batch 466/1536: Processing 2 queries
============================================================
Predictions:  ['2083 2500 2800 2000 00 1667 2833 1667 833 833 1250']
Answer:  ['1847']
Predictions:  ['2083 2500 2800 2000 00 1667 2833 1667 833 833 1250']
Answer:  ['1847']
  [Batch] Query 931: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (7.52s avg)
  Warning: Large text input (22562 tokens)
Processing batches:  30%|███       | 466/1536 [2:01:03<5:02:01, 16.94s/it]Processing batches:  30%|███       | 467/1536 [2:01:09<4:07:33, 13.89s/it]Processing batches:  30%|███       | 468/1536 [2:01:13<3:15:16, 10.97s/it]  [Single] Query 932: {'GPT_EVAL': 'N/A (no eval_api_key)'} (10.88s)
Checkpoint saved: 928 queries processed

============================================================
Batch 467/1536: Processing 2 queries
============================================================
Predictions:  ['feb2014 jan2014', '20141213']
Answer:  ['february', '20141206']
Predictions:  ['feb2014 jan2014']
Answer:  ['february']
  [Batch] Query 933: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.12s avg)
Predictions:  ['20141213']
Answer:  ['20141206']
  [Batch] Query 934: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.12s avg)
Checkpoint saved: 930 queries processed

============================================================
Batch 468/1536: Processing 2 queries
============================================================
Predictions:  ['20141216 20141217', '400']
Answer:  ['no', '43']
Predictions:  ['20141216 20141217']
Answer:  ['no']
  [Batch] Query 935: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.94s avg)
Predictions:  ['400']
Answer:  ['43']
  [Batch] Query 936: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.94s avg)
Checkpoint saved: 932 queries processed

============================================================
Batch 469/1536: Processing 2 queries
============================================================
Predictions:  ['3']
Answer:  ['5']
Predictions:  ['3']
Answer:  ['5']
  [Batch] Query 937: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.38s avg)
  Warning: Large text input (9553 tokens)
Processing batches:  31%|███       | 469/1536 [2:01:20<2:49:41,  9.54s/it]Processing batches:  31%|███       | 470/1536 [2:01:24<2:18:56,  7.82s/it]Processing batches:  31%|███       | 471/1536 [2:01:26<1:48:35,  6.12s/it]Processing batches:  31%|███       | 472/1536 [2:01:36<2:08:45,  7.26s/it]Processing batches:  31%|███       | 473/1536 [2:01:40<1:52:45,  6.36s/it]Processing batches:  31%|███       | 474/1536 [2:01:44<1:41:33,  5.74s/it]  [Single] Query 938: {'GPT_EVAL': 'N/A (no eval_api_key)'} (4.69s)
Checkpoint saved: 934 queries processed

============================================================
Batch 470/1536: Processing 2 queries
============================================================
Predictions:  ['20141213', '212012 512014']
Answer:  ['20141206', '20120201 20140501']
Predictions:  ['20141213']
Answer:  ['20141206']
  [Batch] Query 939: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.77s avg)
Predictions:  ['212012 512014']
Answer:  ['20120201 20140501']
  [Batch] Query 940: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.77s avg)
Checkpoint saved: 936 queries processed

============================================================
Batch 471/1536: Processing 2 queries
============================================================
Predictions:  ['b', 'aa']
Answer:  ['', 'b']
Predictions:  ['b']
Answer:  ['']
  [Batch] Query 941: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (0.94s avg)
Predictions:  ['aa']
Answer:  ['b']
  [Batch] Query 942: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (0.94s avg)
Checkpoint saved: 938 queries processed

============================================================
Batch 472/1536: Processing 2 queries
============================================================
Predictions:  ['c']
Answer:  ['4']
Predictions:  ['c']
Answer:  ['4']
  [Batch] Query 943: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.10s avg)
  [Single] Query 944: {'GPT_EVAL': 'N/A (no eval_api_key)'} (8.68s)
Checkpoint saved: 940 queries processed

============================================================
Batch 473/1536: Processing 2 queries
============================================================
Predictions:  ['sp braga', 'sp braga benfica fc porto rio ave']
Answer:  ['sp braga v guimarães belenenses ffc porto rio ave moreirense', 'benfica fc porto rio ave']
Predictions:  ['sp braga']
Answer:  ['sp braga v guimarães belenenses ffc porto rio ave moreirense']
  [Batch] Query 945: {'F1': 33.33, 'EM': 0.0, 'ROUGE-L': 30.77, 'SacreBLEU': 0.0} (2.01s avg)
Predictions:  ['sp braga benfica fc porto rio ave']
Answer:  ['benfica fc porto rio ave']
  [Batch] Query 946: {'F1': 83.33, 'EM': 0.0, 'ROUGE-L': 83.33, 'SacreBLEU': 61.48} (2.01s avg)
Checkpoint saved: 942 queries processed

============================================================
Batch 474/1536: Processing 2 queries
============================================================
Predictions:  ['sp braga benfica fc porto rio ave', 'sp braga']
Answer:  ['6', 'sp braga v guimarães belenenses']
Predictions:  ['sp braga benfica fc porto rio ave']
Answer:  ['6']
  [Batch] Query 947: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.01s avg)
Predictions:  ['sp braga']
Answer:  ['sp braga v guimarães belenenses']
  [Batch] Query 948: {'F1': 57.14, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (2.01s avg)
Checkpoint saved: 944 queries processed

============================================================
Batch 475/1536: Processing 2 queries
============================================================
Predictions:  ['2406']
Answer:  ['2406']
Predictions:  ['2406']
Answer:  ['2406']
  [Batch] Query 950: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (5.58s avg)
  Warning: Large text input (11834 tokens)
Processing batches:  31%|███       | 475/1536 [2:01:52<1:54:28,  6.47s/it]Processing batches:  31%|███       | 476/1536 [2:02:04<2:20:39,  7.96s/it]  [Single] Query 949: {'GPT_EVAL': 'N/A (no eval_api_key)'} (2.46s)
Checkpoint saved: 946 queries processed

============================================================
Batch 476/1536: Processing 2 queries
============================================================
Predictions:  ['sive2024cbo31768', 'cbo lbi gbh iba']
Answer:  ['sive2024cbo31768', '4 centeral branch o lower branch i ground branch h inter branch']
Predictions:  ['sive2024cbo31768']
Answer:  ['sive2024cbo31768']
  [Batch] Query 951: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (5.59s avg)
Predictions:  ['cbo lbi gbh iba']
Answer:  ['4 centeral branch o lower branch i ground branch h inter branch']
  [Batch] Query 952: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (5.59s avg)
Checkpoint saved: 948 queries processed

============================================================
Batch 477/1536: Processing 2 queries
============================================================
Predictions:  ['dragon pvt ltd g co pvt']
Answer:  ['g co pvt']
Predictions:  ['dragon pvt ltd g co pvt']
Answer:  ['g co pvt']
  [Batch] Query 953: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 30.21} (5.62s avg)
  Warning: Large text input (31807 tokens)
Processing batches:  31%|███       | 477/1536 [2:02:25<3:28:35, 11.82s/it]Processing batches:  31%|███       | 478/1536 [2:02:36<3:26:47, 11.73s/it]Processing batches:  31%|███       | 479/1536 [2:02:48<3:25:35, 11.67s/it]  [Single] Query 954: {'GPT_EVAL': 'N/A (no eval_api_key)'} (15.06s)
Checkpoint saved: 950 queries processed

============================================================
Batch 478/1536: Processing 2 queries
============================================================
Predictions:  ['24jul14 it is date of table header and serves as reference point for events listed which span from 16aug14 to 28sep14', 'em2058 corona sunsets']
Answer:  ['20140724 contextual date', 'em2058 corona sunsets']
Predictions:  ['24jul14 it is date of table header and serves as reference point for events listed which span from 16aug14 to 28sep14']
Answer:  ['20140724 contextual date']
  [Batch] Query 955: {'F1': 8.33, 'EM': 0.0, 'ROUGE-L': 8.33, 'SacreBLEU': 1.82} (5.63s avg)
Predictions:  ['em2058 corona sunsets']
Answer:  ['em2058 corona sunsets']
  [Batch] Query 956: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (5.63s avg)
Checkpoint saved: 952 queries processed

============================================================
Batch 479/1536: Processing 2 queries
============================================================
Predictions:  ['1391', '24jul14 it is date of table header and serves as reference point for events listed which span from 16aug14 to 28sep14']
Answer:  ['1391', '20140724 contextual date']
Predictions:  ['1391']
Answer:  ['1391']
  [Batch] Query 957: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (5.64s avg)
Predictions:  ['24jul14 it is date of table header and serves as reference point for events listed which span from 16aug14 to 28sep14']
Answer:  ['20140724 contextual date']
  [Batch] Query 958: {'F1': 8.33, 'EM': 0.0, 'ROUGE-L': 8.33, 'SacreBLEU': 1.82} (5.64s avg)
Checkpoint saved: 954 queries processed

============================================================
Batch 480/1536: Processing 2 queries
============================================================
Predictions:  ['august 2014 september 2014']
Answer:  ['august 2014']
Predictions:  ['august 2014 september 2014']
Answer:  ['august 2014']
  [Batch] Query 959: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 31.95} (4.07s avg)
  Warning: Large text input (24381 tokens)
Processing batches:  31%|███▏      | 480/1536 [2:03:03<3:43:32, 12.70s/it]Traceback (most recent call last):
  File "/export/home/pan/4xin/RealHiTBENCH-Qwen3-VL/inference/inference_qwen3vl_local_a100.py", line 1186, in gen_solution_batch
    batch_results = process_batch_queries(
  File "/export/home/pan/4xin/RealHiTBENCH-Qwen3-VL/inference/inference_qwen3vl_local_a100.py", line 955, in process_batch_queries
    batch_responses = get_batch_final_answers_local(
  File "/export/home/pan/4xin/RealHiTBENCH-Qwen3-VL/inference/inference_qwen3vl_local_a100.py", line 590, in get_batch_final_answers_local
    responses = get_batch_text_response_local(pending_messages, model, processor, opt)
  File "/export/home/pan/4xin/RealHiTBENCH-Qwen3-VL/inference/inference_qwen3vl_local_a100.py", line 533, in get_batch_text_response_local
    generated_ids = base_model.generate(**generate_kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/generation/utils.py", line 2566, in generate
    result = decoding_method(
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/generation/utils.py", line 2786, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/models/qwen3_vl/modeling_qwen3_vl.py", line 1344, in forward
    outputs = self.model(
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/models/qwen3_vl/modeling_qwen3_vl.py", line 1223, in forward
    outputs = self.language_model(
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/models/qwen3_vl/modeling_qwen3_vl.py", line 850, in forward
    layer_outputs = decoder_layer(
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/models/qwen3_vl/modeling_qwen3_vl.py", line 517, in forward
    hidden_states = self.mlp(hidden_states)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/models/qwen3_vl/modeling_qwen3_vl.py", line 472, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.85 GiB. GPU 0 has a total capacity of 79.25 GiB of which 4.68 GiB is free. Including non-PyTorch memory, this process has 74.57 GiB memory in use. Of the allocated memory 57.44 GiB is allocated by PyTorch, and 16.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing batches:  31%|███▏      | 481/1536 [2:03:52<6:54:06, 23.55s/it]Traceback (most recent call last):
  File "/export/home/pan/4xin/RealHiTBENCH-Qwen3-VL/inference/inference_qwen3vl_local_a100.py", line 1186, in gen_solution_batch
    batch_results = process_batch_queries(
  File "/export/home/pan/4xin/RealHiTBENCH-Qwen3-VL/inference/inference_qwen3vl_local_a100.py", line 955, in process_batch_queries
    batch_responses = get_batch_final_answers_local(
  File "/export/home/pan/4xin/RealHiTBENCH-Qwen3-VL/inference/inference_qwen3vl_local_a100.py", line 590, in get_batch_final_answers_local
    responses = get_batch_text_response_local(pending_messages, model, processor, opt)
  File "/export/home/pan/4xin/RealHiTBENCH-Qwen3-VL/inference/inference_qwen3vl_local_a100.py", line 533, in get_batch_text_response_local
    generated_ids = base_model.generate(**generate_kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/generation/utils.py", line 2566, in generate
    result = decoding_method(
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/generation/utils.py", line 2786, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/models/qwen3_vl/modeling_qwen3_vl.py", line 1344, in forward
    outputs = self.model(
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/models/qwen3_vl/modeling_qwen3_vl.py", line 1223, in forward
    outputs = self.language_model(
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/models/qwen3_vl/modeling_qwen3_vl.py", line 850, in forward
    layer_outputs = decoder_layer(
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/models/qwen3_vl/modeling_qwen3_vl.py", line 517, in forward
    hidden_states = self.mlp(hidden_states)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/models/qwen3_vl/modeling_qwen3_vl.py", line 472, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 5.85 GiB. GPU 0 has a total capacity of 79.25 GiB of which 4.68 GiB is free. Including non-PyTorch memory, this process has 74.57 GiB memory in use. Of the allocated memory 57.44 GiB is allocated by PyTorch, and 16.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing batches:  31%|███▏      | 482/1536 [2:04:40<9:04:56, 31.02s/it]  [Single] Query 960: {'GPT_EVAL': 'N/A (no eval_api_key)'} (10.90s)
Checkpoint saved: 956 queries processed

============================================================
Batch 481/1536: Processing 2 queries
============================================================
Error processing batch 481: CUDA out of memory. Tried to allocate 5.85 GiB. GPU 0 has a total capacity of 79.25 GiB of which 4.68 GiB is free. Including non-PyTorch memory, this process has 74.57 GiB memory in use. Of the allocated memory 57.44 GiB is allocated by PyTorch, and 16.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

============================================================
Batch 482/1536: Processing 2 queries
============================================================
Error processing batch 482: CUDA out of memory. Tried to allocate 5.85 GiB. GPU 0 has a total capacity of 79.25 GiB of which 4.68 GiB is free. Including non-PyTorch memory, this process has 74.57 GiB memory in use. Of the allocated memory 57.44 GiB is allocated by PyTorch, and 16.63 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)

============================================================
Batch 483/1536: Processing 2 queries
============================================================
Predictions:  ['04 2014']
Answer:  ['04 2014']
Predictions:  ['04 2014']
Answer:  ['04 2014']
  [Batch] Query 966: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (41.92s avg)
  Warning: Large text input (127843 tokens)
Processing batches:  31%|███▏      | 483/1536 [2:06:19<15:03:19, 51.47s/it]Processing batches:  32%|███▏      | 484/1536 [2:06:24<10:55:46, 37.40s/it]Processing batches:  32%|███▏      | 485/1536 [2:06:27<7:56:49, 27.22s/it]   [Single] Query 965: {'GPT_EVAL': 'N/A (no eval_api_key)'} (57.13s)
Checkpoint saved: 958 queries processed

============================================================
Batch 484/1536: Processing 2 queries
============================================================
Predictions:  ['4494332843598448134540537349', '7162014 22']
Answer:  ['214942', '20140716 12']
Predictions:  ['4494332843598448134540537349']
Answer:  ['214942']
  [Batch] Query 967: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.15s avg)
Predictions:  ['7162014 22']
Answer:  ['20140716 12']
  [Batch] Query 968: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.15s avg)
Checkpoint saved: 960 queries processed

============================================================
Batch 485/1536: Processing 2 queries
============================================================
Predictions:  ['3', '7162014 22']
Answer:  ['1', '20140716 12']
Predictions:  ['3']
Answer:  ['1']
  [Batch] Query 969: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.60s avg)
Predictions:  ['7162014 22']
Answer:  ['20140716 12']
  [Batch] Query 970: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.60s avg)
Checkpoint saved: 962 queries processed

============================================================
Batch 486/1536: Processing 2 queries
============================================================
Predictions:  ['7162014 7162014']
Answer:  ['last row']
Predictions:  ['7162014 7162014']
Answer:  ['last row']
  [Batch] Query 971: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.10s avg)
  Warning: Large text input (8006 tokens)
Processing batches:  32%|███▏      | 486/1536 [2:06:33<6:06:01, 20.92s/it]Processing batches:  32%|███▏      | 487/1536 [2:06:38<4:39:48, 16.00s/it]Processing batches:  32%|███▏      | 488/1536 [2:06:42<3:36:24, 12.39s/it]  [Single] Query 972: {'GPT_EVAL': 'N/A (no eval_api_key)'} (3.96s)
Checkpoint saved: 964 queries processed

============================================================
Batch 487/1536: Processing 2 queries
============================================================
Predictions:  ['336000', 'gratuity employers provident fund contribution employers esi contribution medical insurance peformance incentive']
Answer:  ['336000', 'gratuity employers provident fund contribution employers esi contribution medical insurance performance incentive']
Predictions:  ['336000']
Answer:  ['336000']
  [Batch] Query 973: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.88s avg)
Predictions:  ['gratuity employers provident fund contribution employers esi contribution medical insurance peformance incentive']
Answer:  ['gratuity employers provident fund contribution employers esi contribution medical insurance performance incentive']
  [Batch] Query 974: {'F1': 91.67, 'EM': 0.0, 'ROUGE-L': 91.67, 'SacreBLEU': 82.65} (1.88s avg)
Checkpoint saved: 966 queries processed

============================================================
Batch 488/1536: Processing 2 queries
============================================================
Predictions:  ['basic salary hra special allowance transport allowance medical reimbursement', 'medical insurance medical reimbursement']
Answer:  ['basic salary special allowance hra medical reimbursement transport allowance', 'medical reimbursement']
Predictions:  ['basic salary hra special allowance transport allowance medical reimbursement']
Answer:  ['basic salary special allowance hra medical reimbursement transport allowance']
  [Batch] Query 975: {'F1': 100.0, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 19.64} (1.85s avg)
Predictions:  ['medical insurance medical reimbursement']
Answer:  ['medical reimbursement']
  [Batch] Query 976: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 31.95} (1.85s avg)
Checkpoint saved: 968 queries processed

============================================================
Batch 489/1536: Processing 2 queries
============================================================
Predictions:  ['336000']
Answer:  ['336000']
Predictions:  ['336000']
Answer:  ['336000']
  [Batch] Query 977: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.55s avg)
  Warning: Large text input (8862 tokens)
Processing batches:  32%|███▏      | 489/1536 [2:06:54<3:31:46, 12.14s/it]Processing batches:  32%|███▏      | 490/1536 [2:06:56<2:41:42,  9.28s/it]Processing batches:  32%|███▏      | 491/1536 [2:06:59<2:09:11,  7.42s/it]Processing batches:  32%|███▏      | 492/1536 [2:07:13<2:44:20,  9.45s/it]Processing batches:  32%|███▏      | 493/1536 [2:07:26<3:03:15, 10.54s/it]  [Single] Query 978: {'GPT_EVAL': 'N/A (no eval_api_key)'} (9.85s)
Checkpoint saved: 970 queries processed

============================================================
Batch 490/1536: Processing 2 queries
============================================================
Predictions:  ['13557', 'mobile department other department']
Answer:  ['13557', 'mobile department']
Predictions:  ['13557']
Answer:  ['13557']
  [Batch] Query 979: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.17s avg)
Predictions:  ['mobile department other department']
Answer:  ['mobile department']
  [Batch] Query 980: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 31.95} (1.17s avg)
Checkpoint saved: 972 queries processed

============================================================
Batch 491/1536: Processing 2 queries
============================================================
Predictions:  ['workstation register', '94']
Answer:  ['2', '94']
Predictions:  ['workstation register']
Answer:  ['2']
  [Batch] Query 981: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.41s avg)
Predictions:  ['94']
Answer:  ['94']
  [Batch] Query 982: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.41s avg)
Checkpoint saved: 974 queries processed

============================================================
Batch 492/1536: Processing 2 queries
============================================================
Predictions:  ['eur aud']
Answer:  ['australia']
Predictions:  ['eur aud']
Answer:  ['australia']
  [Batch] Query 984: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (5.57s avg)
  [Single] Query 983: {'GPT_EVAL': 'N/A (no eval_api_key)'} (8.46s)
Checkpoint saved: 976 queries processed

============================================================
Batch 493/1536: Processing 2 queries
============================================================
Predictions:  ['mg', '3month premium subscription 1month premium subscription']
Answer:  ['mg', '1month premium subscription']
Predictions:  ['mg']
Answer:  ['mg']
  [Batch] Query 985: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (6.42s avg)
Predictions:  ['3month premium subscription 1month premium subscription']
Answer:  ['1month premium subscription']
  [Batch] Query 986: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 30.21} (6.42s avg)
Checkpoint saved: 978 queries processed

============================================================
Batch 494/1536: Processing 2 queries
============================================================
Predictions:  ['canada japan']
Answer:  ['canada']
Predictions:  ['canada japan']
Answer:  ['canada']
  [Batch] Query 987: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (5.58s avg)
  Warning: Large text input (35612 tokens)
Processing batches:  32%|███▏      | 494/1536 [2:07:43<3:32:54, 12.26s/it]Processing batches:  32%|███▏      | 495/1536 [2:07:46<2:44:41,  9.49s/it]Processing batches:  32%|███▏      | 496/1536 [2:07:49<2:10:19,  7.52s/it]Processing batches:  32%|███▏      | 497/1536 [2:07:59<2:22:22,  8.22s/it]Processing batches:  32%|███▏      | 498/1536 [2:08:03<2:03:32,  7.14s/it]  [Single] Query 988: {'GPT_EVAL': 'N/A (no eval_api_key)'} (10.55s)
Checkpoint saved: 980 queries processed

============================================================
Batch 495/1536: Processing 2 queries
============================================================
Predictions:  ['new activation add line plan change upgrade', '1804 450 1946 3169']
Answer:  ['new activation add line plan change upgrade', '7369']
Predictions:  ['new activation add line plan change upgrade']
Answer:  ['new activation add line plan change upgrade']
  [Batch] Query 989: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (1.39s avg)
Predictions:  ['1804 450 1946 3169']
Answer:  ['7369']
  [Batch] Query 990: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.39s avg)
Checkpoint saved: 982 queries processed

============================================================
Batch 496/1536: Processing 2 queries
============================================================
Predictions:  ['spr 206', '142 142 146']
Answer:  ['spr 206', '143']
Predictions:  ['spr 206']
Answer:  ['spr 206']
  [Batch] Query 991: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.33s avg)
Predictions:  ['142 142 146']
Answer:  ['143']
  [Batch] Query 992: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.33s avg)
Checkpoint saved: 984 queries processed

============================================================
Batch 497/1536: Processing 2 queries
============================================================
Predictions:  ['dnago 10048']
Answer:  ['dnago 10048']
Predictions:  ['dnago 10048']
Answer:  ['dnago 10048']
  [Batch] Query 994: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (2.08s avg)
  [Single] Query 993: {'GPT_EVAL': 'N/A (no eval_api_key)'} (7.64s)
Checkpoint saved: 986 queries processed

============================================================
Batch 498/1536: Processing 2 queries
============================================================
Predictions:  ['24789', 'spress dnago milani belani merili pitali']
Answer:  ['24789', '6']
Predictions:  ['24789']
Answer:  ['24789']
  [Batch] Query 995: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (2.18s avg)
Predictions:  ['spress dnago milani belani merili pitali']
Answer:  ['6']
  [Batch] Query 996: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.18s avg)
Checkpoint saved: 988 queries processed

============================================================
Batch 499/1536: Processing 2 queries
============================================================
Predictions:  ['milani 2879']
Answer:  ['milani 2879']
Predictions:  ['milani 2879']
Answer:  ['milani 2879']
  [Batch] Query 997: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (2.04s avg)
  Warning: Large text input (12543 tokens)
Processing batches:  32%|███▏      | 499/1536 [2:08:16<2:31:05,  8.74s/it]Processing batches:  33%|███▎      | 500/1536 [2:08:21<2:15:43,  7.86s/it]Processing batches:  33%|███▎      | 501/1536 [2:08:28<2:06:33,  7.34s/it]  [Single] Query 998: {'GPT_EVAL': 'N/A (no eval_api_key)'} (10.29s)
Checkpoint saved: 990 queries processed

============================================================
Batch 500/1536: Processing 2 queries
============================================================
Predictions:  ['11400083', '2087427 2078869 180431 446076 60609 353666 87772']
Answer:  ['26227642', 'francois chevalier 8607203 global bob 10388812']
Predictions:  ['11400083']
Answer:  ['26227642']
  [Batch] Query 999: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.77s avg)
Predictions:  ['2087427 2078869 180431 446076 60609 353666 87772']
Answer:  ['francois chevalier 8607203 global bob 10388812']
  [Batch] Query 1000: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.77s avg)
Checkpoint saved: 992 queries processed

============================================================
Batch 501/1536: Processing 2 queries
============================================================
Predictions:  ['big joe maria calux giorgio armani francois chevalier mia martina tia carrera feliciano di venturi global bob vincenzo fertino bob bobitt ken cascaval billy joe giuseppe von firenze', 'big joe 18628302']
Answer:  ['3', 'big joe 18728302']
Predictions:  ['big joe maria calux giorgio armani francois chevalier mia martina tia carrera feliciano di venturi global bob vincenzo fertino bob bobitt ken cascaval billy joe giuseppe von firenze']
Answer:  ['3']
  [Batch] Query 1001: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.93s avg)
Predictions:  ['big joe 18628302']
Answer:  ['big joe 18728302']
  [Batch] Query 1002: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (2.93s avg)
Checkpoint saved: 994 queries processed

============================================================
Batch 502/1536: Processing 2 queries
============================================================
Predictions:  ['argentinos jrs independiente']
Answer:  ['argentinos jrs']
Predictions:  ['argentinos jrs independiente']
Answer:  ['argentinos jrs']
  [Batch] Query 1004: {'F1': 80.0, 'EM': 0.0, 'ROUGE-L': 80.0, 'SacreBLEU': 0.0} (3.04s avg)
  Warning: Large text input (8073 tokens)
Processing batches:  33%|███▎      | 502/1536 [2:08:37<2:19:26,  8.09s/it]Processing batches:  33%|███▎      | 503/1536 [2:08:44<2:09:23,  7.52s/it]  [Single] Query 1003: {'GPT_EVAL': 'N/A (no eval_api_key)'} (6.66s)
Checkpoint saved: 996 queries processed

============================================================
Batch 503/1536: Processing 2 queries
============================================================
Predictions:  ['fc slutsk shakhter soligorsk', 'italy serie 12']
Answer:  ['fc slutsk shakhter soligorsk dinamo minsk bate borisov', 'argentinasuperliga argentina 23']
Predictions:  ['fc slutsk shakhter soligorsk']
Answer:  ['fc slutsk shakhter soligorsk dinamo minsk bate borisov']
  [Batch] Query 1005: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 36.79} (2.95s avg)
Predictions:  ['italy serie 12']
Answer:  ['argentinasuperliga argentina 23']
  [Batch] Query 1006: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.95s avg)
Checkpoint saved: 998 queries processed

============================================================
Batch 504/1536: Processing 2 queries
============================================================
Predictions:  ['argentinasuperliga argentina austriabundesliga']
Answer:  ['equal 2 matches each']
Predictions:  ['argentinasuperliga argentina austriabundesliga']
Answer:  ['equal 2 matches each']
  [Batch] Query 1007: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.54s avg)
  Warning: Large text input (18567 tokens)
Processing batches:  33%|███▎      | 504/1536 [2:08:56<2:35:51,  9.06s/it]Processing batches:  33%|███▎      | 505/1536 [2:08:58<1:59:01,  6.93s/it]Processing batches:  33%|███▎      | 506/1536 [2:09:00<1:34:57,  5.53s/it]Processing batches:  33%|███▎      | 507/1536 [2:09:08<1:44:42,  6.11s/it]Processing batches:  33%|███▎      | 508/1536 [2:09:11<1:31:03,  5.31s/it]Processing batches:  33%|███▎      | 509/1536 [2:09:19<1:40:15,  5.86s/it]Processing batches:  33%|███▎      | 510/1536 [2:09:37<2:43:27,  9.56s/it]Processing batches:  33%|███▎      | 511/1536 [2:09:48<2:53:53, 10.18s/it]  [Single] Query 1008: {'GPT_EVAL': 'N/A (no eval_api_key)'} (8.99s)
Checkpoint saved: 1000 queries processed

============================================================
Batch 505/1536: Processing 2 queries
============================================================
Predictions:  ['150000', 'b2 732288']
Answer:  ['150667', 'b2 732288']
Predictions:  ['150000']
Answer:  ['150667']
  [Batch] Query 1009: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (0.84s avg)
Predictions:  ['b2 732288']
Answer:  ['b2 732288']
  [Batch] Query 1010: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (0.84s avg)
Checkpoint saved: 1002 queries processed

============================================================
Batch 506/1536: Processing 2 queries
============================================================
Predictions:  ['4 bob', '310 310']
Answer:  ['5 bob', '3833']
Predictions:  ['4 bob']
Answer:  ['5 bob']
  [Batch] Query 1011: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (1.01s avg)
Predictions:  ['310 310']
Answer:  ['3833']
  [Batch] Query 1012: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.01s avg)
Checkpoint saved: 1004 queries processed

============================================================
Batch 507/1536: Processing 2 queries
============================================================
Predictions:  ['28000']
Answer:  ['36000']
Predictions:  ['28000']
Answer:  ['36000']
  [Batch] Query 1014: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.29s avg)
  [Single] Query 1013: {'GPT_EVAL': 'N/A (no eval_api_key)'} (6.01s)
Checkpoint saved: 1006 queries processed

============================================================
Batch 508/1536: Processing 2 queries
============================================================
Predictions:  ['bob john', 'week 1 week 2 week 4 week 5 week 3']
Answer:  ['bob john', 'week 1 week 2 week 4 week 3 week 5 week 6']
Predictions:  ['bob john']
Answer:  ['bob john']
  [Batch] Query 1015: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.60s avg)
Predictions:  ['week 1 week 2 week 4 week 5 week 3']
Answer:  ['week 1 week 2 week 4 week 3 week 5 week 6']
  [Batch] Query 1016: {'F1': 90.91, 'EM': 0.0, 'ROUGE-L': 81.82, 'SacreBLEU': 66.24} (1.60s avg)
Checkpoint saved: 1008 queries processed

============================================================
Batch 509/1536: Processing 2 queries
============================================================
Predictions:  ['bill smith bob bloggs john howard']
Answer:  ['2']
Predictions:  ['bill smith bob bloggs john howard']
Answer:  ['2']
  [Batch] Query 1017: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.39s avg)
  [Single] Query 1018: {'GPT_EVAL': 'N/A (no eval_api_key)'} (5.59s)
Checkpoint saved: 1010 queries processed

============================================================
Batch 510/1536: Processing 2 queries
============================================================
Predictions:  ['23775000 22685000', '3162017 3172017 3182017 3232017 3242017 3252017 3262017 3272017 3282017 3292017 3302017 3312017']
Answer:  ['51255000', '201736 2017317 2017321 2017322 2017323 2017324 2017325 2017326 2017327 2017328 2017329 2017330 2017331']
Predictions:  ['23775000 22685000']
Answer:  ['51255000']
  [Batch] Query 1019: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (8.97s avg)
Predictions:  ['3162017 3172017 3182017 3232017 3242017 3252017 3262017 3272017 3282017 3292017 3302017 3312017']
Answer:  ['201736 2017317 2017321 2017322 2017323 2017324 2017325 2017326 2017327 2017328 2017329 2017330 2017331']
  [Batch] Query 1020: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (8.97s avg)
Checkpoint saved: 1012 queries processed

============================================================
Batch 511/1536: Processing 2 queries
============================================================
Predictions:  ['march 17 1000000', '3530000 1700000 1750000 1360000 1210000 250000 250000']
Answer:  ['march 17 10', '11914286']
Predictions:  ['march 17 1000000']
Answer:  ['march 17 10']
  [Batch] Query 1021: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (5.68s avg)
Predictions:  ['3530000 1700000 1750000 1360000 1210000 250000 250000']
Answer:  ['11914286']
  [Batch] Query 1022: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (5.68s avg)
Checkpoint saved: 1014 queries processed

============================================================
Batch 512/1536: Processing 2 queries
============================================================
Predictions:  ['max 21']
Answer:  ['max 21']
Predictions:  ['max 21']
Answer:  ['max 21']
  [Batch] Query 1024: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (0.96s avg)
  Warning: Large text input (21841 tokens)
Processing batches:  33%|███▎      | 512/1536 [2:09:57<2:44:39,  9.65s/it]Processing batches:  33%|███▎      | 513/1536 [2:10:00<2:09:16,  7.58s/it]Processing batches:  33%|███▎      | 514/1536 [2:10:09<2:19:35,  8.19s/it]Processing batches:  34%|███▎      | 515/1536 [2:10:16<2:11:04,  7.70s/it]Processing batches:  34%|███▎      | 516/1536 [2:10:23<2:08:06,  7.54s/it]  [Single] Query 1023: {'GPT_EVAL': 'N/A (no eval_api_key)'} (7.31s)
Checkpoint saved: 1016 queries processed

============================================================
Batch 513/1536: Processing 2 queries
============================================================
Predictions:  ['75434 80239', 'adam max samrt lucas']
Answer:  ['805 trip1', '4 adam max samrt lucas']
Predictions:  ['75434 80239']
Answer:  ['805 trip1']
  [Batch] Query 1025: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.10s avg)
Predictions:  ['adam max samrt lucas']
Answer:  ['4 adam max samrt lucas']
  [Batch] Query 1026: {'F1': 88.89, 'EM': 0.0, 'ROUGE-L': 88.89, 'SacreBLEU': 77.88} (1.10s avg)
Checkpoint saved: 1018 queries processed

============================================================
Batch 514/1536: Processing 2 queries
============================================================
Predictions:  ['76']
Answer:  ['95']
Predictions:  ['76']
Answer:  ['95']
  [Batch] Query 1027: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (0.92s avg)
  [Single] Query 1028: {'GPT_EVAL': 'N/A (no eval_api_key)'} (8.56s)
Checkpoint saved: 1020 queries processed

============================================================
Batch 515/1536: Processing 2 queries
============================================================
Predictions:  ['125 15 125', 'roast beef']
Answer:  ['250', 'roast beef']
Predictions:  ['125 15 125']
Answer:  ['250']
  [Batch] Query 1029: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.15s avg)
Predictions:  ['roast beef']
Answer:  ['roast beef']
  [Batch] Query 1030: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (3.15s avg)
Checkpoint saved: 1022 queries processed

============================================================
Batch 516/1536: Processing 2 queries
============================================================
Predictions:  ['running walking', 'wed jan 04 tue jan 03 mon jan 02']
Answer:  ['2', 'wed jan 04 tue jan 03 mon jan 02']
Predictions:  ['running walking']
Answer:  ['2']
  [Batch] Query 1031: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.45s avg)
Predictions:  ['wed jan 04 tue jan 03 mon jan 02']
Answer:  ['wed jan 04 tue jan 03 mon jan 02']
  [Batch] Query 1032: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (3.45s avg)
Checkpoint saved: 1024 queries processed

============================================================
Batch 517/1536: Processing 2 queries
============================================================
Predictions:  ['fruits coffee grains meats poultry oils fats beer weightlifting weighin']
Answer:  ['weightlifting']
Predictions:  ['fruits coffee grains meats poultry oils fats beer weightlifting weighin']
Answer:  ['weightlifting']
  [Batch] Query 1034: {'F1': 18.18, 'EM': 0.0, 'ROUGE-L': 18.18, 'SacreBLEU': 4.2} (4.52s avg)
  Warning: Large text input (19764 tokens)
Processing batches:  34%|███▎      | 517/1536 [2:10:35<2:31:40,  8.93s/it]Processing batches:  34%|███▎      | 518/1536 [2:10:41<2:18:07,  8.14s/it]  [Single] Query 1033: {'GPT_EVAL': 'N/A (no eval_api_key)'} (7.52s)
Checkpoint saved: 1026 queries processed

============================================================
Batch 518/1536: Processing 2 queries
============================================================
Predictions:  ['fri feb 03 62', '40']
Answer:  ['20170202 21', '545']
Predictions:  ['fri feb 03 62']
Answer:  ['20170202 21']
  [Batch] Query 1035: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.02s avg)
Predictions:  ['40']
Answer:  ['545']
  [Batch] Query 1036: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.02s avg)
Checkpoint saved: 1028 queries processed

============================================================
Batch 519/1536: Processing 2 queries
============================================================
Predictions:  ['300 60']
Answer:  ['60']
Predictions:  ['300 60']
Answer:  ['60']
  [Batch] Query 1037: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (3.04s avg)
  Warning: Large text input (19737 tokens)
Processing batches:  34%|███▍      | 519/1536 [2:10:52<2:29:03,  8.79s/it]Processing batches:  34%|███▍      | 520/1536 [2:10:57<2:11:54,  7.79s/it]Processing batches:  34%|███▍      | 521/1536 [2:11:03<2:04:40,  7.37s/it]  [Single] Query 1038: {'GPT_EVAL': 'N/A (no eval_api_key)'} (7.13s)
Checkpoint saved: 1030 queries processed

============================================================
Batch 520/1536: Processing 2 queries
============================================================
Predictions:  ['no', '30 30']
Answer:  ['no', '675']
Predictions:  ['no']
Answer:  ['no']
  [Batch] Query 1039: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (2.59s avg)
Predictions:  ['30 30']
Answer:  ['675']
  [Batch] Query 1040: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.59s avg)
Checkpoint saved: 1032 queries processed

============================================================
Batch 521/1536: Processing 2 queries
============================================================
Predictions:  ['3 3', 'mar 02 300']
Answer:  ['1 3', 'mar 4 53']
Predictions:  ['3 3']
Answer:  ['1 3']
  [Batch] Query 1041: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (3.06s avg)
Predictions:  ['mar 02 300']
Answer:  ['mar 4 53']
  [Batch] Query 1042: {'F1': 33.33, 'EM': 0.0, 'ROUGE-L': 33.33, 'SacreBLEU': 0.0} (3.06s avg)
Checkpoint saved: 1034 queries processed

============================================================
Batch 522/1536: Processing 2 queries
============================================================
Predictions:  ['steve griggs yes']
Answer:  ['steve griggs yes']
Predictions:  ['steve griggs yes']
Answer:  ['steve griggs yes']
  [Batch] Query 1044: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (4.89s avg)
  Warning: Large text input (19822 tokens)
Processing batches:  34%|███▍      | 522/1536 [2:11:17<2:37:09,  9.30s/it]Processing batches:  34%|███▍      | 523/1536 [2:11:47<4:20:37, 15.44s/it]Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/data/pan/4xin/datasets/RealHiTBench/tables/health-table14.xlsx')
daily_totals = df[df['ACTION'].str.contains('DAILY TOTALS', na=False)]
daily_totals['DATE'] = pd.to_datetime(daily_totals['DATE'])
daily_totals = daily_totals.sort_values('DATE')
daily_totals.set_index('DATE', inplace=True)
plt.plot(daily_totals.index, daily_totals['KCAL'])
plt.title('Total Calories Consumed Per Day')
plt.xlabel('Date')
plt.ylabel('Total Calories')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

Python Error: 'ACTION'
  [Single] Query 1043: {'ECR': False, 'Pass': False} (8.77s)
Checkpoint saved: 1036 queries processed

============================================================
Batch 523/1536: Processing 2 queries
============================================================
Predictions:  ['2', 'dot clark steve griggs steph mullard andy marsden roger stroud brian thomas del hopkins bill hopkins neil allen mick clark dan calver jody holgarth craig mansfield darren kerrigan richard griggs craig mechan mick salmon matt heskett marc witherden paul marshall susanne roalf richard holloway rosemary rose jason halmshaw dave holt carlos hinds steve aimable dan drake david brown johnny fung julie zhu luke heskett ben rayner scott merry allen mevo nick page darren ball mike blackburn jim doyle adam stavrou ross oneil jo luck steve childs brendan fitzpatrick']
Answer:  ['4', '14']
Predictions:  ['2']
Answer:  ['4']
  [Batch] Query 1045: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (14.75s avg)
Predictions:  ['dot clark steve griggs steph mullard andy marsden roger stroud brian thomas del hopkins bill hopkins neil allen mick clark dan calver jody holgarth craig mansfield darren kerrigan richard griggs craig mechan mick salmon matt heskett marc witherden paul marshall susanne roalf richard holloway rosemary rose jason halmshaw dave holt carlos hinds steve aimable dan drake david brown johnny fung julie zhu luke heskett ben rayner scott merry allen mevo nick page darren ball mike blackburn jim doyle adam stavrou ross oneil jo luck steve childs brendan fitzpatrick']
Answer:  ['14']
  [Batch] Query 1046: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (14.75s avg)
Checkpoint saved: 1038 queries processed

============================================================
Batch 524/1536: Processing 2 queries
============================================================
Predictions:  ['167']
Answer:  ['60546']
Predictions:  ['167']
Answer:  ['60546']
  [Batch] Query 1047: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.85s avg)
  Warning: Large text input (31656 tokens)
Processing batches:  34%|███▍      | 524/1536 [2:12:06<4:39:48, 16.59s/it]Processing batches:  34%|███▍      | 525/1536 [2:12:12<3:44:33, 13.33s/it]Processing batches:  34%|███▍      | 526/1536 [2:12:18<3:06:38, 11.09s/it]  [Single] Query 1048: {'GPT_EVAL': 'N/A (no eval_api_key)'} (14.29s)
Checkpoint saved: 1040 queries processed

============================================================
Batch 525/1536: Processing 2 queries
============================================================
Predictions:  ['jane doe 800', '1150']
Answer:  ['jane doe 80', '159']
Predictions:  ['jane doe 800']
Answer:  ['jane doe 80']
  [Batch] Query 1049: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (2.72s avg)
Predictions:  ['1150']
Answer:  ['159']
  [Batch] Query 1050: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.72s avg)
Checkpoint saved: 1042 queries processed

============================================================
Batch 526/1536: Processing 2 queries
============================================================
Predictions:  ['eftpos cheque cash', 'check permit licence reports services gst']
Answer:  ['cheque 159 eftpos 146 cash 100', 'checkn00 permit n00 licence n00 reports s10 services s10 reports n00']
Predictions:  ['eftpos cheque cash']
Answer:  ['cheque 159 eftpos 146 cash 100']
  [Batch] Query 1051: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 44.44, 'SacreBLEU': 0.0} (2.80s avg)
Predictions:  ['check permit licence reports services gst']
Answer:  ['checkn00 permit n00 licence n00 reports s10 services s10 reports n00']
  [Batch] Query 1052: {'F1': 47.06, 'EM': 0.0, 'ROUGE-L': 47.06, 'SacreBLEU': 4.99} (2.80s avg)
Checkpoint saved: 1044 queries processed

============================================================
Batch 527/1536: Processing 2 queries
============================================================
Predictions:  ['d']
Answer:  ['e']
Predictions:  ['d']
Answer:  ['e']
  [Batch] Query 1054: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.09s avg)
  Warning: Large text input (18130 tokens)
Processing batches:  34%|███▍      | 527/1536 [2:12:29<3:06:31, 11.09s/it]Processing batches:  34%|███▍      | 528/1536 [2:12:31<2:21:15,  8.41s/it]Processing batches:  34%|███▍      | 529/1536 [2:12:40<2:24:01,  8.58s/it]Processing batches:  35%|███▍      | 530/1536 [2:12:51<2:35:39,  9.28s/it]Processing batches:  35%|███▍      | 531/1536 [2:12:58<2:23:37,  8.57s/it]Processing batches:  35%|███▍      | 532/1536 [2:13:09<2:34:17,  9.22s/it]Processing batches:  35%|███▍      | 533/1536 [2:13:18<2:36:08,  9.34s/it]  [Single] Query 1053: {'GPT_EVAL': 'N/A (no eval_api_key)'} (9.86s)
Checkpoint saved: 1046 queries processed

============================================================
Batch 528/1536: Processing 2 queries
============================================================
Predictions:  ['yes', 'f']
Answer:  ['yes', '']
Predictions:  ['yes']
Answer:  ['yes']
  [Batch] Query 1055: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (0.94s avg)
Predictions:  ['f']
Answer:  ['']
  [Batch] Query 1056: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (0.94s avg)
Checkpoint saved: 1048 queries processed

============================================================
Batch 529/1536: Processing 2 queries
============================================================
Predictions:  ['f']
Answer:  ['f']
Predictions:  ['f']
Answer:  ['f']
  [Batch] Query 1057: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.58s avg)
  [Single] Query 1058: {'GPT_EVAL': 'N/A (no eval_api_key)'} (7.26s)
Checkpoint saved: 1050 queries processed

============================================================
Batch 530/1536: Processing 2 queries
============================================================
Predictions:  ['7988nynjct region 7985capitol region 7980new england region 7976midatlantic region 7954north central region 7987floridageorgia region 7989mid south region 7953miohwv region 7964south central region 7960california region 7959gold region 7971central region', 'no']
Answer:  ['7988nynjct region 77 7985capitol region 42 7980new england region 36 7976midatlantic region 57', 'no']
Predictions:  ['7988nynjct region 7985capitol region 7980new england region 7976midatlantic region 7954north central region 7987floridageorgia region 7989mid south region 7953miohwv region 7964south central region 7960california region 7959gold region 7971central region']
Answer:  ['7988nynjct region 77 7985capitol region 42 7980new england region 36 7976midatlantic region 57']
  [Batch] Query 1059: {'F1': 43.9, 'EM': 0.0, 'ROUGE-L': 43.9, 'SacreBLEU': 8.23} (5.33s avg)
Predictions:  ['no']
Answer:  ['no']
  [Batch] Query 1060: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (5.33s avg)
Checkpoint saved: 1052 queries processed

============================================================
Batch 531/1536: Processing 2 queries
============================================================
Predictions:  ['7988nynjct region 7976midatlantic region 0205eastern area 7989mid south region 7964south central region 7959gold region 0221western area', 'eastern area central area']
Answer:  ['4', 'eastern area']
Predictions:  ['7988nynjct region 7976midatlantic region 0205eastern area 7989mid south region 7964south central region 7959gold region 0221western area']
Answer:  ['4']
  [Batch] Query 1061: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.33s avg)
Predictions:  ['eastern area central area']
Answer:  ['eastern area']
  [Batch] Query 1062: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 31.95} (3.33s avg)
Checkpoint saved: 1054 queries processed

============================================================
Batch 532/1536: Processing 2 queries
============================================================
Predictions:  ['dot clark brian thomas']
Answer:  ['2']
Predictions:  ['dot clark brian thomas']
Answer:  ['2']
  [Batch] Query 1064: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.22s avg)
  [Single] Query 1063: {'GPT_EVAL': 'N/A (no eval_api_key)'} (7.37s)
Checkpoint saved: 1056 queries processed

============================================================
Batch 533/1536: Processing 2 queries
============================================================
Predictions:  ['544 372', '5440 4080 3720 2720 2330']
Answer:  ['172', '4824']
Predictions:  ['544 372']
Answer:  ['172']
  [Batch] Query 1065: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.68s avg)
Predictions:  ['5440 4080 3720 2720 2330']
Answer:  ['4824']
  [Batch] Query 1066: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.68s avg)
Checkpoint saved: 1058 queries processed

============================================================
Batch 534/1536: Processing 2 queries
============================================================
Predictions:  ['17760 15440 14080']
Answer:  ['19448']
Predictions:  ['17760 15440 14080']
Answer:  ['19448']
  [Batch] Query 1067: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.28s avg)
  Warning: Large text input (21832 tokens)
Processing batches:  35%|███▍      | 534/1536 [2:13:30<2:49:13, 10.13s/it]Processing batches:  35%|███▍      | 535/1536 [2:13:34<2:16:06,  8.16s/it]Processing batches:  35%|███▍      | 536/1536 [2:13:39<1:59:39,  7.18s/it]Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/data/pan/4xin/datasets/RealHiTBench/tables/sport-table11.xlsx')
top5_points = df.iloc[0:5, 1].astype(int).values
labels = df.iloc[0:5, 2].values
plt.pie(top5_points, labels=labels, autopct='%1.1f%%')
plt.title('Proportion of Total Points by Top 5 Players')
plt.show()

Python Error: Cannot convert non-finite values (NA or inf) to integer
  [Single] Query 1068: {'ECR': False, 'Pass': False} (7.56s)
Checkpoint saved: 1060 queries processed

============================================================
Batch 535/1536: Processing 2 queries
============================================================
Predictions:  ['8000', '10 40000']
Answer:  ['80000', '10 40000']
Predictions:  ['8000']
Answer:  ['80000']
  [Batch] Query 1069: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.64s avg)
Predictions:  ['10 40000']
Answer:  ['10 40000']
  [Batch] Query 1070: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.64s avg)
Checkpoint saved: 1062 queries processed

============================================================
Batch 536/1536: Processing 2 queries
============================================================
Predictions:  ['drop size incentive accounts payable incentive program maximization incentive new business incentive other contracted rebates other', 'total gpo incentives total standard']
Answer:  ['7', 'equal']
Predictions:  ['drop size incentive accounts payable incentive program maximization incentive new business incentive other contracted rebates other']
Answer:  ['7']
  [Batch] Query 1071: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.31s avg)
Predictions:  ['total gpo incentives total standard']
Answer:  ['equal']
  [Batch] Query 1072: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.31s avg)
Checkpoint saved: 1064 queries processed

============================================================
Batch 537/1536: Processing 2 queries
============================================================
Predictions:  ['computer science']
Answer:  ['computer science']
Predictions:  ['computer science']
Answer:  ['computer science']
  [Batch] Query 1074: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (3.12s avg)
  Warning: Large text input (9726 tokens)
Processing batches:  35%|███▍      | 537/1536 [2:13:48<2:10:22,  7.83s/it]Processing batches:  35%|███▌      | 538/1536 [2:13:55<2:07:06,  7.64s/it]  [Single] Query 1073: {'GPT_EVAL': 'N/A (no eval_api_key)'} (6.08s)
Checkpoint saved: 1066 queries processed

============================================================
Batch 538/1536: Processing 2 queries
============================================================
Predictions:  ['abdullahi abdul maida', '19']
Answer:  ['yes', '23']
Predictions:  ['abdullahi abdul maida']
Answer:  ['yes']
  [Batch] Query 1075: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.47s avg)
Predictions:  ['19']
Answer:  ['23']
  [Batch] Query 1076: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.47s avg)
Checkpoint saved: 1068 queries processed

============================================================
Batch 539/1536: Processing 2 queries
============================================================
Predictions:  ['865 231']
Answer:  ['261']
Predictions:  ['865 231']
Answer:  ['261']
  [Batch] Query 1077: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.57s avg)
  Warning: Large text input (21730 tokens)
Processing batches:  35%|███▌      | 539/1536 [2:14:10<2:40:34,  9.66s/it]Processing batches:  35%|███▌      | 540/1536 [2:14:12<2:03:48,  7.46s/it]Processing batches:  35%|███▌      | 541/1536 [2:14:15<1:40:32,  6.06s/it]Processing batches:  35%|███▌      | 542/1536 [2:14:25<2:01:52,  7.36s/it]Processing batches:  35%|███▌      | 543/1536 [2:14:27<1:33:02,  5.62s/it]Processing batches:  35%|███▌      | 544/1536 [2:14:33<1:36:14,  5.82s/it]Processing batches:  35%|███▌      | 545/1536 [2:14:35<1:18:49,  4.77s/it]Processing batches:  36%|███▌      | 546/1536 [2:14:38<1:06:29,  4.03s/it]Processing batches:  36%|███▌      | 547/1536 [2:14:48<1:36:20,  5.85s/it]Processing batches:  36%|███▌      | 548/1536 [2:14:57<1:55:03,  6.99s/it]Processing batches:  36%|███▌      | 549/1536 [2:15:06<2:00:41,  7.34s/it]Processing batches:  36%|███▌      | 550/1536 [2:15:08<1:34:14,  5.73s/it]Processing batches:  36%|███▌      | 551/1536 [2:15:17<1:50:18,  6.72s/it]Processing batches:  36%|███▌      | 552/1536 [2:15:24<1:51:24,  6.79s/it]  [Single] Query 1078: {'GPT_EVAL': 'N/A (no eval_api_key)'} (10.66s)
Checkpoint saved: 1070 queries processed

============================================================
Batch 540/1536: Processing 2 queries
============================================================
Predictions:  ['mobilization dot', 'detailed plan no']
Answer:  ['mobilization', '21 days no']
Predictions:  ['mobilization dot']
Answer:  ['mobilization']
  [Batch] Query 1079: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (1.03s avg)
Predictions:  ['detailed plan no']
Answer:  ['21 days no']
  [Batch] Query 1080: {'F1': 33.33, 'EM': 0.0, 'ROUGE-L': 33.33, 'SacreBLEU': 0.0} (1.03s avg)
Checkpoint saved: 1072 queries processed

============================================================
Batch 541/1536: Processing 2 queries
============================================================
Predictions:  ['16', 'detailed plan detailed plan estidama']
Answer:  ['20', '6']
Predictions:  ['16']
Answer:  ['20']
  [Batch] Query 1081: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.27s avg)
Predictions:  ['detailed plan detailed plan estidama']
Answer:  ['6']
  [Batch] Query 1082: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.27s avg)
Checkpoint saved: 1074 queries processed

============================================================
Batch 542/1536: Processing 2 queries
============================================================
Predictions:  ['central']
Answer:  ['yes']
Predictions:  ['central']
Answer:  ['yes']
  [Batch] Query 1084: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (0.68s avg)
  [Single] Query 1083: {'GPT_EVAL': 'N/A (no eval_api_key)'} (9.55s)
Checkpoint saved: 1076 queries processed

============================================================
Batch 543/1536: Processing 2 queries
============================================================
Predictions:  ['football 14', '3 3']
Answer:  ['football 14', '2']
Predictions:  ['football 14']
Answer:  ['football 14']
  [Batch] Query 1085: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (0.66s avg)
Predictions:  ['3 3']
Answer:  ['2']
  [Batch] Query 1086: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (0.66s avg)
Checkpoint saved: 1078 queries processed

============================================================
Batch 544/1536: Processing 2 queries
============================================================
Predictions:  ['north east']
Answer:  ['true']
Predictions:  ['north east']
Answer:  ['true']
  [Batch] Query 1087: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (0.76s avg)
  [Single] Query 1088: {'GPT_EVAL': 'N/A (no eval_api_key)'} (5.38s)
Checkpoint saved: 1080 queries processed

============================================================
Batch 545/1536: Processing 2 queries
============================================================
Predictions:  ['region commission override', 'salary territory and team personal led mbo']
Answer:  ['region commission override', 'salary territory and team personal led mbo']
Predictions:  ['region commission override']
Answer:  ['region commission override']
  [Batch] Query 1089: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.03s avg)
Predictions:  ['salary territory and team personal led mbo']
Answer:  ['salary territory and team personal led mbo']
  [Batch] Query 1090: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (1.03s avg)
Checkpoint saved: 1082 queries processed

============================================================
Batch 546/1536: Processing 2 queries
============================================================
Predictions:  ['territory and team personal led salary', 'salary personal commission']
Answer:  ['territory and team personal led salary mbo', '2']
Predictions:  ['territory and team personal led salary']
Answer:  ['territory and team personal led salary mbo']
  [Batch] Query 1091: {'F1': 92.31, 'EM': 0.0, 'ROUGE-L': 92.31, 'SacreBLEU': 84.65} (1.02s avg)
Predictions:  ['salary personal commission']
Answer:  ['2']
  [Batch] Query 1092: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.02s avg)
Checkpoint saved: 1084 queries processed

============================================================
Batch 547/1536: Processing 2 queries
============================================================
Predictions:  ['153']
Answer:  ['227']
Predictions:  ['153']
Answer:  ['227']
  [Batch] Query 1094: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.61s avg)
  [Single] Query 1093: {'GPT_EVAL': 'N/A (no eval_api_key)'} (6.33s)
Checkpoint saved: 1086 queries processed

============================================================
Batch 548/1536: Processing 2 queries
============================================================
Predictions:  ['adhesives fasteners hardware lubricant misc saftey tools', 'adhesives tools']
Answer:  ['4', 'adhesives']
Predictions:  ['adhesives fasteners hardware lubricant misc saftey tools']
Answer:  ['4']
  [Batch] Query 1095: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.70s avg)
Predictions:  ['adhesives tools']
Answer:  ['adhesives']
  [Batch] Query 1096: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (4.70s avg)
Checkpoint saved: 1088 queries processed

============================================================
Batch 549/1536: Processing 2 queries
============================================================
Predictions:  ['4 5 6 7', '70 53']
Answer:  ['11', '86 64']
Predictions:  ['4 5 6 7']
Answer:  ['11']
  [Batch] Query 1097: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.95s avg)
Predictions:  ['70 53']
Answer:  ['86 64']
  [Batch] Query 1098: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.95s avg)
Checkpoint saved: 1090 queries processed

============================================================
Batch 550/1536: Processing 2 queries
============================================================
Predictions:  ['us australia japan uk singapore france', 'singapore']
Answer:  ['us australia japan uk singapore france', 'singapore']
Predictions:  ['us australia japan uk singapore france']
Answer:  ['us australia japan uk singapore france']
  [Batch] Query 1099: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (0.87s avg)
Predictions:  ['singapore']
Answer:  ['singapore']
  [Batch] Query 1100: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (0.87s avg)
Checkpoint saved: 1092 queries processed

============================================================
Batch 551/1536: Processing 2 queries
============================================================
Predictions:  ['japan']
Answer:  ['japan']
Predictions:  ['japan']
Answer:  ['japan']
  [Batch] Query 1101: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (0.73s avg)
  [Single] Query 1102: {'GPT_EVAL': 'N/A (no eval_api_key)'} (8.14s)
Checkpoint saved: 1094 queries processed

============================================================
Batch 552/1536: Processing 2 queries
============================================================
Predictions:  ['28972 31988 36832 32916 36832 29784 42400 37876 23752 30132', 'basic pay 102016 da hra ta washing allowance other gross pay']
Answer:  ['427072', 'basic pay da hra ta washing allowance other gross pay']
Predictions:  ['28972 31988 36832 32916 36832 29784 42400 37876 23752 30132']
Answer:  ['427072']
  [Batch] Query 1103: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (3.35s avg)
Predictions:  ['basic pay 102016 da hra ta washing allowance other gross pay']
Answer:  ['basic pay da hra ta washing allowance other gross pay']
  [Batch] Query 1104: {'F1': 95.24, 'EM': 0.0, 'ROUGE-L': 95.24, 'SacreBLEU': 74.19} (3.35s avg)
Checkpoint saved: 1096 queries processed

============================================================
Batch 553/1536: Processing 2 queries
============================================================
Predictions:  ['e bhavanandhi', 'admin cse ece mechanical civil']
Answer:  ['e bhavanandhi', 'civil']
Predictions:  ['e bhavanandhi']
Answer:  ['e bhavanandhi']
Processing batches:  36%|███▌      | 553/1536 [2:15:27<1:35:22,  5.82s/it]  [Batch] Query 1105: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.64s avg)
Predictions:  ['admin cse ece mechanical civil']
Answer:  ['civil']
  [Batch] Query 1106: {'F1': 33.33, 'EM': 0.0, 'ROUGE-L': 33.33, 'SacreBLEU': 10.68} (1.64s avg)
Checkpoint saved: 1098 queries processed

============================================================
Batch 554/1536: Processing 2 queries
============================================================
Predictions:  ['410 33470']
Answer:  ['410']
Predictions:  ['410 33470']
Answer:  ['410']
  [Batch] Query 1108: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (3.50s avg)
  Warning: Large text input (9344 tokens)
Processing batches:  36%|███▌      | 554/1536 [2:15:40<2:08:15,  7.84s/it]Processing batches:  36%|███▌      | 555/1536 [2:15:46<2:00:56,  7.40s/it]  [Single] Query 1107: {'GPT_EVAL': 'N/A (no eval_api_key)'} (8.89s)
Checkpoint saved: 1100 queries processed

============================================================
Batch 555/1536: Processing 2 queries
============================================================
Predictions:  ['yes', '740']
Answer:  ['yes', '740']
Predictions:  ['yes']
Answer:  ['yes']
  [Batch] Query 1109: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (3.06s avg)
Predictions:  ['740']
Answer:  ['740']
  [Batch] Query 1110: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (3.06s avg)
Checkpoint saved: 1102 queries processed

============================================================
Batch 556/1536: Processing 2 queries
============================================================
Predictions:  ['740 982 410 980 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 4']
Answer:  ['14']
Predictions:  ['740 982 410 980 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 410 4']
Answer:  ['14']
  [Batch] Query 1111: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (222.81s avg)
  Warning: Large text input (21733 tokens)
Processing batches:  36%|███▌      | 556/1536 [2:19:34<20:03:04, 73.66s/it]Processing batches:  36%|███▋      | 557/1536 [2:19:52<15:30:04, 57.00s/it]Processing batches:  36%|███▋      | 558/1536 [2:20:01<11:34:47, 42.63s/it]Processing batches:  36%|███▋      | 559/1536 [2:20:07<8:31:30, 31.41s/it] Processing batches:  36%|███▋      | 560/1536 [2:20:10<6:12:41, 22.91s/it]Processing batches:  37%|███▋      | 561/1536 [2:20:18<5:02:36, 18.62s/it]Processing batches:  37%|███▋      | 562/1536 [2:20:22<3:51:12, 14.24s/it]  [Single] Query 1112: {'GPT_EVAL': 'N/A (no eval_api_key)'} (5.31s)
Checkpoint saved: 1104 queries processed

============================================================
Batch 557/1536: Processing 2 queries
============================================================
Predictions:  ['fresh air damper step 4 13 flood light steps 14 dm2 flood light activation steps 15 18 dm1 flood light activation steps 19 22 dm2 flood lights and edd illumination deactivation steps 23 31 edd exit signals at dmi1 steps 39 43 edd exit signals at dmi2 steps 44 47 parking brake steps 48 56 resetting train propulsion equipment isolation steps 57 62 train equipment reset steps 63 68', 'pv38']
Answer:  ['2', 'pv38 20150310']
Predictions:  ['fresh air damper step 4 13 flood light steps 14 dm2 flood light activation steps 15 18 dm1 flood light activation steps 19 22 dm2 flood lights and edd illumination deactivation steps 23 31 edd exit signals at dmi1 steps 39 43 edd exit signals at dmi2 steps 44 47 parking brake steps 48 56 resetting train propulsion equipment isolation steps 57 62 train equipment reset steps 63 68']
Answer:  ['2']
  [Batch] Query 1113: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (8.94s avg)
Predictions:  ['pv38']
Answer:  ['pv38 20150310']
  [Batch] Query 1114: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (8.94s avg)
Checkpoint saved: 1106 queries processed

============================================================
Batch 558/1536: Processing 2 queries
============================================================
Predictions:  ['11 11 11 11 11 11 11 11 11 11 11', 'pv38 3102015']
Answer:  ['pv3811 pv2111 pv7911 pv7411 pv189 pv179 pv309 pv379 pv359 pv229 pv779 pv789', 'pv38 2015310']
Predictions:  ['11 11 11 11 11 11 11 11 11 11 11']
Answer:  ['pv3811 pv2111 pv7911 pv7411 pv189 pv179 pv309 pv379 pv359 pv229 pv779 pv789']
  [Batch] Query 1115: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.41s avg)
Predictions:  ['pv38 3102015']
Answer:  ['pv38 2015310']
  [Batch] Query 1116: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (4.41s avg)
Checkpoint saved: 1108 queries processed

============================================================
Batch 559/1536: Processing 2 queries
============================================================
Predictions:  ['7', 'navel mandrin red']
Answer:  ['12', 'navel mandrin red']
Predictions:  ['7']
Answer:  ['12']
  [Batch] Query 1117: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.49s avg)
Predictions:  ['navel mandrin red']
Answer:  ['navel mandrin red']
  [Batch] Query 1118: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (2.49s avg)
Checkpoint saved: 1110 queries processed

============================================================
Batch 560/1536: Processing 2 queries
============================================================
Predictions:  ['no', '81 73 45 44 41']
Answer:  ['no', '284']
Predictions:  ['no']
Answer:  ['no']
  [Batch] Query 1119: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.41s avg)
Predictions:  ['81 73 45 44 41']
Answer:  ['284']
  [Batch] Query 1120: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.41s avg)
Checkpoint saved: 1112 queries processed

============================================================
Batch 561/1536: Processing 2 queries
============================================================
Predictions:  ['navel mandrin red']
Answer:  ['navel red mandrin']
Predictions:  ['navel mandrin red']
Answer:  ['navel red mandrin']
  [Batch] Query 1121: {'F1': 100.0, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (1.26s avg)
  [Single] Query 1122: {'GPT_EVAL': 'N/A (no eval_api_key)'} (7.21s)
Checkpoint saved: 1114 queries processed

============================================================
Batch 562/1536: Processing 2 queries
============================================================
Predictions:  ['eur jpy', 'asia pacific twd']
Answer:  ['europe eur', 'europe ils middle east sar middle east aed']
Predictions:  ['eur jpy']
Answer:  ['europe eur']
  [Batch] Query 1123: {'F1': 50.0, 'EM': 0.0, 'ROUGE-L': 50.0, 'SacreBLEU': 0.0} (1.88s avg)
Predictions:  ['asia pacific twd']
Answer:  ['europe ils middle east sar middle east aed']
  [Batch] Query 1124: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.88s avg)
Checkpoint saved: 1116 queries processed

============================================================
Batch 563/1536: Processing 2 queries
============================================================
Predictions:  ['north america canada europe eur europe gbp europe chf europe dkk europe sek europe nok middle east sar middle east aed japan jpy asia pacific twd asia pacific krw asia pacific hkd australia aud new zealand nzd philippines php', '129 140 95 125 71 87 755 1500 380 13700 100 150 19 46 60 75 650 1550 250 38 32 48 275 335 29 18 18 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20']
Answer:  ['12', '115']
Predictions:  ['north america canada europe eur europe gbp europe chf europe dkk europe sek europe nok middle east sar middle east aed japan jpy asia pacific twd asia pacific krw asia pacific hkd australia aud new zealand nzd philippines php']
Answer:  ['12']
Processing batches:  37%|███▋      | 563/1536 [2:25:31<27:40:45, 102.41s/it]  [Batch] Query 1125: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (153.94s avg)
Predictions:  ['129 140 95 125 71 87 755 1500 380 13700 100 150 19 46 60 75 650 1550 250 38 32 48 275 335 29 18 18 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20 20']
Answer:  ['115']
  [Batch] Query 1126: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (153.94s avg)
Checkpoint saved: 1118 queries processed

============================================================
Batch 564/1536: Processing 2 queries
============================================================
Predictions:  ['548']
Answer:  ['548']
Predictions:  ['548']
Answer:  ['548']
  [Batch] Query 1128: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.49s avg)
  Warning: Large text input (13597 tokens)
Processing batches:  37%|███▋      | 564/1536 [2:25:42<20:17:36, 75.16s/it] Processing batches:  37%|███▋      | 565/1536 [2:25:46<14:27:56, 53.63s/it]  [Single] Query 1127: {'GPT_EVAL': 'N/A (no eval_api_key)'} (9.95s)
Checkpoint saved: 1120 queries processed

============================================================
Batch 565/1536: Processing 2 queries
============================================================
Predictions:  ['99 99 99', '7 160']
Answer:  ['299', '9 195']
Predictions:  ['99 99 99']
Answer:  ['299']
  [Batch] Query 1129: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.56s avg)
Predictions:  ['7 160']
Answer:  ['9 195']
  [Batch] Query 1130: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.56s avg)
Checkpoint saved: 1122 queries processed

============================================================
Batch 566/1536: Processing 2 queries
============================================================
Predictions:  ['40 89 89']
Answer:  ['259']
Predictions:  ['40 89 89']
Answer:  ['259']
  [Batch] Query 1131: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.93s avg)
  Warning: Large text input (8080 tokens)
Processing batches:  37%|███▋      | 566/1536 [2:26:02<11:25:19, 42.39s/it]Processing batches:  37%|███▋      | 567/1536 [2:26:10<8:38:21, 32.10s/it] Processing batches:  37%|███▋      | 568/1536 [2:26:19<6:47:27, 25.26s/it]  [Single] Query 1132: {'GPT_EVAL': 'N/A (no eval_api_key)'} (14.09s)
Checkpoint saved: 1124 queries processed

============================================================
Batch 567/1536: Processing 2 queries
============================================================
Predictions:  ['user name ascending', '12']
Answer:  ['users are organized alphabetically by their names in ascending order changing sort order to descending would display users in reverse alphabetical order', '12']
Predictions:  ['user name ascending']
Answer:  ['users are organized alphabetically by their names in ascending order changing sort order to descending would display users in reverse alphabetical order']
  [Batch] Query 1133: {'F1': 8.0, 'EM': 0.0, 'ROUGE-L': 8.0, 'SacreBLEU': 0.0} (3.91s avg)
Predictions:  ['12']
Answer:  ['12']
  [Batch] Query 1134: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (3.91s avg)
Checkpoint saved: 1126 queries processed

============================================================
Batch 568/1536: Processing 2 queries
============================================================
Predictions:  ['3 34', 'chandrasekhar vanam 10172468']
Answer:  ['2 24', 'chandrasekhar vanam']
Predictions:  ['3 34']
Answer:  ['2 24']
  [Batch] Query 1135: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (4.43s avg)
Predictions:  ['chandrasekhar vanam 10172468']
Answer:  ['chandrasekhar vanam']
  [Batch] Query 1136: {'F1': 80.0, 'EM': 0.0, 'ROUGE-L': 80.0, 'SacreBLEU': 0.0} (4.43s avg)
Checkpoint saved: 1128 queries processed

============================================================
Batch 569/1536: Processing 2 queries
============================================================
Predictions:  ['97 127']
Answer:  ['224']
Predictions:  ['97 127']
Answer:  ['224']
  [Batch] Query 1138: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.03s avg)
  Warning: Large text input (26102 tokens)
Processing batches:  37%|███▋      | 569/1536 [2:26:35<6:01:41, 22.44s/it]Processing batches:  37%|███▋      | 570/1536 [2:26:39<4:30:50, 16.82s/it]  [Single] Query 1137: {'GPT_EVAL': 'N/A (no eval_api_key)'} (13.70s)
Checkpoint saved: 1130 queries processed

============================================================
Batch 570/1536: Processing 2 queries
============================================================
Predictions:  ['87 92', 'daikon notops daikon wtops']
Answer:  ['179', 'notops']
Predictions:  ['87 92']
Answer:  ['179']
  [Batch] Query 1139: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.72s avg)
Predictions:  ['daikon notops daikon wtops']
Answer:  ['notops']
  [Batch] Query 1140: {'F1': 40.0, 'EM': 0.0, 'ROUGE-L': 40.0, 'SacreBLEU': 15.97} (1.72s avg)
Checkpoint saved: 1132 queries processed

============================================================
Batch 571/1536: Processing 2 queries
============================================================
Predictions:  ['117 152']
Answer:  ['269']
Predictions:  ['117 152']
Answer:  ['269']
  [Batch] Query 1141: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.08s avg)
  Warning: Large text input (10965 tokens)
Processing batches:  37%|███▋      | 571/1536 [2:26:48<3:56:32, 14.71s/it]Processing batches:  37%|███▋      | 572/1536 [2:26:53<3:08:33, 11.74s/it]Processing batches:  37%|███▋      | 573/1536 [2:26:58<2:35:51,  9.71s/it]  [Single] Query 1142: {'GPT_EVAL': 'N/A (no eval_api_key)'} (7.55s)
Checkpoint saved: 1134 queries processed

============================================================
Batch 572/1536: Processing 2 queries
============================================================
Predictions:  ['c palace', 'home draw away']
Answer:  ['swansea', 'home draw away']
Predictions:  ['c palace']
Answer:  ['swansea']
  [Batch] Query 1143: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.27s avg)
Predictions:  ['home draw away']
Answer:  ['home draw away']
  [Batch] Query 1144: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (2.27s avg)
Checkpoint saved: 1136 queries processed

============================================================
Batch 573/1536: Processing 2 queries
============================================================
Predictions:  ['hoffenheim', '2']
Answer:  ['man utd', '4']
Predictions:  ['hoffenheim']
Answer:  ['man utd']
  [Batch] Query 1145: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.15s avg)
Predictions:  ['2']
Answer:  ['4']
  [Batch] Query 1146: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (2.15s avg)
Checkpoint saved: 1138 queries processed

============================================================
Batch 574/1536: Processing 2 queries
============================================================
Predictions:  ['01 01']
Answer:  ['01']
Predictions:  ['01 01']
Answer:  ['01']
  [Batch] Query 1148: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (1.36s avg)
  Warning: Large text input (16311 tokens)
Processing batches:  37%|███▋      | 574/1536 [2:27:11<2:48:24, 10.50s/it]Processing batches:  37%|███▋      | 575/1536 [2:27:13<2:09:08,  8.06s/it]Processing batches:  38%|███▊      | 576/1536 [2:27:18<1:52:11,  7.01s/it]Processing batches:  38%|███▊      | 577/1536 [2:27:21<1:33:29,  5.85s/it]Processing batches:  38%|███▊      | 578/1536 [2:27:24<1:20:41,  5.05s/it]  [Single] Query 1147: {'GPT_EVAL': 'N/A (no eval_api_key)'} (10.42s)
Checkpoint saved: 1140 queries processed

============================================================
Batch 575/1536: Processing 2 queries
============================================================
Predictions:  ['01 02', '02 00']
Answer:  ['01 02', 'false']
Predictions:  ['01 02']
Answer:  ['01 02']
  [Batch] Query 1149: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.05s avg)
Predictions:  ['02 00']
Answer:  ['false']
  [Batch] Query 1150: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.05s avg)
Checkpoint saved: 1142 queries processed

============================================================
Batch 576/1536: Processing 2 queries
============================================================
Predictions:  ['third floor second floor first floor', '01 02 00 04 01 03 01 04']
Answer:  ['third floor second floor first floor', '02']
Predictions:  ['third floor second floor first floor']
Answer:  ['third floor second floor first floor']
  [Batch] Query 1151: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 100.0} (2.15s avg)
Predictions:  ['01 02 00 04 01 03 01 04']
Answer:  ['02']
  [Batch] Query 1152: {'F1': 22.22, 'EM': 0.0, 'ROUGE-L': 22.22, 'SacreBLEU': 5.52} (2.15s avg)
Checkpoint saved: 1144 queries processed

============================================================
Batch 577/1536: Processing 2 queries
============================================================
Predictions:  ['fresh', 'fresh ready to drink']
Answer:  ['19', 'ready to drink']
Predictions:  ['fresh']
Answer:  ['19']
  [Batch] Query 1153: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.44s avg)
Predictions:  ['fresh ready to drink']
Answer:  ['ready to drink']
  [Batch] Query 1154: {'F1': 85.71, 'EM': 0.0, 'ROUGE-L': 85.71, 'SacreBLEU': 59.46} (1.44s avg)
Checkpoint saved: 1146 queries processed

============================================================
Batch 578/1536: Processing 2 queries
============================================================
Predictions:  ['01', 'applesauce']
Answer:  ['01', 'applesauce ready to drink frozen']
Predictions:  ['01']
Answer:  ['01']
  [Batch] Query 1155: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.46s avg)
Predictions:  ['applesauce']
Answer:  ['applesauce ready to drink frozen']
  [Batch] Query 1156: {'F1': 33.33, 'EM': 0.0, 'ROUGE-L': 33.33, 'SacreBLEU': 0.0} (1.46s avg)
Checkpoint saved: 1148 queries processed

============================================================
Batch 579/1536: Processing 2 queries
============================================================
Predictions:  ['07']
Answer:  ['07']
Predictions:  ['07']
Answer:  ['07']
  [Batch] Query 1158: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.17s avg)
  Warning: Large text input (9546 tokens)
Processing batches:  38%|███▊      | 579/1536 [2:27:32<1:33:24,  5.86s/it]Processing batches:  38%|███▊      | 580/1536 [2:27:34<1:16:51,  4.82s/it]Processing batches:  38%|███▊      | 581/1536 [2:27:42<1:31:48,  5.77s/it]Processing batches:  38%|███▊      | 582/1536 [2:27:46<1:24:30,  5.31s/it]Processing batches:  38%|███▊      | 583/1536 [2:27:50<1:18:32,  4.94s/it]  [Single] Query 1157: {'GPT_EVAL': 'N/A (no eval_api_key)'} (6.42s)
Checkpoint saved: 1150 queries processed

============================================================
Batch 580/1536: Processing 2 queries
============================================================
Predictions:  ['15', '156']
Answer:  ['15', '156']
Predictions:  ['15']
Answer:  ['15']
  [Batch] Query 1159: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.08s avg)
Predictions:  ['156']
Answer:  ['156']
  [Batch] Query 1160: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.08s avg)
Checkpoint saved: 1152 queries processed

============================================================
Batch 581/1536: Processing 2 queries
============================================================
Predictions:  ['1']
Answer:  ['1']
Predictions:  ['1']
Answer:  ['1']
  [Batch] Query 1161: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (0.96s avg)
  [Single] Query 1162: {'GPT_EVAL': 'N/A (no eval_api_key)'} (6.87s)
Checkpoint saved: 1154 queries processed

============================================================
Batch 582/1536: Processing 2 queries
============================================================
Predictions:  ['23', '23 30']
Answer:  ['23', '20year historical average']
Predictions:  ['23']
Answer:  ['23']
  [Batch] Query 1163: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.99s avg)
Predictions:  ['23 30']
Answer:  ['20year historical average']
  [Batch] Query 1164: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.99s avg)
Checkpoint saved: 1156 queries processed

============================================================
Batch 583/1536: Processing 2 queries
============================================================
Predictions:  ['21 23 26', '1']
Answer:  ['21 23 26', '1']
Predictions:  ['21 23 26']
Answer:  ['21 23 26']
  [Batch] Query 1165: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.91s avg)
Predictions:  ['1']
Answer:  ['1']
  [Batch] Query 1166: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.91s avg)
Checkpoint saved: 1158 queries processed

============================================================
Batch 584/1536: Processing 2 queries
============================================================
Predictions:  ['no']
Answer:  ['no']
Predictions:  ['no']
Answer:  ['no']
  [Batch] Query 1168: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (3.28s avg)
  Warning: Large text input (13725 tokens)
Processing batches:  38%|███▊      | 584/1536 [2:28:03<1:55:28,  7.28s/it]Processing batches:  38%|███▊      | 585/1536 [2:35:21<36:00:59, 136.34s/it]Processing batches:  38%|███▊      | 586/1536 [2:35:28<25:48:39, 97.81s/it] Processing batches:  38%|███▊      | 587/1536 [2:35:33<18:22:50, 69.73s/it]Processing batches:  38%|███▊      | 588/1536 [2:35:37<13:11:16, 50.08s/it]Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/data/pan/4xin/datasets/RealHiTBench/tables/economy-table86.xlsx')
data = df[df['Consumer Price Index item'] == 'All food']
prediction_2024 = data[['Prediction Interval 2024 Lower', 'Prediction Interval 2024 Mid', 'Prediction Interval 2024 Upper']].iloc[0].values
labels = ['Lower', 'Mid', 'Upper']
plt.bar(labels, prediction_2024, color=['blue', 'green', 'red'])
plt.xlabel('Prediction Interval 2024')
plt.ylabel('Percent change')
plt.title('Comparison of Prediction Interval 2024 for All food')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

Python Error: "None of [Index(['Prediction Interval 2024 Lower', 'Prediction Interval 2024 Mid',\n       'Prediction Interval 2024 Upper'],\n      dtype='object')] are in the [columns]"
  [Single] Query 1167: {'ECR': False, 'Pass': False} (9.29s)
Checkpoint saved: 1160 queries processed

============================================================
Batch 585/1536: Processing 2 queries
============================================================
Predictions:  ['yes', '47 41 48 48 60 52 49 54 57 50 57 63 68 61 57 58 67 81 85 63 76 63 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00']
Answer:  ['327 yes', '1306']
Predictions:  ['yes']
Answer:  ['327 yes']
  [Batch] Query 1169: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (218.61s avg)
Predictions:  ['47 41 48 48 60 52 49 54 57 50 57 63 68 61 57 58 67 81 85 63 76 63 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00']
Answer:  ['1306']
  [Batch] Query 1170: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (218.61s avg)
Checkpoint saved: 1162 queries processed

============================================================
Batch 586/1536: Processing 2 queries
============================================================
Predictions:  ['dollars in repayment dollars entering default', 'decreasing trend fluctuating trend']
Answer:  ['dollars in repayment', 'decreasing trend']
Predictions:  ['dollars in repayment dollars entering default']
Answer:  ['dollars in repayment']
  [Batch] Query 1171: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 30.21} (3.82s avg)
Predictions:  ['decreasing trend fluctuating trend']
Answer:  ['decreasing trend']
  [Batch] Query 1172: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 31.95} (3.82s avg)
Checkpoint saved: 1164 queries processed

============================================================
Batch 587/1536: Processing 2 queries
============================================================
Predictions:  ['147172 58963', '2015']
Answer:  ['206135', '2015']
Predictions:  ['147172 58963']
Answer:  ['206135']
  [Batch] Query 1173: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.97s avg)
Predictions:  ['2015']
Answer:  ['2015']
  [Batch] Query 1174: {'F1': 100.0, 'EM': 100.0, 'ROUGE-L': 100.0, 'SacreBLEU': 0.0} (1.97s avg)
Checkpoint saved: 1166 queries processed

============================================================
Batch 588/1536: Processing 2 queries
============================================================
Predictions:  ['2015 2014', '2014q4 2015q4']
Answer:  ['2015', '2']
Predictions:  ['2015 2014']
Answer:  ['2015']
  [Batch] Query 1175: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (1.99s avg)
Predictions:  ['2014q4 2015q4']
Answer:  ['2']
  [Batch] Query 1176: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (1.99s avg)
Checkpoint saved: 1168 queries processed

============================================================
Batch 589/1536: Processing 2 queries
============================================================
Predictions:  ['167 68']
Answer:  ['99']
Predictions:  ['167 68']
Answer:  ['99']
  [Batch] Query 1178: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (7.52s avg)
  Warning: Large text input (11733 tokens)
Processing batches:  38%|███▊      | 589/1536 [2:35:46<9:58:49, 37.94s/it] Processing batches:  38%|███▊      | 590/1536 [2:36:11<8:54:20, 33.89s/it]Processing batches:  38%|███▊      | 591/1536 [2:36:34<8:01:13, 30.55s/it]Processing batches:  38%|███▊      | 591/1536 [2:43:03<4:20:43, 16.55s/it]
  [Single] Query 1177: {'GPT_EVAL': 'N/A (no eval_api_key)'} (1.95s)
Checkpoint saved: 1170 queries processed

============================================================
Batch 590/1536: Processing 2 queries
============================================================
Predictions:  ['2000 2020', '109 107 107 108 106 107 107 107 107 107 107']
Answer:  ['2008 2016', '285']
Predictions:  ['2000 2020']
Answer:  ['2008 2016']
  [Batch] Query 1179: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (12.09s avg)
Predictions:  ['109 107 107 108 106 107 107 107 107 107 107']
Answer:  ['285']
  [Batch] Query 1180: {'F1': 0.0, 'EM': 0.0, 'ROUGE-L': 0.0, 'SacreBLEU': 0.0} (12.09s avg)
Checkpoint saved: 1172 queries processed

============================================================
Batch 591/1536: Processing 2 queries
============================================================
Predictions:  ['1978 1979', '21 24 12 29 19 35 35 14 19 34']
Answer:  ['1979', '14']
Predictions:  ['1978 1979']
Answer:  ['1979']
  [Batch] Query 1181: {'F1': 66.67, 'EM': 0.0, 'ROUGE-L': 66.67, 'SacreBLEU': 0.0} (11.25s avg)
Predictions:  ['21 24 12 29 19 35 35 14 19 34']
Answer:  ['14']
  [Batch] Query 1182: {'F1': 18.18, 'EM': 0.0, 'ROUGE-L': 18.18, 'SacreBLEU': 4.2} (11.25s avg)
Checkpoint saved: 1174 queries processed

============================================================
Batch 592/1536: Processing 2 queries
============================================================
Traceback (most recent call last):
  File "/export/home/pan/4xin/RealHiTBENCH-Qwen3-VL/inference/inference_qwen3vl_local_a100.py", line 1702, in <module>
    main()
  File "/export/home/pan/4xin/RealHiTBENCH-Qwen3-VL/inference/inference_qwen3vl_local_a100.py", line 1696, in main
    gen_solution_batch(opt)
  File "/export/home/pan/4xin/RealHiTBENCH-Qwen3-VL/inference/inference_qwen3vl_local_a100.py", line 1186, in gen_solution_batch
    batch_results = process_batch_queries(
  File "/export/home/pan/4xin/RealHiTBENCH-Qwen3-VL/inference/inference_qwen3vl_local_a100.py", line 955, in process_batch_queries
    batch_responses = get_batch_final_answers_local(
  File "/export/home/pan/4xin/RealHiTBENCH-Qwen3-VL/inference/inference_qwen3vl_local_a100.py", line 590, in get_batch_final_answers_local
    responses = get_batch_text_response_local(pending_messages, model, processor, opt)
  File "/export/home/pan/4xin/RealHiTBENCH-Qwen3-VL/inference/inference_qwen3vl_local_a100.py", line 533, in get_batch_text_response_local
    generated_ids = base_model.generate(**generate_kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/generation/utils.py", line 2566, in generate
    result = decoding_method(
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/generation/utils.py", line 2789, in _sample
    outputs = model_forward(**model_inputs, return_dict=True)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/models/qwen3_vl/modeling_qwen3_vl.py", line 1344, in forward
    outputs = self.model(
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/models/qwen3_vl/modeling_qwen3_vl.py", line 1223, in forward
    outputs = self.language_model(
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/utils/generic.py", line 1072, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/models/qwen3_vl/modeling_qwen3_vl.py", line 850, in forward
    layer_outputs = decoder_layer(
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/models/qwen3_vl/modeling_qwen3_vl.py", line 502, in forward
    hidden_states, _ = self.self_attn(
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/models/qwen3_vl/modeling_qwen3_vl.py", line 444, in forward
    attn_output, attn_weights = attention_interface(
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/integrations/flash_attention.py", line 66, in flash_attention_forward
    attn_output = _flash_attention_forward(
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/modeling_flash_attention_utils.py", line 607, in _flash_attention_forward
    q, k, v, indices_q, (cu_seq_lens_q, cu_seq_lens_k), (max_length_q, max_length_k) = _upad_input(
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/modeling_flash_attention_utils.py", line 278, in _upad_input
    indices_k, cu_seqlens_k, max_seqlen_in_batch_k = _get_unpad_data(attention_mask)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/site-packages/transformers/modeling_flash_attention_utils.py", line 225, in _get_unpad_data
    indices = torch.nonzero(attention_mask.flatten(), as_tuple=False).flatten()
KeyboardInterrupt
Running inference for text_html (all question types)...
Command: /export/home/pan/miniconda3/envs/4xin-hit/bin/python /export/home/pan/4xin/RealHiTBENCH-Qwen3-VL/inference/inference_qwen3vl_local_a100.py --modality text --format html --model_dir /data/pan/4xin/models/Qwen3-VL-8B-Instruct --data_path /data/pan/4xin/datasets/RealHiTBench --qa_path /export/home/pan/4xin/RealHiTBENCH-Qwen3-VL/data --batch_size 2 --use_sc_filled
--------------------------------------------------------------------------------
Traceback (most recent call last):
  File "/export/home/pan/4xin/RealHiTBENCH-Qwen3-VL/inference/run_text_html.py", line 52, in <module>
    main()
  File "/export/home/pan/4xin/RealHiTBENCH-Qwen3-VL/inference/run_text_html.py", line 43, in main
    result = subprocess.run(cmd, cwd=script_dir)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/subprocess.py", line 505, in run
    stdout, stderr = process.communicate(input, timeout=timeout)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/subprocess.py", line 1146, in communicate
    self.wait()
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/subprocess.py", line 1209, in wait
    return self._wait(timeout=timeout)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/subprocess.py", line 1959, in _wait
    (pid, sts) = self._try_wait(0)
  File "/export/home/pan/miniconda3/envs/4xin-hit/lib/python3.10/subprocess.py", line 1917, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
KeyboardInterrupt
