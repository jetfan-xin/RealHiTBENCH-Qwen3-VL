nohup: ignoring input
Configuration:
  Model: /mnt/data1/users/4xin/qwen/Qwen3-VL-8B-Instruct
  Modality: text
  Format: html
  Data path: /mnt/data1/users/4xin/RealHiTBench
  Use Flash Attention: True
  Temperature: 0.0
  Batch size: 1

Loading Qwen3-VL model from /mnt/data1/users/4xin/qwen/Qwen3-VL-8B-Instruct...
Available GPUs: 1
`torch_dtype` is deprecated! Use `dtype` instead!
Warning: Could not load with flash_attention_2: /mnt/data1/users/4xin/conda_envs/HIT/lib/python3.10/site-packages/flash_attn_2_cuda.cpython-310-x86_64-linux-gnu.so: undefined symbol: _ZN3c105ErrorC2ENS_14SourceLocationESs
Falling back to default attention implementation...
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:02,  1.08it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:01<00:01,  1.07it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:02<00:00,  1.05it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.27it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.18it/s]
Model distributed across devices: {0}
Successfully loaded F1, EM, ROUGE, SacreBLEU
Processing text modality:   0%|          | 0/3071 [00:00<?, ?it/s]
============================================================
Query ID: 1 | Type: Fact Checking | SubType: Multi-hop Fact Checking
============================================================
Predictions:  ['1953 6260']
Answer:  ['1955 62170']
Prediction: 1953, 6260
Reference: 1955, 62170
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   0%|          | 1/3071 [00:04<4:04:12,  4.77s/it]
============================================================
Query ID: 2 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['1953']
Answer:  ['1954']
Prediction: 1953
Reference: 1954
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   0%|          | 2/3071 [00:08<3:46:28,  4.43s/it]
============================================================
Query ID: 3 | Type: Fact Checking | SubType: Multi-hop Fact Checking
============================================================
Predictions:  ['2022']
Answer:  ['1953']
Prediction: 2022
Reference: 1953
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   0%|          | 3/3071 [00:13<3:40:51,  4.32s/it]
============================================================
Query ID: 4 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['161037']
Answer:  ['158772']
Prediction: 161037
Reference: 158772
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   0%|          | 4/3071 [00:17<3:40:05,  4.31s/it]
============================================================
Query ID: 5 | Type: Data Analysis | SubType: Rudimentary Analysis
============================================================
Predictions:  ['55 16']
Answer:  ['58 16']
Prediction: 5.47, 1.58
Reference: 5.80, 1.62
Metrics: {'F1': 50.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(50.0), 'SacreBLEU': 0.0}
Processing text modality:   0%|          | 5/3071 [00:21<3:42:57,  4.36s/it]
============================================================
Query ID: 6 | Type: Data Analysis | SubType: Summary Analysis
============================================================
Error processing query 6: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    eval_prompt = Eval_Prompt[query['SubQType']].format_map({
KeyError: 'User_Answer'
Processing text modality:   0%|          | 6/3071 [00:35<6:26:22,  7.56s/it]
============================================================
Query ID: 7 | Type: Data Analysis | SubType: Predictive Analysis
============================================================
Predictions:  ['562 increasing trend']
Answer:  ['predicted percentage for 1965 551']
Prediction: 56.2, Increasing trend
Reference: Predicted percentage for 1965: 55.12%
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   0%|          | 7/3071 [00:40<5:32:41,  6.51s/it]
============================================================
Query ID: 8 | Type: Data Analysis | SubType: Exploratory Analysis
============================================================
Predictions:  ['strong positive correlation 10']
Answer:  ['strong positive correlation 10']
Prediction: Strong positive correlation, 0.99
Reference: Strong positive correlation, 1.00
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 100.0}
Processing text modality:   0%|          | 8/3071 [00:44<4:58:41,  5.85s/it]
============================================================
Query ID: 9 | Type: Data Analysis | SubType: Anomaly Analysis
============================================================
Error processing query 9: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    eval_prompt = Eval_Prompt[query['SubQType']].format_map({
KeyError: 'User_Answer'
Processing text modality:   0%|          | 9/3071 [00:49<4:51:14,  5.71s/it]
============================================================
Query ID: 10 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['1983']
Answer:  ['1983']
Prediction: 1983
Reference: 1983
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   0%|          | 10/3071 [00:54<4:36:19,  5.42s/it]
============================================================
Query ID: 11 | Type: Fact Checking | SubType: Multi-hop Fact Checking
============================================================
Predictions:  ['no']
Answer:  ['no']
Prediction: No
Reference: No
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   0%|          | 11/3071 [00:59<4:24:24,  5.18s/it]
============================================================
Query ID: 12 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['44627']
Answer:  ['39957']
Prediction: 4462.6667
Reference: 3995.67
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Checkpoint saved: 10 queries processed
Processing text modality:   0%|          | 12/3071 [01:04<4:21:27,  5.13s/it]
============================================================
Query ID: 13 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['no']
Answer:  ['yes']
Prediction: No
Reference: Yes
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   0%|          | 13/3071 [01:08<4:13:24,  4.97s/it]
============================================================
Query ID: 14 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['1986']
Answer:  ['1986']
Prediction: 1986
Reference: 1986
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   0%|          | 14/3071 [01:13<4:11:08,  4.93s/it]
============================================================
Query ID: 15 | Type: Visualization | SubType: BarChart Generation
============================================================
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel("/mnt/data1/users/4xin/RealHiTBench/tables/employment-table02.xlsx")
years = [1985, 1987, 1989]
civilian_population = df[df['Year'].isin(years)]['Civilian noninstitutional population'].values
employed_population = df[df['Year'].isin(years)]['Employed Total'].values
plt.bar(years, civilian_population, label='Civilian Population', color='blue')
plt.bar(years, employed_population, bottom=civilian_population, label='Employed Population', color='orange')
plt.xlabel('Year')
plt.ylabel('Population')
plt.title('Civilian Population vs Employed Population (1985, 1987, 1989)')
plt.legend()
plt.xticks(years)
plt.show()

Python Error: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.
Prediction: import pandas as pd 
 import matplotlib.pyplot as plt 
 df = pd.read_excel("table.xlsx")
 years = [1985, 1987, 1989]
 civilian_population = df[df['Year'].isin(years)]['Civilian noninstitutional popula...
Reference: [93736, 95853, 97630, 59891, 62107, 64315]

Metrics: {'ECR': False, 'Pass': 'None'}
Processing text modality:   0%|          | 15/3071 [01:25<5:58:21,  7.04s/it]
============================================================
Query ID: 16 | Type: Visualization | SubType: ScatterChart Generation
============================================================
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel("/mnt/data1/users/4xin/RealHiTBench/tables/employment-table02.xlsx")
df_men = df[df['Year'].isin(df['Year']) & (df['Year'].str.contains('Men'))]
df_women = df[df['Year'].isin(df['Year']) & (df['Year'].str.contains('Women'))]
df_total = pd.concat([df_men, df_women], ignore_index=True)
df_total = df_total.dropna(subset=['Year'])
df_total['Unemployment Rate'] = df_total['Unemployment Rate'].astype(float)
df_total['Total Civilian Labor Force'] = df_total['Total Civilian Labor Force'].astype(int)
plt.scatter(df_total['Unemployment Rate'], df_total['Total Civilian Labor Force'])
plt.xlabel('Unemployment Rate')
plt.ylabel('Total Civilian Labor Force')
plt.title('Relationship between Unemployment Rate and Total Civilian Labor Force')
plt.show()

Python Error: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.
Prediction: import pandas as pd 
 import matplotlib.pyplot as plt 
 df = pd.read_excel("table.xlsx")
 df_men = df[df['Year'].isin(df['Year']) & (df['Year'].str.contains('Men'))]
 df_women = df[df['Year'].isin(df[...
Reference: [[9.9, 7.4, 7.0, 6.9, 6.2, 5.5, 5.2, 5.7, 7.2, 7.9, 7.2, 6.2, 5.6, 5.4, 4.9, 4.4, 4.1, 3.9, 4.8, 5.9, 6.3, 5.6, 5.1, 4.6, 4.7, 6.1, 10.3, 10.5, 9.4, 8.2, 7.6, 6.3, 5.4, 4.9, 4.4, 3.9, 3.7, 7.8, 5.5, 3...
Metrics: {'ECR': False, 'Pass': 'None'}
Processing text modality:   1%|          | 16/3071 [01:38<7:27:45,  8.79s/it]
============================================================
Query ID: 17 | Type: Visualization | SubType: PieChart Generation
============================================================
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel("/mnt/data1/users/4xin/RealHiTBench/tables/employment-table02.xlsx")
data_1984 = df[df['Year'] == 1984]
agriculture = data_1984.iloc[0]['Agri- culture']
non_agriculture = data_1984.iloc[0]['Nonagri- cultural industries']
labels = ['Agriculture', 'Non-agriculture']
sizes = [agriculture, non_agriculture]
plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140)
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
plt.title('Employment Distribution in 1984')
plt.show()

Python Error: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.
Prediction: import pandas as pd 
 import matplotlib.pyplot as plt 
 df = pd.read_excel("table.xlsx")
 data_1984 = df[df['Year'] == 1984]
 agriculture = data_1984.iloc[0]['Agri- culture']
 non_agriculture = data_1...
Reference: [0.05, 0.95]

Metrics: {'ECR': False, 'Pass': 'None'}
Processing text modality:   1%|          | 17/3071 [01:50<8:10:36,  9.64s/it]
============================================================
Query ID: 18 | Type: Visualization | SubType: LineChart Generation
============================================================
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel("/mnt/data1/users/4xin/RealHiTBench/tables/employment-table02.xlsx")
df = df[df['Year'].between(1983, 1990)]
df.set_index('Year', inplace=True)
df[['Employed Total', 'Unemployed Total']] = df[['Total', 'Number']].iloc[:, [0, 3]]
df[['Employed Total', 'Unemployed Total']] = df[['Employed Total', 'Unemployed Total']].astype(int)
df.plot(kind='line', figsize=(10, 6))
plt.title('Trends of Total Employed and Unemployed Population from 1983 to 1990')
plt.xlabel('Year')
plt.ylabel('Population')
plt.legend(['Employed', 'Unemployed'])
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

Python Error: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.
Prediction: import pandas as pd 
 import matplotlib.pyplot as plt 
 df = pd.read_excel("table.xlsx")
 df = df[df['Year'].between(1983, 1990)]
 df.set_index('Year', inplace=True)
 df[['Employed Total', 'Unemployed...
Reference: [[56787, 59091, 59891, 60892, 62107, 63273, 64315, 65104], [6260, 4744, 4521, 4530, 4101, 3655, 3525, 3906], [44047, 45915, 47259, 48706, 50334, 51696, 53027, 53689], [4457, 3794, 3791, 3707, 3324, 30...
Metrics: {'ECR': False, 'Pass': 'None'}
Processing text modality:   1%|          | 18/3071 [02:02<8:48:36, 10.39s/it]
============================================================
Query ID: 19 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['161037 6360 2174 3473 14725 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537 75537']
Answer:  ['161037']
Prediction: 161037, 6360, 2174, 3473, 14725, 75537, 75537, 75537, 75537, 75537, 75537, 75537, 75537, 75537, 75537, 75537, 75537, 75537, 75537, 75537, 75537, 75537, 75537, 75537, 75537, 75537, 75537, 75537, 75537,...
Reference: 161037
Metrics: {'F1': 0.34, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.34), 'SacreBLEU': 0.06}
Processing text modality:   1%|          | 19/3071 [06:38<76:26:36, 90.17s/it]
============================================================
Query ID: 20 | Type: Numerical Reasoning | SubType: Ranking
============================================================
Predictions:  ['35 to 44 years 30 to 34 years']
Answer:  ['35 to 39 years 35 to 44 years']
Prediction: 35 to 44 years, 30 to 34 years
Reference: 35 to 39 years, 35 to 44 years
Metrics: {'F1': 75.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(62.5), 'SacreBLEU': 38.26}
Processing text modality:   1%|          | 20/3071 [06:55<57:50:23, 68.25s/it]
============================================================
Query ID: 21 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['167116 99826']
Answer:  ['99826']
Prediction: 167116, 99826
Reference: 99826
Metrics: {'F1': 66.67, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 0.0}
Processing text modality:   1%|          | 21/3071 [07:12<44:46:12, 52.84s/it]
============================================================
Query ID: 22 | Type: Numerical Reasoning | SubType: Multi-hop Numerical Reasoning
============================================================
Predictions:  ['626 36']
Answer:  ['639']
Prediction: 62.6, 3.6
Reference: 63.90
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Checkpoint saved: 20 queries processed
Processing text modality:   1%|          | 22/3071 [07:29<35:34:40, 42.01s/it]
============================================================
Query ID: 23 | Type: Visualization | SubType: PieChart Generation
============================================================
Code: import pandas as pd
import matplotlib.pyplot as plt

# Load the data from the HTML table
df = pd.read_html('/mnt/data1/users/4xin/RealHiTBench/tables/employment-table03.xlsx', header=0)[0]

# Filter the data for '16 years and over' age group
age_group = '16 years and over'
row_index = df[df.iloc[:, 0] == age_group].index[0]

# Extract the values for 'employed', 'unemployed', and 'not in the labor force'
employed = df.iloc[row_index, 4]
unemployed = df.iloc[row_index, 6]
not_in_labor_force = df.iloc[row_index, 8]

# Create a pie chart
labels = ['Employed', 'Unemployed', 'Not in Labor Force']
sizes = [employed, unemployed, not_in_labor_force]
colors = ['lightblue', 'lightcoral', 'lightgreen']
explode = (0.1, 0, 0)  # explode the first slice (Employed)

plt.figure(figsize=(8, 8))
plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=140)
plt.title('Distribution of Civilian Non-Institutional Population (16 years and over)')
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
plt.show()

Python Error: Missing optional dependency 'html5lib'.  Use pip or conda to install html5lib.
Prediction: import pandas as pd 
 import matplotlib.pyplot as plt 

# Load the data from the HTML table
df = pd.read_html('table.xlsx', header=0)[0]

# Filter the data for '16 years and over' age group
age_group ...
Reference: [0.6, 0.02, 0.37]

Metrics: {'ECR': False, 'Pass': 'None'}
Processing text modality:   1%|          | 23/3071 [08:03<33:36:24, 39.69s/it]
============================================================
Query ID: 24 | Type: Visualization | SubType: BarChart Generation
============================================================
Code: import pandas as pd
import matplotlib.pyplot as plt

# Load the data from the HTML table
df = pd.read_html('/mnt/data1/users/4xin/RealHiTBench/tables/employment-table03.xlsx', header=0)[0]

# Filter the data for unemployment rates (percentage of labor force unemployed)
# We need to extract the relevant rows and columns
unemployment_data = df[df['Age, sex, and race'].isin(['16 years and over', '16 to 19 years', '18 to 19 years', '20 to 24 years', '25 to 54 years', '25 to 34 years', '30 to 34 years', '35 to 44 years', '35 to 39 years', '40 to 44 years', '45 to 54 years', '45 to 49 years', '50 to 54 years', '55 to 64 years', '55 to 59 years', '60 to 64 years', '65 years and over', '65 to 69 years', '70 to 74 years', '75 years and over'])]

# Extract the unemployment rates (column 7: Percent of labor force unemployed)
unemployment_rates = unemployment_data['Percent of labor force unemployed'].dropna()

# Create a bar chart
plt.figure(figsize=(14, 8))
plt.bar(unemployment_rates.index, unemployment_rates.values, color='blue')
plt.xlabel('Age Groups')
plt.ylabel('Unemployment Rate (%)')
plt.title('Unemployment Rates by Age Group')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

Python Error: Missing optional dependency 'html5lib'.  Use pip or conda to install html5lib.
Prediction: import pandas as pd 
 import matplotlib.pyplot as plt 

# Load the data from the HTML table
df = pd.read_html('table.xlsx', header=0)[0]

# Filter the data for unemployment rates (percentage of labor ...
Reference: [12.64, 12.016666666666666, 3.858333333333333, 12.0, 7.108333333333333, 4.841666666666667, 4.191666666666666, 3.341666666666667, 3.591666666666667, 3.091666666666667, 3.0416666666666665, 3.00833333333...
Metrics: {'ECR': False, 'Pass': 'None'}
Processing text modality:   1%|          | 24/3071 [08:41<33:12:50, 39.24s/it]
============================================================
Query ID: 25 | Type: Numerical Reasoning | SubType: Comparison
============================================================
Predictions:  ['18 to 19 years 16 to 17 years']
Answer:  ['16 to 17 years']
Prediction: 18 to 19 years, 16 to 17 years
Reference: 16 to 17 years
Metrics: {'F1': 66.67, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 34.57}
Processing text modality:   1%|          | 25/3071 [08:45<24:11:55, 28.60s/it]
============================================================
Query ID: 26 | Type: Numerical Reasoning | SubType: Counting
============================================================
Predictions:  ['15714 2892 1867 1026 1411 5034 1797 933 864 1694 855 839 1543 810 1961 841 1119 4416 1329 1145 1942']
Answer:  ['101529']
Prediction: 15714, 2892, 1867, 1026, 1411, 5034, 1797, 933, 864, 1694, 855, 839, 1543, 810, 1961, 841, 1119, 4416, 1329, 1145, 1942
Reference: 101529
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   1%|          | 26/3071 [08:53<18:54:13, 22.35s/it]
============================================================
Query ID: 27 | Type: Numerical Reasoning | SubType: Ranking
============================================================
Predictions:  ['25 to 54 years 35 to 44 years 40 to 44 years 30 to 34 years 25 to 34 years 45 to 54 years 35 to 39 years 45 to 49 years 50 to 54 years 55 to 64 years 60 to 64 years 65 to 69 years 70 to 74 years 75 years and over 18 to 19 years 20 to 24 years 16 to 19 years 16 to 17 years 16 years and over 25 to 29 years 30 to 34 years 35 to 44 years 40 to 44 years 45 to 54 years 55 to 64 years 60 to 64 years 65 to 69 years 70 to 74 years 75 years and over 18 to 19 years 20 to 24 years 16 to 19 years 16 to 17 years 16 years and over 25 to 29 years 30 to 34 years 35 to 44 years 40 to 44 years 45 to 54 years 55 to 64 years 60 to 64 years 65 to 69 years 70 to 74 years 75 years and over']
Answer:  ['45 to 49 years 40 to 44 years 35 to 39 years 35 to 44 years 25 to 54 years']
Prediction: 25 to 54 years, 35 to 44 years, 40 to 44 years, 30 to 34 years, 25 to 34 years, 45 to 54 years, 35 to 39 years, 45 to 49 years, 50 to 54 years, 55 to 64 years, 60 to 64 years, 65 to 69 years, 70 to 74...
Reference: 45 to 49 years, 40 to 44 years, 35 to 39 years, 35 to 44 years, 25 to 54 years
Metrics: {'F1': 20.41, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(18.37), 'SacreBLEU': 8.23}
Processing text modality:   1%|          | 27/3071 [09:11<17:49:22, 21.08s/it]
============================================================
Query ID: 28 | Type: Numerical Reasoning | SubType: Multi-hop Numerical Reasoning
============================================================
Predictions:  ['66']
Answer:  ['66']
Prediction: 6.6
Reference: 6.60
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   1%|          | 28/3071 [09:14<13:17:44, 15.73s/it]
============================================================
Query ID: 29 | Type: Data Analysis | SubType: Rudimentary Analysis
============================================================
Predictions:  ['188 126']
Answer:  ['188 126']
Prediction: 188, 12.6
Reference: 188, 12.60
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   1%|          | 29/3071 [09:17<10:11:24, 12.06s/it]
============================================================
Query ID: 30 | Type: Data Analysis | SubType: Summary Analysis
============================================================
Error processing query 30: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    eval_prompt = Eval_Prompt[query['SubQType']].format_map({
KeyError: 'User_Answer'
Processing text modality:   1%|          | 30/3071 [09:27<9:28:24, 11.21s/it] 
============================================================
Query ID: 31 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['164287']
Answer:  ['164287']
Prediction: 164287
Reference: 164287
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   1%|          | 31/3071 [09:29<7:18:23,  8.65s/it]
============================================================
Query ID: 32 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['2023 2022']
Answer:  ['2023']
Prediction: 2023, 2022
Reference: 2023
Metrics: {'F1': 66.67, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 0.0}
Processing text modality:   1%|          | 32/3071 [09:32<5:49:38,  6.90s/it]
============================================================
Query ID: 33 | Type: Fact Checking | SubType: Multi-hop Fact Checking
============================================================
Predictions:  ['2829']
Answer:  ['2829']
Prediction: 2829
Reference: 2829
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Checkpoint saved: 30 queries processed
Processing text modality:   1%|          | 33/3071 [09:35<4:44:09,  5.61s/it]
============================================================
Query ID: 34 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['yes']
Answer:  ['yes']
Prediction: Yes
Reference: Yes
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   1%|          | 34/3071 [09:37<3:56:01,  4.66s/it]
============================================================
Query ID: 35 | Type: Visualization | SubType: LineChart Generation
============================================================
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/mnt/data1/users/4xin/RealHiTBench/tables/employment-table05.xlsx', sheet_name=0)
data = df.iloc[3:5, 1:3].values
years = ['2022', '2023']
populations = data.flatten()
plt.plot(years, populations, marker='o')
plt.title('Trend in Total Civilian Noninstitutional Population from 2022 to 2023')
plt.xlabel('Year')
plt.ylabel('Population')
plt.xticks(years)
plt.grid(True)
plt.show()

Python Error: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.
Prediction: import pandas as pd 
 import matplotlib.pyplot as plt 
 df = pd.read_excel('table.xlsx', sheet_name=0)
 data = df.iloc[3:5, 1:3].values
 years = ['2022', '2023']
 populations = data.flatten()
 plt.plo...
Reference: [[263973.0, 266942.0]]

Metrics: {'ECR': False, 'Pass': 'None'}
Processing text modality:   1%|          | 35/3071 [09:44<4:27:54,  5.29s/it]
============================================================
Query ID: 36 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['543']
Answer:  ['543']
Prediction: 543
Reference: 543
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   1%|          | 36/3071 [09:47<3:47:52,  4.51s/it]
============================================================
Query ID: 37 | Type: Numerical Reasoning | SubType: Ranking
============================================================
Predictions:  ['men 16 years and over women 16 years and over']
Answer:  ['men women']
Prediction: Men, 16 years and over, Women, 16 years and over
Reference: Men, Women
Metrics: {'F1': 33.33, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(33.33), 'SacreBLEU': 4.99}
Processing text modality:   1%|          | 37/3071 [09:50<3:27:10,  4.10s/it]
============================================================
Query ID: 38 | Type: Numerical Reasoning | SubType: Comparison
============================================================
Predictions:  ['3926 13233']
Answer:  ['4135']
Prediction: 3926, 13233
Reference: 4135
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   1%|          | 38/3071 [09:53<3:09:49,  3.76s/it]
============================================================
Query ID: 39 | Type: Numerical Reasoning | SubType: Counting
============================================================
Predictions:  ['663 669']
Answer:  ['1332']
Prediction: 66.3, 66.9
Reference: 133.2
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   1%|▏         | 39/3071 [09:56<2:57:07,  3.51s/it]
============================================================
Query ID: 40 | Type: Data Analysis | SubType: Rudimentary Analysis
============================================================
Predictions:  ['573 587']
Answer:  ['mean 2022 622 median 2022 629 mean 2023 628 median 2023 640']
Prediction: 57.3, 58.7
Reference: Mean 2022: 62.25, Median 2022: 62.85, Mean 2023: 62.77, Median 2023: 64.00
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   1%|▏         | 40/3071 [09:59<2:48:14,  3.33s/it]
============================================================
Query ID: 41 | Type: Data Analysis | SubType: Summary Analysis
============================================================
Error processing query 41: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    eval_prompt = Eval_Prompt[query['SubQType']].format_map({
KeyError: 'User_Answer'
Processing text modality:   1%|▏         | 41/3071 [10:10<4:55:41,  5.86s/it]
============================================================
Query ID: 42 | Type: Fact Checking | SubType: Multi-hop Fact Checking
============================================================
Predictions:  ['39357 24720']
Answer:  ['39357']
Prediction: 39357, 24720
Reference: 39357
Metrics: {'F1': 66.67, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 0.0}
Processing text modality:   1%|▏         | 42/3071 [10:13<4:11:37,  4.98s/it]
============================================================
Query ID: 43 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['bachelors degree only associate degree']
Answer:  ['associate degree']
Prediction: Bachelor's degree only, Associate degree
Reference: Associate degree
Metrics: {'F1': 57.14, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(57.14), 'SacreBLEU': 21.36}
Processing text modality:   1%|▏         | 43/3071 [10:16<3:37:21,  4.31s/it]
============================================================
Query ID: 44 | Type: Fact Checking | SubType: Multi-hop Fact Checking
============================================================
Predictions:  ['16796 17302']
Answer:  ['7668']
Prediction: 16796, 17302
Reference: 7668
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Checkpoint saved: 40 queries processed
Processing text modality:   1%|▏         | 44/3071 [10:19<3:16:46,  3.90s/it]
============================================================
Query ID: 45 | Type: Numerical Reasoning | SubType: Comparison
============================================================
Predictions:  ['women less than high school diploma']
Answer:  ['women']
Prediction: Women, Less than a high school diploma
Reference: Women
Metrics: {'F1': 28.57, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(28.57), 'SacreBLEU': 8.12}
Processing text modality:   1%|▏         | 45/3071 [10:22<2:59:30,  3.56s/it]
============================================================
Query ID: 46 | Type: Data Analysis | SubType: Summary Analysis
============================================================
Error processing query 46: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    eval_prompt = Eval_Prompt[query['SubQType']].format_map({
KeyError: 'User_Answer'
Processing text modality:   1%|▏         | 46/3071 [10:30<4:08:29,  4.93s/it]
============================================================
Query ID: 47 | Type: Data Analysis | SubType: Predictive Analysis
============================================================
Predictions:  ['increasing trend increasing trend']
Answer:  ['increasing trend']
Prediction: Increasing trend, Increasing trend
Reference: Increasing trend
Metrics: {'F1': 66.67, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 31.95}
Processing text modality:   2%|▏         | 47/3071 [10:33<3:34:19,  4.25s/it]
============================================================
Query ID: 48 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['men women']
Answer:  ['men']
Prediction: Men, Women
Reference: Men
Metrics: {'F1': 66.67, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 0.0}
Processing text modality:   2%|▏         | 48/3071 [10:36<3:16:37,  3.90s/it]
============================================================
Query ID: 49 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['436']
Answer:  ['436']
Prediction: 43.6
Reference: 43.60
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   2%|▏         | 49/3071 [10:39<3:05:25,  3.68s/it]
============================================================
Query ID: 50 | Type: Fact Checking | SubType: Multi-hop Fact Checking
============================================================
Predictions:  ['08 05']
Answer:  ['07']
Prediction: 0.8, 0.5
Reference: 0.70
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   2%|▏         | 50/3071 [10:42<2:59:54,  3.57s/it]
============================================================
Query ID: 51 | Type: Data Analysis | SubType: Rudimentary Analysis
============================================================
Predictions:  ['478 481']
Answer:  ['478']
Prediction: 47.8, 48.1
Reference: 47.80
Metrics: {'F1': 66.67, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 0.0}
Processing text modality:   2%|▏         | 51/3071 [10:46<2:57:13,  3.52s/it]
============================================================
Query ID: 52 | Type: Data Analysis | SubType: Summary Analysis
============================================================
Error processing query 52: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    eval_prompt = Eval_Prompt[query['SubQType']].format_map({
KeyError: 'User_Answer'
Processing text modality:   2%|▏         | 52/3071 [10:55<4:26:19,  5.29s/it]
============================================================
Query ID: 53 | Type: Numerical Reasoning | SubType: Ranking
============================================================
Predictions:  ['management professional and related occupations management occupations business and financial operations occupations']
Answer:  ['management professional and related occupations management occupations business and financial operations occupations']
Prediction: Management, professional, and related occupations, Management occupations, Business and financial operations occupations
Reference: Management, professional, and related occupations, Management occupations, Business and financial operations occupations
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 100.0}
Processing text modality:   2%|▏         | 53/3071 [10:57<3:43:19,  4.44s/it]
============================================================
Query ID: 54 | Type: Numerical Reasoning | SubType: Comparison
============================================================
Predictions:  ['35083 33016']
Answer:  ['2067']
Prediction: 35083, 33016
Reference: 2067
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   2%|▏         | 54/3071 [11:00<3:11:33,  3.81s/it]
============================================================
Query ID: 55 | Type: Visualization | SubType: ScatterChart Generation
============================================================
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel("/mnt/data1/users/4xin/RealHiTBench/tables/employment-table09.xlsx")
men_2023 = df[df['Occupation'] != 'Total']['Men 2023'].dropna().values
women_2023 = df[df['Occupation'] != 'Total']['Women 2023'].dropna().values
plt.scatter(men_2023, women_2023)
plt.xlabel('Men Employment in 2023')
plt.ylabel('Women Employment in 2023')
plt.title('Relationship between Men and Women Employment in 2023')
plt.show()

Python Error: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.
Prediction: import pandas as pd 
 import matplotlib.pyplot as plt 
 df = pd.read_excel("table.xlsx")
 men_2023 = df[df['Occupation'] != 'Total']['Men 2023'].dropna().values
 women_2023 = df[df['Occupation'] != 'T...
Reference: [[2987.0, 1769.0, 3063.0, 4414.0, 863.0, 4729.0, 7881.0, 2528.0, 658.0, 3021.0, 2426.0, 783.0, 4571.0, 909.0, 934.0, 12104.0, 16518.0, 33663.0, 13111.0, 4400.0, 961.0, 5675.0, 14435.0, 17145.0, 2306.0...
Metrics: {'ECR': False, 'Pass': 'None'}
Processing text modality:   2%|▏         | 55/3071 [11:06<3:55:17,  4.68s/it]
============================================================
Query ID: 56 | Type: Visualization | SubType: PieChart Generation
============================================================
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel("/mnt/data1/users/4xin/RealHiTBench/tables/employment-table09.xlsx")
data_2023 = df[df['Occupation'].isin(['Management occupations', 'Business and financial operations occupations', 'Management, professional, and related occupations'])]
data_2023 = data_2023.iloc[:, 2:4]  # Select 2023 data for men and women
data_2023 = data_2023.sum(axis=1)  # Sum men and women for each occupation
labels = data_2023.index
sizes = data_2023.values
plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140)
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
plt.title('Proportion of Total Employment in 2023')
plt.show()

Python Error: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.
Prediction: import pandas as pd 
 import matplotlib.pyplot as plt 
 df = pd.read_excel("table.xlsx")
 data_2023 = df[df['Occupation'].isin(['Management occupations', 'Business and financial operations occupations...
Reference: [0.53, 0.23, 0.16, 0.07]

Metrics: {'ECR': False, 'Pass': 'None'}
Checkpoint saved: 50 queries processed
Processing text modality:   2%|▏         | 56/3071 [11:15<4:59:09,  5.95s/it]
============================================================
Query ID: 57 | Type: Numerical Reasoning | SubType: Multi-hop Numerical Reasoning
============================================================
Predictions:  ['24153 24246']
Answer:  ['24165']
Prediction: 24153, 24246
Reference: 24165
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   2%|▏         | 57/3071 [11:18<4:04:37,  4.87s/it]
============================================================
Query ID: 58 | Type: Fact Checking | SubType: Multi-hop Fact Checking
============================================================
Predictions:  ['119454 26981']
Answer:  ['134056 26981']
Prediction: 119454, 26981
Reference: 134056, 26981
Metrics: {'F1': 50.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(50.0), 'SacreBLEU': 0.0}
Processing text modality:   2%|▏         | 58/3071 [11:23<4:11:37,  5.01s/it]
============================================================
Query ID: 59 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['4945 1135']
Answer:  ['3810']
Prediction: 4945, 1135
Reference: 3810
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   2%|▏         | 59/3071 [11:28<4:14:37,  5.07s/it]
============================================================
Query ID: 60 | Type: Fact Checking | SubType: Multi-hop Fact Checking
============================================================
Predictions:  ['1200 536']
Answer:  ['parttime workers']
Prediction: 1200, 536
Reference: Part-time workers
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   2%|▏         | 60/3071 [11:33<4:16:00,  5.10s/it]
============================================================
Query ID: 61 | Type: Data Analysis | SubType: Anomaly Analysis
============================================================
Error processing query 61: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    eval_prompt = Eval_Prompt[query['SubQType']].format_map({
KeyError: 'User_Answer'
Processing text modality:   2%|▏         | 61/3071 [11:38<4:11:50,  5.02s/it]
============================================================
Query ID: 62 | Type: Data Analysis | SubType: Summary Analysis
============================================================
Error processing query 62: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    eval_prompt = Eval_Prompt[query['SubQType']].format_map({
KeyError: 'User_Answer'
Processing text modality:   2%|▏         | 62/3071 [11:56<7:29:13,  8.96s/it]
============================================================
Query ID: 63 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['5243']
Answer:  ['5243']
Prediction: 5243
Reference: 5243
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   2%|▏         | 63/3071 [11:59<5:52:08,  7.02s/it]
============================================================
Query ID: 64 | Type: Fact Checking | SubType: Multi-hop Fact Checking
============================================================
Predictions:  ['white black']
Answer:  ['white']
Prediction: White, Black
Reference: White
Metrics: {'F1': 66.67, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 0.0}
Processing text modality:   2%|▏         | 64/3071 [12:01<4:42:59,  5.65s/it]
============================================================
Query ID: 65 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['17']
Answer:  ['17']
Prediction: 1.73
Reference: 1.73
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   2%|▏         | 65/3071 [12:04<3:55:42,  4.70s/it]
============================================================
Query ID: 66 | Type: Data Analysis | SubType: Predictive Analysis
============================================================
Predictions:  ['increasing trend']
Answer:  ['stabilize']
Prediction: Increasing trend
Reference: Stabilize
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   2%|▏         | 66/3071 [12:06<3:21:13,  4.02s/it]
============================================================
Query ID: 67 | Type: Data Analysis | SubType: Rudimentary Analysis
============================================================
Predictions:  ['84203 74089']
Answer:  ['79146']
Prediction: 84203, 74089
Reference: 79146
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   2%|▏         | 67/3071 [12:09<3:02:52,  3.65s/it]
============================================================
Query ID: 68 | Type: Numerical Reasoning | SubType: Comparison
============================================================
Predictions:  ['17071 13271']
Answer:  ['3800']
Prediction: 17071, 13271
Reference: 3800
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Checkpoint saved: 60 queries processed
Processing text modality:   2%|▏         | 68/3071 [12:12<2:45:27,  3.31s/it]
============================================================
Query ID: 69 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['7414']
Answer:  ['7414']
Prediction: 7414
Reference: 7414
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   2%|▏         | 69/3071 [12:14<2:28:57,  2.98s/it]
============================================================
Query ID: 70 | Type: Numerical Reasoning | SubType: Ranking
============================================================
Predictions:  ['mexican puerto rican cuban']
Answer:  ['mexican puerto rican cuban']
Prediction: Mexican, Puerto Rican, Cuban
Reference: Mexican, Puerto Rican, Cuban
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 100.0}
Processing text modality:   2%|▏         | 70/3071 [12:16<2:17:52,  2.76s/it]
============================================================
Query ID: 71 | Type: Visualization | SubType: BarChart Generation
============================================================
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel("/mnt/data1/users/4xin/RealHiTBench/tables/employment-table14.xlsx")
data = df[df['Category'].isin(['Men', 'Women'])]
data = data[['Category', '2022', '2023']]
data.set_index('Category', inplace=True)
data.plot(kind='bar', stacked=False)
plt.xlabel('Gender')
plt.ylabel('Total Employment')
plt.title('Total Employment for Men and Women among Hispanic or Latino Workers (2022-2023)')
plt.xticks(rotation=0)
plt.legend(['2022', '2023'])
plt.tight_layout()
plt.show()

Python Error: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.
Prediction: import pandas as pd 
 import matplotlib.pyplot as plt 
 df = pd.read_excel("table.xlsx")
 data = df[df['Category'].isin(['Men', 'Women'])]
 data = data[['Category', '2022', '2023']]
 data.set_index('C...
Reference: [16654.0, 17071.0, 12646.0, 13271.0]

Metrics: {'ECR': False, 'Pass': 'None'}
Processing text modality:   2%|▏         | 71/3071 [12:23<3:18:33,  3.97s/it]
============================================================
Query ID: 72 | Type: Visualization | SubType: LineChart Generation
============================================================
invalid visualization_answer: import pandas as pd 
 import matplotlib.pyplot as plt 
 df = pd.read_excel("/mnt/data1/users/4xin/RealHiTBench/tables/employment-table14.xlsx")
 data = df[df['Category'].isin(['Management, professional, and related occupations'])]
 data = data[['Category', 'Men 2022', 'Men 2023', 'Women 2022', 'Women 2023']]
 data = data.set_index('Category')
 data.columns.name = 'Year'
 data = data.reset_index()
 data = data.melt(id_vars=['Category'], var_name='Year', value_name='Employment')
 data['Year'] = data['Year'].str.replace('Men ', '').str.replace('Women ', '').str.replace('2022', '2022').str.replace('2023', '2023')
 data['Year'] = pd.to_numeric(data['Year'])
 data = data.sort_values(['Category', 'Year'])
 data = data.pivot(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.loc[[2022, 2023]]
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='Category', values='Employment')
 data = data.reset_index()
 data = data.set_index('Year')
 data = data.reset_index()
 data = data.melt(id_vars=['Year'], var_name='Category', value_name='Employment')
 data = data.set_index(['Year', 'Category'])
 data = data.reset_index()
 data = data.pivot_table(index='Year', columns='

Code: 

Python Error: expected an indented block after 'if' statement on line 2 (<string>, line 3)
Prediction: import pandas as pd 
 import matplotlib.pyplot as plt 
 df = pd.read_excel("table.xlsx")
 data = df[df['Category'].isin(['Management, professional, and related occupations'])]
 data = data[['Category'...
Reference: [[4027.0, 4245.0], [773.0, 874.0]]

Metrics: {'ECR': False, 'Pass': 'None'}
Processing text modality:   2%|▏         | 72/3071 [14:57<40:56:36, 49.15s/it]
============================================================
Query ID: 73 | Type: Fact Checking | SubType: Multi-hop Fact Checking
============================================================
Predictions:  ['1358']
Answer:  ['2218']
Prediction: 1358
Reference: 2218
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   2%|▏         | 73/3071 [15:03<30:04:40, 36.12s/it]
============================================================
Query ID: 74 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['wholesale and retail trade']
Answer:  ['leisure and hospitality']
Prediction: Wholesale and retail trade
Reference: Leisure and hospitality
Metrics: {'F1': 28.57, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(28.57), 'SacreBLEU': 15.97}
Processing text modality:   2%|▏         | 74/3071 [15:09<22:27:33, 26.98s/it]
============================================================
Query ID: 75 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['no']
Answer:  ['yes']
Prediction: No
Reference: Yes
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   2%|▏         | 75/3071 [15:14<17:05:39, 20.54s/it]
============================================================
Query ID: 76 | Type: Data Analysis | SubType: Summary Analysis
============================================================
Error processing query 76: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    eval_prompt = Eval_Prompt[query['SubQType']].format_map({
KeyError: 'User_Answer'
Processing text modality:   2%|▏         | 76/3071 [15:27<15:08:40, 18.20s/it]
============================================================
Query ID: 77 | Type: Data Analysis | SubType: Exploratory Analysis
============================================================
Predictions:  ['strong positive correlation 10']
Answer:  ['strong positive correlation 10']
Prediction: Strong positive correlation, 0.98
Reference: Strong positive correlation, 0.99
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 100.0}
Processing text modality:   3%|▎         | 77/3071 [15:33<12:04:39, 14.52s/it]
============================================================
Query ID: 78 | Type: Numerical Reasoning | SubType: Comparison
============================================================
Predictions:  ['75 10']
Answer:  ['65']
Prediction: 75, 10
Reference: 65
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   3%|▎         | 78/3071 [15:35<9:00:58, 10.84s/it] 
============================================================
Query ID: 79 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['3520104236711111']
Answer:  ['35']
Prediction: 35,20,10,4,2,3,6,7,1,1,1,1,1
Reference: 35
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Checkpoint saved: 70 queries processed
Processing text modality:   3%|▎         | 79/3071 [15:38<7:04:14,  8.51s/it]
============================================================
Query ID: 80 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['128154 21538']
Answer:  ['128154 21538']
Prediction: 128154, 21538
Reference: 128154, 21538
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   3%|▎         | 80/3071 [15:41<5:34:24,  6.71s/it]
============================================================
Query ID: 81 | Type: Visualization | SubType: ScatterChart Generation
============================================================
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel("/mnt/data1/users/4xin/RealHiTBench/tables/employment-table16.xlsx")
# Extract relevant data for non-agricultural industries: wage and salary workers and self-employed workers
age_groups = df[df['Age and sex'].str.contains('Total, 16 years and over|16 to 19 years|16 to 17 years|18 to 19 years|20 to 24 years|25 to 34 years|35 to 44 years|45 to 54 years|55 to 64 years|65 years and over|Men, 16 years and over|Women, 16 years and over')].copy()
# Filter for non-agricultural industries
non_agricultural = age_groups[['Age and sex', 'Wage and salary workers(1)', 'Self-employed workers, unincorporated']]
# Create scatter plot
plt.figure(figsize=(10, 6))
plt.scatter(non_agricultural['Wage and salary workers(1)'], non_agricultural['Self-employed workers, unincorporated'], alpha=0.7)
plt.title('Relationship between Wage and Salary Workers and Self-Employed Workers in Non-Agricultural Industries')
plt.xlabel('Wage and Salary Workers')
plt.ylabel('Self-Employed Workers')
plt.grid(True)
plt.show()

Python Error: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.
Prediction: import pandas as pd 
 import matplotlib.pyplot as plt 
 df = pd.read_excel("table.xlsx")
 # Extract relevant data for non-agricultural industries: wage and salary workers and self-employed workers
 ag...
Reference: [[128154.0, 5197.0, 2012.0, 3185.0, 13053.0, 29697.0, 27781.0, 24341.0, 20263.0, 7822.0, 69190.0, 2562.0, 936.0, 1626.0, 6670.0, 16054.0, 15279.0, 13339.0, 11045.0, 4241.0, 58964.0, 2634.0, 1076.0, 15...
Metrics: {'ECR': False, 'Pass': 'None'}
Processing text modality:   3%|▎         | 81/3071 [15:53<6:59:22,  8.42s/it]
============================================================
Query ID: 82 | Type: Visualization | SubType: PieChart Generation
============================================================
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel("/mnt/data1/users/4xin/RealHiTBench/tables/employment-table16.xlsx")
data = df.loc[df['Age and sex'] == 'Total, 16 years and over', ['Age and sex', 'Agriculture and related industries', 'Nonagricultural industries']]
# Extract the relevant data for private industry workers, government workers, and unpaid family workers
private_industry = data.iloc[0]['Nonagricultural industries'] - data.iloc[0]['Agriculture and related industries']
government_workers = data.iloc[0]['Nonagricultural industries'] - private_industry
unpaid_family_workers = data.iloc[0]['Agriculture and related industries']
# Create a pie chart
labels = ['Private Industry Workers', 'Government Workers', 'Unpaid Family Workers']
sizes = [private_industry, government_workers, unpaid_family_workers]
colors = ['lightblue', 'lightgreen', 'lightcoral']
plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)
plt.title('Proportion of Private Industry Workers, Government Workers, and Unpaid Family Workers for Individuals Aged 16 Years and Older')
plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
plt.show()

Python Error: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.
Prediction: import pandas as pd 
 import matplotlib.pyplot as plt 
 df = pd.read_excel("table.xlsx")
 data = df.loc[df['Age and sex'] == 'Total, 16 years and over', ['Age and sex', 'Agriculture and related indust...
Reference: [0.68, 0.31, 0.01]

Metrics: {'ECR': False, 'Pass': 'None'}
Processing text modality:   3%|▎         | 82/3071 [16:05<7:50:14,  9.44s/it]
============================================================
Query ID: 83 | Type: Fact Checking | SubType: Multi-hop Fact Checking
============================================================
Predictions:  ['590 11']
Answer:  ['590']
Prediction: 590, 11
Reference: 590
Metrics: {'F1': 66.67, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 0.0}
Processing text modality:   3%|▎         | 83/3071 [16:09<6:24:25,  7.72s/it]
============================================================
Query ID: 84 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['education and health services']
Answer:  ['education and health services']
Prediction: Education and health services
Reference: Education and health services
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 100.0}
Processing text modality:   3%|▎         | 84/3071 [16:12<5:21:55,  6.47s/it]
============================================================
Query ID: 85 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['00 00']
Answer:  ['01']
Prediction: 0.00, 0.00
Reference: 0.07%
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   3%|▎         | 85/3071 [16:16<4:42:20,  5.67s/it]
============================================================
Query ID: 86 | Type: Data Analysis | SubType: Exploratory Analysis
============================================================
Predictions:  ['strong positive correlation 10']
Answer:  ['strong positive correlation 10']
Prediction: Strong positive correlation, 0.99
Reference: Strong positive correlation, 1.00.
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 100.0}
Processing text modality:   3%|▎         | 86/3071 [16:20<4:14:06,  5.11s/it]
============================================================
Query ID: 87 | Type: Data Analysis | SubType: Summary Analysis
============================================================
Error processing query 87: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    eval_prompt = Eval_Prompt[query['SubQType']].format_map({
KeyError: 'User_Answer'
Processing text modality:   3%|▎         | 87/3071 [16:29<5:19:37,  6.43s/it]
============================================================
Query ID: 88 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['161037']
Answer:  ['145345']
Prediction: 161037
Reference: 145345
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   3%|▎         | 88/3071 [16:44<7:26:39,  8.98s/it]
============================================================
Query ID: 89 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['child day care services']
Answer:  ['child day care services']
Prediction: Child day care services
Reference: Child day care services
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 100.0}
Processing text modality:   3%|▎         | 89/3071 [16:59<8:52:32, 10.72s/it]
============================================================
Query ID: 90 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['crop production forestry except logging']
Answer:  ['crop production']
Prediction: Crop production, Forestry, except logging
Reference: Crop production
Metrics: {'F1': 57.14, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(57.14), 'SacreBLEU': 21.36}
Checkpoint saved: 80 queries processed
Processing text modality:   3%|▎         | 90/3071 [17:14<9:56:33, 12.01s/it]
============================================================
Query ID: 91 | Type: Visualization | SubType: LineChart Generation
============================================================
Code: import pandas as pd
import matplotlib.pyplot as plt

# Load the data from the HTML table
df = pd.read_html("/mnt/data1/users/4xin/RealHiTBench/tables/employment-table19.xlsx", header=0)[0]

# Extract the industry names and total employed data
industries = df['Industry'].dropna().tolist()
total_employed = df['Total<br />employed'].dropna().astype(float).tolist()

# Create a line chart
plt.figure(figsize=(14, 7))
plt.plot(industries, total_employed, marker='o', linestyle='-', color='blue', label='Total Employed')
plt.title('Total Number of Employed Individuals Across Different Industries')
plt.xlabel('Industry')
plt.ylabel('Total Employed')
plt.xticks(rotation=90)  # Rotate x-axis labels for better readability
plt.grid(True)
plt.legend()
plt.tight_layout()  # Adjust layout to prevent clipping of labels
plt.show()

Python Error: Missing optional dependency 'html5lib'.  Use pip or conda to install html5lib.
Prediction: import pandas as pd 
 import matplotlib.pyplot as plt 

# Load the data from the HTML table
df = pd.read_html("table.xlsx", header=0)[0]

# Extract the industry names and total employed data
industrie...
Reference: [[1279.0, 10759.0, 1236.0, 617.0, 245.0, 1615.0, 6344.0, 617.0, 44.0, 1322.0, 33.0, 148.0, 2264.0, 734.0, 961.0, 105.0, 55.0, 139.0, 705.0, 434.0, 91.0, 1883.0, 3529.0, 1314.0, 180.0, 488.0, 1353.0, 2...
Metrics: {'ECR': False, 'Pass': 'None'}
Processing text modality:   3%|▎         | 91/3071 [17:40<13:19:55, 16.11s/it]
============================================================
Query ID: 92 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['2854 590']
Answer:  ['2264 590']
Prediction: 2854, 590
Reference: 2264, 590
Metrics: {'F1': 50.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(50.0), 'SacreBLEU': 0.0}
Processing text modality:   3%|▎         | 92/3071 [17:49<11:29:23, 13.88s/it]
============================================================
Query ID: 93 | Type: Numerical Reasoning | SubType: Ranking
============================================================
Predictions:  ['construction manufacturing agriculture']
Answer:  ['manufacturing construction agriculture']
Prediction: Construction, Manufacturing, Agriculture
Reference: Manufacturing, Construction, Agriculture
Metrics: {'F1': 100.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 0.0}
Processing text modality:   3%|▎         | 93/3071 [17:57<10:08:23, 12.26s/it]
============================================================
Query ID: 94 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['220 220']
Answer:  ['265']
Prediction: 220, 220
Reference: 265
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   3%|▎         | 94/3071 [18:06<9:14:35, 11.18s/it] 
============================================================
Query ID: 95 | Type: Data Analysis | SubType: Summary Analysis
============================================================
Error processing query 95: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    eval_prompt = Eval_Prompt[query['SubQType']].format_map({
KeyError: 'User_Answer'
Processing text modality:   3%|▎         | 95/3071 [18:19<9:45:41, 11.81s/it]
============================================================
Query ID: 96 | Type: Numerical Reasoning | SubType: Multi-hop Numerical Reasoning
============================================================
Predictions:  ['10000 wholesale and retail trade']
Answer:  ['15825 leisure and hospitality']
Prediction: 1000.00, Wholesale and retail trade
Reference: 1582.47, Leisure and hospitality
Metrics: {'F1': 22.22, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(22.22), 'SacreBLEU': 10.68}
Processing text modality:   3%|▎         | 96/3071 [18:28<9:01:31, 10.92s/it]
============================================================
Query ID: 97 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['24492 24062']
Answer:  ['24492 24062']
Prediction: 24492, 24062
Reference: 24492, 24062
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   3%|▎         | 97/3071 [18:29<6:41:13,  8.09s/it]
============================================================
Query ID: 98 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['377102']
Answer:  ['377102']
Prediction: 37710.2
Reference: 37710.20
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   3%|▎         | 98/3071 [18:31<5:00:27,  6.06s/it]
============================================================
Query ID: 99 | Type: Numerical Reasoning | SubType: Counting
============================================================
Predictions:  ['economic reasons noneconomic reasons']
Answer:  ['4']
Prediction: Economic reasons, Noneconomic reasons
Reference: 4
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   3%|▎         | 99/3071 [18:32<3:48:54,  4.62s/it]
============================================================
Query ID: 100 | Type: Data Analysis | SubType: Summary Analysis
============================================================
Error processing query 100: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    eval_prompt = Eval_Prompt[query['SubQType']].format_map({
KeyError: 'User_Answer'
Processing text modality:   3%|▎         | 100/3071 [18:40<4:40:21,  5.66s/it]
============================================================
Query ID: 101 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['48828']
Answer:  ['48828']
Prediction: 4882.8
Reference: 4882.80
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   3%|▎         | 101/3071 [18:41<3:35:22,  4.35s/it]
============================================================
Query ID: 102 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['3390']
Answer:  ['33695']
Prediction: 3390
Reference: 33695
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Checkpoint saved: 90 queries processed
Processing text modality:   3%|▎         | 102/3071 [18:42<2:46:35,  3.37s/it]
============================================================
Query ID: 103 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['134']
Answer:  ['134']
Prediction: 134
Reference: 134
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   3%|▎         | 103/3071 [18:43<2:11:28,  2.66s/it]
============================================================
Query ID: 104 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['35 hours and over']
Answer:  ['35 hours and over']
Prediction: 35 hours and over
Reference: 35 hours and over
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 100.0}
Processing text modality:   3%|▎         | 104/3071 [18:44<1:47:57,  2.18s/it]
============================================================
Query ID: 105 | Type: Visualization | SubType: ScatterChart Generation
============================================================
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/mnt/data1/users/4xin/RealHiTBench/tables/employment-table21.xlsx')
agriculture = df[df['Hours of work'].str.contains('Agriculture')]['Total, persons at work'].values
non_agricultural = df[df['Hours of work'].str.contains('Nonagricultural')]['Total, persons at work'].values
plt.scatter(agriculture, non_agricultural)
plt.xlabel('Agriculture and related industries')
plt.ylabel('Nonagricultural industries')
plt.title('Relationship between persons working in agriculture and non-agricultural industries')
plt.show()

Python Error: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.
Prediction: import pandas as pd 
 import matplotlib.pyplot as plt 
 df = pd.read_excel('table.xlsx')
 agriculture = df[df['Hours of work'].str.contains('Agriculture')]['Total, persons at work'].values
 non_agricu...
Reference: [[3.5, 11.0, 6.9, 77.5, 6.1, 49.3, 22.1, 7.9, 8.7, 5.6]]

Metrics: {'ECR': False, 'Pass': 'None'}
Processing text modality:   3%|▎         | 105/3071 [18:49<2:30:25,  3.04s/it]
============================================================
Query ID: 106 | Type: Numerical Reasoning | SubType: Comparison
============================================================
Predictions:  ['14880 10054']
Answer:  ['4826']
Prediction: 14880, 10054
Reference: 4826
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   3%|▎         | 106/3071 [18:51<2:09:46,  2.63s/it]
============================================================
Query ID: 107 | Type: Numerical Reasoning | SubType: Counting
============================================================
Predictions:  ['total nonagricultural industries wage and salary workers1 education and health services']
Answer:  ['7']
Prediction: Total, nonagricultural industries, Wage and salary workers(1), Education and health services
Reference: 7
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   3%|▎         | 107/3071 [18:53<1:58:29,  2.40s/it]
============================================================
Query ID: 108 | Type: Numerical Reasoning | SubType: Ranking
============================================================
Predictions:  ['wholesale and retail trade education and health services leisure and hospitality']
Answer:  ['mining quarrying and oil and gas extraction unpaid family workers information']
Prediction: Wholesale and retail trade, Education and health services, Leisure and hospitality
Reference: Mining, quarrying, and oil and gas extraction, Unpaid family workers, Information
Metrics: {'F1': 18.18, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(18.18), 'SacreBLEU': 4.46}
Processing text modality:   4%|▎         | 108/3071 [18:55<1:47:27,  2.18s/it]
============================================================
Query ID: 109 | Type: Visualization | SubType: PieChart Generation
============================================================
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel("/mnt/data1/users/4xin/RealHiTBench/tables/employment-table23.xlsx")
industry_data = df[df['Industry and class of worker'].isin(['Manufacturing', 'Construction'])]
values = industry_data.iloc[:, 1].values
labels = industry_data['Industry and class of worker'].values
plt.pie(values, labels=labels, autopct='%1.1f%%')
plt.title('Proportion in Manufacturing and Construction Industries in 2023')
plt.show()

Python Error: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.
Prediction: import pandas as pd 
 import matplotlib.pyplot as plt 
 df = pd.read_excel("table.xlsx")
 industry_data = df[df['Industry and class of worker'].isin(['Manufacturing', 'Construction'])]
 values = indus...
Reference: [0.4, 0.6]

Metrics: {'ECR': False, 'Pass': 'None'}
Processing text modality:   4%|▎         | 109/3071 [18:59<2:25:14,  2.94s/it]
============================================================
Query ID: 110 | Type: Visualization | SubType: LineChart Generation
============================================================
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/mnt/data1/users/4xin/RealHiTBench/tables/employment-table23.xlsx')
industry = 'Manufacturing'
subset = df[df['Industry and class of worker'] == industry]
full_time = subset.iloc[0]['Average hours - Persons who usually work full time']
part_time = subset.iloc[0]['Average hours - Persons who usually work part time']
categories = ['Full Time', 'Part Time']
values = [full_time, part_time]
plt.plot(categories, values, marker='o')
plt.title('Average Hours Worked by Workers in Manufacturing Industry')
plt.xlabel('Work Category')
plt.ylabel('Average Hours')
plt.grid(True)
plt.show()

Python Error: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.
Prediction: import pandas as pd 
 import matplotlib.pyplot as plt 
 df = pd.read_excel('table.xlsx')
 industry = 'Manufacturing'
 subset = df[df['Industry and class of worker'] == industry]
 full_time = subset.il...
Reference: [[791, 577]]

Metrics: {'ECR': False, 'Pass': 'None'}
Processing text modality:   4%|▎         | 110/3071 [19:05<3:08:59,  3.83s/it]
============================================================
Query ID: 111 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['married spouse present1 418']
Answer:  ['men 16 years and over married spouse present1 433']
Prediction: Married, spouse present(1), 41.8
Reference: Men, 16 years and over, Married, spouse present(1), 43.30
Metrics: {'F1': 46.15, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(46.15), 'SacreBLEU': 17.04}
Processing text modality:   4%|▎         | 111/3071 [19:08<2:55:00,  3.55s/it]
============================================================
Query ID: 112 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['34282 118705']
Answer:  ['34282 118705']
Prediction: 34282, 118705
Reference: 34282, 118705
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Checkpoint saved: 100 queries processed
Processing text modality:   4%|▎         | 112/3071 [19:11<2:46:20,  3.37s/it]
============================================================
Query ID: 113 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['406 376']
Answer:  ['406 376']
Prediction: 40.6, 37.6
Reference: 40.60, 37.60
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   4%|▎         | 113/3071 [19:14<2:38:33,  3.22s/it]
============================================================
Query ID: 114 | Type: Data Analysis | SubType: Summary Analysis
============================================================
Error processing query 114: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    eval_prompt = Eval_Prompt[query['SubQType']].format_map({
KeyError: 'User_Answer'
Processing text modality:   4%|▎         | 114/3071 [19:24<4:22:12,  5.32s/it]
============================================================
Query ID: 115 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['152987']
Answer:  ['152987']
Prediction: 152987
Reference: 152987
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   4%|▎         | 115/3071 [19:27<3:43:26,  4.54s/it]
============================================================
Query ID: 116 | Type: Numerical Reasoning | SubType: Comparison
============================================================
Predictions:  ['25193 37780']
Answer:  ['12587']
Prediction: 25193, 37780
Reference: 12587
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   4%|▍         | 116/3071 [19:29<3:11:37,  3.89s/it]
============================================================
Query ID: 117 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['30091']
Answer:  ['30091']
Prediction: 30091
Reference: 30091
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   4%|▍         | 117/3071 [19:31<2:45:39,  3.36s/it]
============================================================
Query ID: 118 | Type: Numerical Reasoning | SubType: Counting
============================================================
Predictions:  ['management business and financial operations occupations service occupations sales and office occupations sales and related occupations office and administrative support occupations installation maintenance and repair occupations production occupations transportation and material moving occupations']
Answer:  ['6']
Prediction: Management, business, and financial operations occupations, Service occupations, Sales and office occupations, Sales and related occupations, Office and administrative support occupations, Installatio...
Reference: 6
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   4%|▍         | 118/3071 [19:35<2:47:26,  3.40s/it]
============================================================
Query ID: 119 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['41 35']
Answer:  ['41 35']
Prediction: 4.1, 3.5
Reference: 4.10, 3.50
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   4%|▍         | 119/3071 [19:37<2:33:39,  3.12s/it]
============================================================
Query ID: 120 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['3218 2778']
Answer:  ['men']
Prediction: 3218, 2778
Reference: Men
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   4%|▍         | 120/3071 [19:40<2:25:08,  2.95s/it]
============================================================
Query ID: 121 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['135']
Answer:  ['135']
Prediction: 135
Reference: 135
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   4%|▍         | 121/3071 [19:42<2:15:23,  2.75s/it]
============================================================
Query ID: 122 | Type: Data Analysis | SubType: Predictive Analysis
============================================================
Predictions:  ['increase 65']
Answer:  ['increasing trend']
Prediction: Increase, 6.5%
Reference: Increasing trend
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   4%|▍         | 122/3071 [19:45<2:10:21,  2.65s/it]
============================================================
Query ID: 123 | Type: Data Analysis | SubType: Exploratory Analysis
============================================================
Predictions:  ['strong positive correlation 10']
Answer:  ['strong positive correlation 10']
Prediction: Strong positive correlation, 0.98
Reference: Strong positive correlation, 1.00
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 100.0}
Checkpoint saved: 110 queries processed
Processing text modality:   4%|▍         | 123/3071 [19:47<2:08:20,  2.61s/it]
============================================================
Query ID: 124 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['418 472']
Answer:  ['418 472']
Prediction: 418, 472
Reference: 418, 472
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   4%|▍         | 124/3071 [19:50<2:06:16,  2.57s/it]
============================================================
Query ID: 125 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['31']
Answer:  ['31']
Prediction: 31
Reference: 31
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   4%|▍         | 125/3071 [19:51<1:54:13,  2.33s/it]
============================================================
Query ID: 126 | Type: Numerical Reasoning | SubType: Comparison
============================================================
Predictions:  ['25 24']
Answer:  ['men 01']
Prediction: 2.5, 2.4
Reference: Men, 0.10%
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   4%|▍         | 126/3071 [19:53<1:48:53,  2.22s/it]
============================================================
Query ID: 127 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['20 20']
Answer:  ['20']
Prediction: 20, 20
Reference: 20
Metrics: {'F1': 66.67, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 0.0}
Processing text modality:   4%|▍         | 127/3071 [19:55<1:44:04,  2.12s/it]
============================================================
Query ID: 128 | Type: Visualization | SubType: ScatterChart Generation
============================================================
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel("/mnt/data1/users/4xin/RealHiTBench/tables/employment-table27.xlsx")
men_2023 = df[df['Occupation'] != 'Total, 16 years and over(1)']['Men 2023'].dropna()
women_2023 = df[df['Occupation'] != 'Total, 16 years and over(1)']['Women 2023'].dropna()
plt.scatter(men_2023, women_2023)
plt.xlabel('Unemployment Rate for Men (2023)')
plt.ylabel('Unemployment Rate for Women (2023)')
plt.title('Correlation between Unemployment Rates for Men and Women in 2023')
plt.grid(True)
plt.show()

Python Error: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.
Prediction: import pandas as pd 
 import matplotlib.pyplot as plt 
 df = pd.read_excel("table.xlsx")
 men_2023 = df[df['Occupation'] != 'Total, 16 years and over(1)']['Men 2023'].dropna()
 women_2023 = df[df['Occ...
Reference: [[3.5, 2.0, 2.0, 1.7, 2.4, 2.0, 2.1, 3.1, 1.5, 2.1, 1.4, 2.3, 3.6, 1.4, 4.4, 3.5, 4.0, 5.6, 5.1, 3.6, 3.6, 4.4, 3.1, 6.1, 7.4, 7.1, 2.5, 5.4, 4.6, 6.2]]

Metrics: {'ECR': False, 'Pass': 'None'}
Processing text modality:   4%|▍         | 128/3071 [20:03<3:01:56,  3.71s/it]
============================================================
Query ID: 129 | Type: Data Analysis | SubType: Rudimentary Analysis
============================================================
Predictions:  ['142']
Answer:  ['142']
Prediction: 14.17
Reference: 14.17
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   4%|▍         | 129/3071 [20:05<2:38:24,  3.23s/it]
============================================================
Query ID: 130 | Type: Data Analysis | SubType: Summary Analysis
============================================================
Error processing query 130: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    eval_prompt = Eval_Prompt[query['SubQType']].format_map({
KeyError: 'User_Answer'
Processing text modality:   4%|▍         | 130/3071 [20:09<2:57:15,  3.62s/it]
============================================================
Query ID: 131 | Type: Numerical Reasoning | SubType: Ranking
============================================================
Predictions:  ['shelter fuels and utilities household furnishings and operations']
Answer:  ['shelter household furnishings and operations fuels and utilities']
Prediction: Shelter, Fuels and utilities, Household furnishings and operations
Reference: Shelter, Household furnishings and operations, Fuels and utilities
Metrics: {'F1': 100.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(62.5), 'SacreBLEU': 51.7}
Processing text modality:   4%|▍         | 131/3071 [20:12<2:37:40,  3.22s/it]
============================================================
Query ID: 132 | Type: Numerical Reasoning | SubType: Multi-hop Numerical Reasoning
============================================================
Predictions:  ['1861 06']
Answer:  ['1857']
Prediction: 186.148, 0.6
Reference: 185.70
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   4%|▍         | 132/3071 [20:14<2:25:02,  2.96s/it]
============================================================
Query ID: 133 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['142']
Answer:  ['142']
Prediction: 14.166
Reference: 14.166
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   4%|▍         | 133/3071 [20:16<2:12:59,  2.72s/it]
============================================================
Query ID: 134 | Type: Numerical Reasoning | SubType: Comparison
============================================================
Predictions:  ['housing food and beverages']
Answer:  ['housing']
Prediction: Housing, Food and beverages
Reference: Housing
Metrics: {'F1': 40.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(40.0), 'SacreBLEU': 15.97}
Checkpoint saved: 120 queries processed
Processing text modality:   4%|▍         | 134/3071 [20:18<2:03:36,  2.53s/it]
============================================================
Query ID: 135 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['no']
Answer:  ['no']
Prediction: No
Reference: No
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   4%|▍         | 135/3071 [20:21<2:08:12,  2.62s/it]
============================================================
Query ID: 136 | Type: Fact Checking | SubType: Multi-hop Fact Checking
============================================================
Predictions:  ['cereals and bakery products']
Answer:  ['cereals and bakery products']
Prediction: Cereals and bakery products
Reference: Cereals and bakery products
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 100.0}
Processing text modality:   4%|▍         | 136/3071 [20:24<2:14:12,  2.74s/it]
============================================================
Query ID: 137 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['135 1000']
Answer:  ['135']
Prediction: 13.474, 100.000
Reference: 13.47
Metrics: {'F1': 66.67, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 0.0}
Processing text modality:   4%|▍         | 137/3071 [20:27<2:23:56,  2.94s/it]
============================================================
Query ID: 138 | Type: Visualization | SubType: LineChart Generation
============================================================
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/mnt/data1/users/4xin/RealHiTBench/tables/economy-table137.xlsx', sheet_name=0)
data = df[df['Expenditure category'] == 'All items']
x = data['Unadjusted indexes'].iloc[0:3].index.tolist()
y = data['Unadjusted indexes'].iloc[0:3].values.tolist()
plt.plot(x, y, marker='o')
plt.title('Trend in Unadjusted Indexes for All Items')
plt.xlabel('Time')
plt.ylabel('Unadjusted Indexes')
plt.xticks(rotation=45)
plt.grid(True)
plt.tight_layout()
plt.show()

Python Error: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.
Prediction: import pandas as pd 
 import matplotlib.pyplot as plt 
 df = pd.read_excel('table.xlsx', sheet_name=0)
 data = df[df['Expenditure category'] == 'All items']
 x = data['Unadjusted indexes'].iloc[0:3].i...
Reference: [[289.11, 301.84, 303.36]]

Metrics: {'ECR': False, 'Pass': 'None'}
Processing text modality:   4%|▍         | 138/3071 [20:35<3:33:46,  4.37s/it]
============================================================
Query ID: 139 | Type: Visualization | SubType: ScatterChart Generation
============================================================
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel("/mnt/data1/users/4xin/RealHiTBench/tables/economy-table137.xlsx", sheet_name=0)
data = df[df['Expenditure category'].notna()]
x = data['Unadjusted percent change (Apr. 2022-April 2023)'].astype(float)
y = data['Unadjusted percent change (Mar. 2023-April 2023)'].astype(float)
plt.scatter(x, y)
plt.xlabel('April 2022-April 2023')
plt.ylabel('March 2023-April 2023')
plt.title('Relationship between Unadjusted Percent Changes')
plt.grid(True)
plt.show()

Python Error: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.
Prediction: import pandas as pd 
 import matplotlib.pyplot as plt 
 df = pd.read_excel("table.xlsx", sheet_name=0)
 data = df[df['Expenditure category'].notna()]
 x = data['Unadjusted percent change (Apr. 2022-Ap...
Reference: [[1.5, 1.7, 2.0, 1.8, 1.6]]

Metrics: {'ECR': False, 'Pass': 'None'}
Processing text modality:   5%|▍         | 139/3071 [20:44<4:34:58,  5.63s/it]
============================================================
Query ID: 140 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['electricity utility piped gas service']
Answer:  ['electricity']
Prediction: Electricity, Utility (piped) gas service
Reference: Electricity
Metrics: {'F1': 33.33, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(33.33), 'SacreBLEU': 10.68}
Processing text modality:   5%|▍         | 140/3071 [20:47<3:58:09,  4.88s/it]
============================================================
Query ID: 141 | Type: Fact Checking | SubType: Multi-hop Fact Checking
============================================================
Predictions:  ['motor vehicle insurance']
Answer:  ['airline fares']
Prediction: Motor vehicle insurance
Reference: Airline fares
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   5%|▍         | 141/3071 [20:50<3:29:16,  4.29s/it]
============================================================
Query ID: 142 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['energy commodities']
Answer:  ['airline fares']
Prediction: Energy commodities
Reference: Airline fares
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   5%|▍         | 142/3071 [20:53<3:08:12,  3.86s/it]
============================================================
Query ID: 143 | Type: Visualization | SubType: BarChart Generation
============================================================
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/mnt/data1/users/4xin/RealHiTBench/tables/economy-table136.xlsx', sheet_name=0)
filtered_df = df[df['Expenditure category'].str.contains('Food at home', na=False)]
filtered_df = filtered_df[filtered_df['Indent Level'] == 2]
filtered_df = filtered_df[filtered_df['Relative importance Sep. 2024'].notna()]
filtered_df = filtered_df.sort_values('Relative importance Sep. 2024', ascending=False)
plt.bar(filtered_df['Expenditure category'], filtered_df['Relative importance Sep. 2024'])
plt.xlabel('Expenditure category')
plt.ylabel('Relative importance Sep. 2024')
plt.title('Relative importance of different expenditure categories under "Food at home" as of September 2024')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

Python Error: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.
Prediction: import pandas as pd 
 import matplotlib.pyplot as plt 
 df = pd.read_excel('table.xlsx', sheet_name=0)
 filtered_df = df[df['Expenditure category'].str.contains('Food at home', na=False)]
 filtered_df...
Reference: [1.044, 1.741, 0.732, 1.385, 1.016, 2.153]

Metrics: {'ECR': False, 'Pass': 'None'}
Processing text modality:   5%|▍         | 143/3071 [21:02<4:36:10,  5.66s/it]
============================================================
Query ID: 144 | Type: Visualization | SubType: PieChart Generation
============================================================
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/mnt/data1/users/4xin/RealHiTBench/tables/economy-table136.xlsx', sheet_name=0)
food_at_home = df[df['Expenditure category'] == 'Food at home']
sep_2024_importance = food_at_home['Relative<br />importance<br />Sep.<br />2024']
sep_2024_categories = food_at_home['Expenditure category']
plt.figure(figsize=(8, 8))
plt.pie(sep_2024_importance, labels=sep_2024_categories, autopct='%1.1f%%', startangle=140)
plt.title('Proportion of Different Expenditure Categories under "Food at home" as of September 2024')
plt.axis('equal')
plt.show()

Python Error: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.
Prediction: import pandas as pd 
 import matplotlib.pyplot as plt 
 df = pd.read_excel('table.xlsx', sheet_name=0)
 food_at_home = df[df['Expenditure category'] == 'Food at home']
 sep_2024_importance = food_at_h...
Reference: [0.8, 0.11, 0.06, 0.01, 0.01]

Metrics: {'ECR': False, 'Pass': 'None'}
Checkpoint saved: 130 queries processed
Processing text modality:   5%|▍         | 144/3071 [21:12<5:28:51,  6.74s/it]
============================================================
Query ID: 145 | Type: Fact Checking | SubType: Multi-hop Fact Checking
============================================================
Predictions:  ['32 107']
Answer:  ['139']
Prediction: 3.2, 10.7
Reference: 13.90
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   5%|▍         | 145/3071 [21:24<6:43:54,  8.28s/it]
============================================================
Query ID: 146 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['logging workers']
Answer:  ['logging workers']
Prediction: Logging workers
Reference: Logging workers
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   5%|▍         | 146/3071 [21:35<7:29:56,  9.23s/it]
============================================================
Query ID: 147 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['no']
Answer:  ['no']
Prediction: No
Reference: No
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   5%|▍         | 147/3071 [21:46<8:01:22,  9.88s/it]
============================================================
Query ID: 148 | Type: Data Analysis | SubType: Summary Analysis
============================================================
Error processing query 148: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    eval_prompt = Eval_Prompt[query['SubQType']].format_map({
KeyError: 'User_Answer'
Processing text modality:   5%|▍         | 148/3071 [22:08<10:52:29, 13.39s/it]
============================================================
Query ID: 149 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['16400']
Answer:  ['16400']
Prediction: 16,400
Reference: 16400
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   5%|▍         | 149/3071 [22:20<10:27:59, 12.89s/it]
============================================================
Query ID: 150 | Type: Fact Checking | SubType: Multi-hop Fact Checking
============================================================
Predictions:  ['135 368']
Answer:  ['1025']
Prediction: 135, 368
Reference: 1025
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   5%|▍         | 150/3071 [22:32<10:11:49, 12.57s/it]
============================================================
Query ID: 151 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['texas 497']
Answer:  ['california 639']
Prediction: Texas, 497
Reference: California, 639
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   5%|▍         | 151/3071 [22:43<9:57:49, 12.28s/it] 
============================================================
Query ID: 152 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['kentucky illinois']
Answer:  ['kentucky']
Prediction: Kentucky, Illinois
Reference: Kentucky
Metrics: {'F1': 66.67, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 0.0}
Processing text modality:   5%|▍         | 152/3071 [22:55<9:45:24, 12.03s/it]
============================================================
Query ID: 153 | Type: Data Analysis | SubType: Exploratory Analysis
============================================================
Predictions:  ['strong negative correlation 09']
Answer:  ['weak positive correlation 01']
Prediction: Strong negative correlation, -0.87
Reference: Weak positive correlation, 0.05
Metrics: {'F1': 25.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(25.0), 'SacreBLEU': 15.97}
Processing text modality:   5%|▍         | 153/3071 [23:06<9:42:36, 11.98s/it]
============================================================
Query ID: 154 | Type: Data Analysis | SubType: Predictive Analysis
============================================================
Predictions:  ['53330 decreasing trend']
Answer:  ['5557']
Prediction: 5333.00, Decreasing trend
Reference: 5557
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   5%|▌         | 154/3071 [23:18<9:42:32, 11.98s/it]
============================================================
Query ID: 155 | Type: Numerical Reasoning | SubType: Comparison
============================================================
Predictions:  ['1217 558']
Answer:  ['1217']
Prediction: 1217, 558
Reference: 1217
Metrics: {'F1': 66.67, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 0.0}
Checkpoint saved: 140 queries processed
Processing text modality:   5%|▌         | 155/3071 [23:20<7:13:40,  8.92s/it]
============================================================
Query ID: 156 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['336 168']
Answer:  ['304']
Prediction: 336, 168
Reference: 304
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   5%|▌         | 156/3071 [23:22<5:28:56,  6.77s/it]
============================================================
Query ID: 157 | Type: Numerical Reasoning | SubType: Ranking
============================================================
Predictions:  ['falls slips trips exposure to harmful substances or environments fires and explosions']
Answer:  ['falls slips trips exposure to harmful substances or environments fires and explosions']
Prediction: Falls, slips, trips, Exposure to harmful substances or environments, Fires and explosions
Reference: Falls, Slips, Trips, Exposure to harmful substances or environments, Fires and Explosions
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 100.0}
Processing text modality:   5%|▌         | 157/3071 [23:24<4:19:10,  5.34s/it]
============================================================
Query ID: 158 | Type: Visualization | SubType: PieChart Generation
============================================================
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/mnt/data1/users/4xin/RealHiTBench/tables/injuries-table04.xlsx')
categories = ['Transportation incidents', 'Violence and other injuries by persons or animals', 'Falls, slips, trips', 'Exposure to harmful substances or environments']
values = [2066, 849, 738, 865]
plt.pie(values, labels=categories, autopct='%1.1f%%')
plt.title('Proportion of Total Fatalities by Category')
plt.show()

Python Error: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.
Prediction: import pandas as pd 
 import matplotlib.pyplot as plt 
 df = pd.read_excel('table.xlsx')
 categories = ['Transportation incidents', 'Violence and other injuries by persons or animals', 'Falls, slips, ...
Reference: [0.45, 0.18, 0.19, 0.18]

Metrics: {'ECR': False, 'Pass': 'None'}
Processing text modality:   5%|▌         | 158/3071 [23:29<4:17:41,  5.31s/it]
============================================================
Query ID: 159 | Type: Visualization | SubType: BarChart Generation
============================================================
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/mnt/data1/users/4xin/RealHiTBench/tables/injuries-table04.xlsx')
wage_salary = df[df['Worker Characteristics'] == 'Wage and salary'][['Transportation incidents', 'Falls, slips, trips']]
self_employed = df[df['Worker Characteristics'] == 'Self-employed'][['Transportation incidents', 'Falls, slips, trips']]
categories = ['Transportation incidents', 'Falls, slips, trips']
plt.figure(figsize=(10,6))
plt.bar(categories, wage_salary.iloc[0], label='Wage and Salary', alpha=0.7)
plt.bar(categories, self_employed.iloc[0], label='Self-employed', alpha=0.7, bottom=wage_salary.iloc[0])
plt.xlabel('Event Categories')
plt.ylabel('Total Fatalities')
plt.title('Comparison of Fatalities: Wage and Salary vs Self-employed')
plt.legend()
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

Python Error: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.
Prediction: import pandas as pd 
 import matplotlib.pyplot as plt 
 df = pd.read_excel('table.xlsx')
 wage_salary = df[df['Worker Characteristics'] == 'Wage and salary'][['Transportation incidents', 'Falls, slips...
Reference: [1775.0, 291.0, 713.0, 152.0]

Metrics: {'ECR': False, 'Pass': 'None'}
Processing text modality:   5%|▌         | 159/3071 [23:38<5:01:15,  6.21s/it]
============================================================
Query ID: 160 | Type: Fact Checking | SubType: Multi-hop Fact Checking
============================================================
Predictions:  ['couriers and express delivery services private industry 4921']
Answer:  ['couriers and express delivery services private industry 4921']
Prediction: Couriers and express delivery services (Private Industry), 4921
Reference: Couriers and express delivery services (Private Industry), 4921
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 100.0}
Processing text modality:   5%|▌         | 160/3071 [23:40<4:06:17,  5.08s/it]
============================================================
Query ID: 161 | Type: Numerical Reasoning | SubType: Counting
============================================================
Predictions:  ['couriers and express delivery services private industry spectator sports private industry light truck and utility vehicle manufacturing private industry']
Answer:  ['3']
Prediction: Couriers and express delivery services (Private Industry), Spectator sports (Private Industry), Light truck and utility vehicle manufacturing (Private Industry)
Reference: 3
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   5%|▌         | 161/3071 [23:43<3:42:41,  4.59s/it]
============================================================
Query ID: 162 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['06']
Answer:  ['23']
Prediction: 000.60
Reference: 2.34
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   5%|▌         | 162/3071 [23:46<3:07:07,  3.86s/it]
============================================================
Query ID: 163 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['performing arts companies private industry nursing and residential care facilities state government']
Answer:  ['performing arts companies private industry nursing and residential care facilities state government']
Prediction: Performing arts companies (Private Industry), Nursing and residential care facilities (State Government)
Reference: Performing arts companies (Private Industry), Nursing and residential care facilities (State Government)
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 100.0}
Processing text modality:   5%|▌         | 163/3071 [23:48<2:41:44,  3.34s/it]
============================================================
Query ID: 164 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['nursing and residential care facilities state government scheduled passenger air transportation private industry']
Answer:  ['nursing and residential care facilities state government']
Prediction: Nursing and residential care facilities (State Government), Scheduled passenger air transportation (Private Industry)
Reference: Nursing and residential care facilities (State Government)
Metrics: {'F1': 70.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(70.0), 'SacreBLEU': 47.04}
Processing text modality:   5%|▌         | 164/3071 [23:50<2:24:36,  2.98s/it]
============================================================
Query ID: 165 | Type: Visualization | SubType: PieChart Generation
============================================================
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel("/mnt/data1/users/4xin/RealHiTBench/tables/injuries-table07.xlsx")
top_five = df.sort_values(by='Incidence Rate', ascending=False).head(5)
plt.pie(top_five['Incidence Rate'], labels=top_five['Industry'], autopct='%1.1f%%')
plt.title('Proportion of Incidence Rates for Top Five Industries')
plt.show()

Python Error: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.
Prediction: import pandas as pd 
 import matplotlib.pyplot as plt 
 df = pd.read_excel("table.xlsx")
 top_five = df.sort_values(by='Incidence Rate', ascending=False).head(5)
 plt.pie(top_five['Incidence Rate'], l...
Reference: [0.3, 0.24, 0.17, 0.16, 0.15]

Metrics: {'ECR': False, 'Pass': 'None'}
Checkpoint saved: 150 queries processed
Processing text modality:   5%|▌         | 165/3071 [23:54<2:44:10,  3.39s/it]
============================================================
Query ID: 166 | Type: Visualization | SubType: BarChart Generation
============================================================
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/mnt/data1/users/4xin/RealHiTBench/tables/injuries-table07.xlsx')
filtered_df = df[df['Incidence Rate'] > 4.0]
filtered_df = filtered_df.sort_values('Incidence Rate', ascending=False)
plt.bar(filtered_df['Industry'], filtered_df['Incidence Rate'])
plt.xlabel('Industry')
plt.ylabel('Incidence Rate')
plt.title('Incidence Rates of Industries (Above 4.0)')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

Python Error: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.
Prediction: import pandas as pd 
 import matplotlib.pyplot as plt 
 df = pd.read_excel('table.xlsx')
 filtered_df = df[df['Incidence Rate'] > 4.0]
 filtered_df = filtered_df.sort_values('Incidence Rate', ascendin...
Reference: [4.8, 4.5, 4.1, 4.2, 6.8, 8.5]

Metrics: {'ECR': False, 'Pass': 'None'}
Processing text modality:   5%|▌         | 166/3071 [24:00<3:12:33,  3.98s/it]
============================================================
Query ID: 167 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['80 62']
Answer:  ['142']
Prediction: 008.0, 006.2
Reference: 14.20
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   5%|▌         | 167/3071 [24:02<2:49:12,  3.50s/it]
============================================================
Query ID: 168 | Type: Numerical Reasoning | SubType: Ranking
============================================================
Predictions:  ['performing arts companies nursing and residential care facilities spectator sports']
Answer:  ['performing arts companies nursing and residential care facilities spectator sports']
Prediction: Performing arts companies, Nursing and residential care facilities, Spectator sports
Reference: Performing arts companies, Nursing and residential care facilities, Spectator sports
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 100.0}
Processing text modality:   5%|▌         | 168/3071 [24:04<2:32:49,  3.16s/it]
============================================================
Query ID: 169 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['scheduled passenger air transportation private industry']
Answer:  ['nursing care facilities skilled nursing facilities private industry']
Prediction: Scheduled passenger air transportation (Private Industry)
Reference: Nursing care facilities (skilled nursing facilities) (Private Industry)
Metrics: {'F1': 28.57, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(28.57), 'SacreBLEU': 11.63}
Processing text modality:   6%|▌         | 169/3071 [24:06<2:18:45,  2.87s/it]
============================================================
Query ID: 170 | Type: Data Analysis | SubType: Anomaly Analysis
============================================================
Error processing query 170: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    eval_prompt = Eval_Prompt[query['SubQType']].format_map({
KeyError: 'User_Answer'
Processing text modality:   6%|▌         | 170/3071 [24:17<4:03:11,  5.03s/it]
============================================================
Query ID: 171 | Type: Data Analysis | SubType: Summary Analysis
============================================================
Error processing query 171: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    eval_prompt = Eval_Prompt[query['SubQType']].format_map({
KeyError: 'User_Answer'
Processing text modality:   6%|▌         | 171/3071 [24:25<4:49:54,  6.00s/it]
============================================================
Query ID: 172 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['agriculture forestry fishing and hunting']
Answer:  ['sports teams and clubs naics 711211']
Prediction: Agriculture, forestry, fishing and hunting
Reference: Sports teams and clubs (NAICS 711211)
Metrics: {'F1': 18.18, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(18.18), 'SacreBLEU': 8.75}
Processing text modality:   6%|▌         | 172/3071 [24:31<4:56:54,  6.15s/it]
============================================================
Query ID: 173 | Type: Fact Checking | SubType: Multi-hop Fact Checking
============================================================
Predictions:  ['29']
Answer:  ['30']
Prediction: 2.90
Reference: 3.00
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   6%|▌         | 173/3071 [24:38<5:02:16,  6.26s/it]
============================================================
Query ID: 174 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['no']
Answer:  ['yes']
Prediction: No
Reference: Yes
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   6%|▌         | 174/3071 [24:44<5:01:29,  6.24s/it]
============================================================
Query ID: 175 | Type: Numerical Reasoning | SubType: Comparison
============================================================
Predictions:  ['50 249 250 999']
Answer:  ['50 249']
Prediction: 50 - 249, 250 - 999
Reference: 50 - 249
Metrics: {'F1': 66.67, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 31.95}
Processing text modality:   6%|▌         | 175/3071 [24:51<5:12:16,  6.47s/it]
============================================================
Query ID: 176 | Type: Data Analysis | SubType: Summary Analysis
============================================================
Error processing query 176: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    eval_prompt = Eval_Prompt[query['SubQType']].format_map({
KeyError: 'User_Answer'
Processing text modality:   6%|▌         | 176/3071 [25:02<6:15:47,  7.79s/it]
============================================================
Query ID: 177 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['02']
Answer:  ['04']
Prediction: 0.20
Reference: 0.40%
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   6%|▌         | 177/3071 [25:05<5:11:16,  6.45s/it]
============================================================
Query ID: 178 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['2020 q3']
Answer:  ['2020 q3']
Prediction: 2020 Q3
Reference: 2020 Q3
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Checkpoint saved: 160 queries processed
Processing text modality:   6%|▌         | 178/3071 [25:09<4:27:06,  5.54s/it]
============================================================
Query ID: 179 | Type: Fact Checking | SubType: Multi-hop Fact Checking
============================================================
Predictions:  ['07 01']
Answer:  ['15']
Prediction: 0.70, 0.10
Reference: 1.50%
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   6%|▌         | 179/3071 [25:12<3:58:27,  4.95s/it]
============================================================
Query ID: 180 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['manufacturing services']
Answer:  ['whole economy']
Prediction: Manufacturing, Services
Reference: Whole economy
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   6%|▌         | 180/3071 [25:15<3:33:49,  4.44s/it]
============================================================
Query ID: 181 | Type: Data Analysis | SubType: Exploratory Analysis
============================================================
Predictions:  ['strong positive correlation 08']
Answer:  ['weak positive correlation']
Prediction: Strong positive correlation, 0.85
Reference: Weak positive correlation
Metrics: {'F1': 57.14, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(57.14), 'SacreBLEU': 31.95}
Processing text modality:   6%|▌         | 181/3071 [25:19<3:20:52,  4.17s/it]
============================================================
Query ID: 182 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['31 28']
Answer:  ['32']
Prediction: -3.1, -2.8
Reference: -3.20%
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   6%|▌         | 182/3071 [25:26<4:05:59,  5.11s/it]
============================================================
Query ID: 183 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['999 1003']
Answer:  ['increase']
Prediction: 99.9, 100.3
Reference: Increase
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   6%|▌         | 183/3071 [25:34<4:38:08,  5.78s/it]
============================================================
Query ID: 184 | Type: Fact Checking | SubType: Multi-hop Fact Checking
============================================================
Predictions:  ['976 976']
Answer:  ['977']
Prediction: 97.60, 97.60
Reference: 97.73
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   6%|▌         | 184/3071 [25:41<5:01:11,  6.26s/it]
============================================================
Query ID: 185 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['q3']
Answer:  ['q3']
Prediction: Q3
Reference: Q3
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   6%|▌         | 185/3071 [25:48<5:09:44,  6.44s/it]
============================================================
Query ID: 186 | Type: Data Analysis | SubType: Exploratory Analysis
============================================================
Predictions:  ['strong positive correlation 08']
Answer:  ['positive correlation 07']
Prediction: Strong positive correlation, 0.85
Reference: Positive correlation, 0.65
Metrics: {'F1': 57.14, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(57.14), 'SacreBLEU': 31.95}
Processing text modality:   6%|▌         | 186/3071 [25:55<5:21:14,  6.68s/it]
============================================================
Query ID: 187 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['81 80']
Answer:  ['162']
Prediction: 8.14, 8.04
Reference: 16.18
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   6%|▌         | 187/3071 [26:08<6:50:16,  8.54s/it]
============================================================
Query ID: 188 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['03 06']
Answer:  ['07']
Prediction: 0.34, 0.63
Reference: 0.68
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Checkpoint saved: 170 queries processed
Processing text modality:   6%|▌         | 188/3071 [26:21<7:52:43,  9.84s/it]
============================================================
Query ID: 189 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['07 17']
Answer:  ['fulltime employed mothers 03']
Prediction: 0.68, 1.68
Reference: full-time employed mothers, 0.28
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   6%|▌         | 189/3071 [26:34<8:36:18, 10.75s/it]
============================================================
Query ID: 190 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['12 02 06']
Answer:  ['18']
Prediction: 1.21, 0.23, 0.61
Reference: 1.78
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   6%|▌         | 190/3071 [26:47<9:11:38, 11.49s/it]
============================================================
Query ID: 191 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['not employed']
Answer:  ['not employed']
Prediction: Not employed
Reference: Not employed
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   6%|▌         | 191/3071 [26:59<9:24:02, 11.75s/it]
============================================================
Query ID: 192 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['04']
Answer:  ['01']
Prediction: 0.36
Reference: 0.07
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   6%|▋         | 192/3071 [27:01<7:05:55,  8.88s/it]
============================================================
Query ID: 193 | Type: Numerical Reasoning | SubType: Comparison
============================================================
Predictions:  ['85 81']
Answer:  ['employed parttime married mothers']
Prediction: 08.48, 08.11
Reference: Employed part-time married mothers
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   6%|▋         | 193/3071 [27:04<5:33:23,  6.95s/it]
============================================================
Query ID: 194 | Type: Numerical Reasoning | SubType: Multi-hop Numerical Reasoning
============================================================
Predictions:  ['38']
Answer:  ['41']
Prediction: 3.79
Reference: 4.12
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   6%|▋         | 194/3071 [27:06<4:24:32,  5.52s/it]
============================================================
Query ID: 195 | Type: Visualization | SubType: PieChart Generation
============================================================
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/mnt/data1/users/4xin/RealHiTBench/tables/activitytime-table02.xlsx', sheet_name=0)
data = df.loc[df['Activity'] == 'Household activities', ['Activity', 'Employed full time', 'Employed part time', 'Not employed']]
data = data.iloc[:, 1:].sum()
plt.pie(data, labels=data.index, autopct='%1.1f%%')
plt.title('Percentage of Participation in Household Activities for Married Mothers')
plt.show()

Python Error: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.
Prediction: import pandas as pd 
 import matplotlib.pyplot as plt 
 df = pd.read_excel('table.xlsx', sheet_name=0)
 data = df.loc[df['Activity'] == 'Household activities', ['Activity', 'Employed full time', 'Empl...
Reference: [0.33, 0.35, 0.31]

Metrics: {'ECR': False, 'Pass': 'None'}
Processing text modality:   6%|▋         | 195/3071 [27:12<4:25:27,  5.54s/it]
============================================================
Query ID: 196 | Type: Visualization | SubType: LineChart Generation
============================================================
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/mnt/data1/users/4xin/RealHiTBench/tables/activitytime-table02.xlsx')
data = df[df['Activity'] == 'Household activities']
employment_statuses = ['Employed full time', 'Employed part time', 'Not employed']
hours = data.iloc[0, 1:4].values
plt.plot(employment_statuses, hours, marker='o')
plt.title('Average Hours Spent on Household Activities for Married Mothers')
plt.xlabel('Employment Status')
plt.ylabel('Average Hours per Day')
plt.grid(True)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

Python Error: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.
Prediction: import pandas as pd 
 import matplotlib.pyplot as plt 
 df = pd.read_excel('table.xlsx')
 data = df[df['Activity'] == 'Household activities']
 employment_statuses = ['Employed full time', 'Employed pa...
Reference: [[1.86, 2.67, 3.60]]

Metrics: {'ECR': False, 'Pass': 'None'}
Processing text modality:   6%|▋         | 196/3071 [27:18<4:37:55,  5.80s/it]
============================================================
Query ID: 197 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['29 37']
Answer:  ['29 37']
Prediction: 2.93, 3.73
Reference: 2.93, 3.73
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   6%|▋         | 197/3071 [27:37<7:47:56,  9.77s/it]
============================================================
Query ID: 198 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['caring for and helping household members']
Answer:  ['household activities']
Prediction: Caring for and helping household members
Reference: Household activities
Metrics: {'F1': 25.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(25.0), 'SacreBLEU': 8.12}
Checkpoint saved: 180 queries processed
Processing text modality:   6%|▋         | 198/3071 [27:56<9:57:11, 12.47s/it]
============================================================
Query ID: 199 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['caring for and helping household children caring for and helping household children']
Answer:  ['reading towith children']
Prediction: Caring for and helping household children, Caring for and helping household children
Reference: Reading to/with children
Metrics: {'F1': 13.33, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(13.33), 'SacreBLEU': 3.39}
Processing text modality:   6%|▋         | 199/3071 [28:15<11:34:39, 14.51s/it]
============================================================
Query ID: 200 | Type: Data Analysis | SubType: Summary Analysis
============================================================
Error processing query 200: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    eval_prompt = Eval_Prompt[query['SubQType']].format_map({
KeyError: 'User_Answer'
Processing text modality:   7%|▋         | 200/3071 [28:44<15:02:04, 18.85s/it]
============================================================
Query ID: 201 | Type: Data Analysis | SubType: Exploratory Analysis
============================================================
Predictions:  ['strong positive correlation 10']
Answer:  ['strong positive correlation 09']
Prediction: Strong positive correlation, 0.98
Reference: Strong positive correlation, 0.92
Metrics: {'F1': 75.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(75.0), 'SacreBLEU': 59.46}
Processing text modality:   7%|▋         | 201/3071 [29:03<15:04:02, 18.90s/it]
============================================================
Query ID: 202 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['43 32']
Answer:  ['22']
Prediction: 4.28, 3.23
Reference: 2.23
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   7%|▋         | 202/3071 [29:23<15:19:12, 19.22s/it]
============================================================
Query ID: 203 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['caring for and helping household members caring for and helping household children physical care educationrelated activities reading towith children playingdoing hobbies with children']
Answer:  ['watching television']
Prediction: Caring for and helping household members, Caring for and helping household children, Physical care, Education-related activities, Reading to/with children, Playing/doing hobbies with children
Reference: Watching television
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   7%|▋         | 203/3071 [29:45<15:51:00, 19.90s/it]
============================================================
Query ID: 204 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['lawn and garden care']
Answer:  ['reading towith children']
Prediction: Lawn and garden care
Reference: Reading to/with children
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   7%|▋         | 204/3071 [30:04<15:43:52, 19.75s/it]
============================================================
Query ID: 205 | Type: Data Analysis | SubType: Anomaly Analysis
============================================================
Error processing query 205: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    eval_prompt = Eval_Prompt[query['SubQType']].format_map({
KeyError: 'User_Answer'
Processing text modality:   7%|▋         | 205/3071 [30:24<15:46:05, 19.81s/it]
============================================================
Query ID: 206 | Type: Data Analysis | SubType: Summary Analysis
============================================================
Error processing query 206: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    eval_prompt = Eval_Prompt[query['SubQType']].format_map({
KeyError: 'User_Answer'
Processing text modality:   7%|▋         | 206/3071 [30:48<16:49:00, 21.13s/it]
============================================================
Query ID: 207 | Type: Numerical Reasoning | SubType: Comparison
============================================================
Predictions:  ['05 05']
Answer:  ['05']
Prediction: 0.50, 0.49
Reference: 0.50
Metrics: {'F1': 66.67, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 0.0}
Processing text modality:   7%|▋         | 207/3071 [31:06<16:02:56, 20.17s/it]
============================================================
Query ID: 208 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['06 06']
Answer:  ['06']
Prediction: 0.59, 0.61
Reference: 0.59
Metrics: {'F1': 66.67, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 0.0}
Processing text modality:   7%|▋         | 208/3071 [31:24<15:30:43, 19.51s/it]
============================================================
Query ID: 209 | Type: Numerical Reasoning | SubType: Counting
============================================================
Predictions:  ['both spouses work full time mother employed part time and father employed full time mother not employed and father employed full time']
Answer:  ['3']
Prediction: Both spouses work full time, Mother employed part time and father employed full time, Mother not employed and father employed full time
Reference: 3
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   7%|▋         | 209/3071 [31:43<15:19:40, 19.28s/it]
============================================================
Query ID: 210 | Type: Visualization | SubType: BarChart Generation
============================================================
invalid visualization_answer: import pandas as pd 
 import matplotlib.pyplot as plt 

# Load the data from the HTML table
df = pd.read_html("/mnt/data1/users/4xin/RealHiTBench/tables/activitytime-table04.xlsx", header=0)[0]

# Filter the data for household activities
household_activities = df[df['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]

# Create a bar chart
fig, ax = plt.subplots(figsize=(12, 8))

# Define the categories for the x-axis
categories = ['Both spouses work full time', 'Mother employed part time and father employed full time', 'Mother not employed and father employed full time']

# Define the age groups for the y-axis
age_groups = ['Own household children under 18', 'Own household children 6-17, none younger']

# Create a bar chart for each age group
for i, age_group in enumerate(age_groups):
    # Filter the data for the current age group
    age_group_data = household_activities[household_activities['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup', 'Lawn and garden care'])]
    age_group_data = age_group_data[age_group_data['Activity'].isin(['Household activities', 'Housework', 'Food preparation and cleanup',

Code: 

Python Error: expected an indented block after 'if' statement on line 2 (<string>, line 3)
Prediction: import pandas as pd 
 import matplotlib.pyplot as plt 

# Load the data from the HTML table
df = pd.read_html("table.xlsx", header=0)[0]

# Filter the data for household activities
household_activitie...
Reference: [0.62, 1.4, 2.44, 0.59, 1.15, 2.29, 0.64, 1.61, 2.67]

Metrics: {'ECR': False, 'Pass': 'None'}
Processing text modality:   7%|▋         | 210/3071 [36:26<78:18:38, 98.54s/it]
============================================================
Query ID: 211 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['06 16']
Answer:  ['06']
Prediction: 0.64, 1.61
Reference: 0.64
Metrics: {'F1': 66.67, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 0.0}
Checkpoint saved: 190 queries processed
Processing text modality:   7%|▋         | 211/3071 [36:44<59:05:33, 74.38s/it]
============================================================
Query ID: 212 | Type: Fact Checking | SubType: Multi-hop Fact Checking
============================================================
Predictions:  ['serviceproviding industries']
Answer:  ['serviceproviding industries']
Prediction: Service-providing industries
Reference: Service-providing industries
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   7%|▋         | 212/3071 [36:48<42:19:58, 53.30s/it]
============================================================
Query ID: 213 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['no']
Answer:  ['no']
Prediction: No
Reference: No
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   7%|▋         | 213/3071 [36:52<30:33:51, 38.50s/it]
============================================================
Query ID: 214 | Type: Data Analysis | SubType: Anomaly Analysis
============================================================
Error processing query 214: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    eval_prompt = Eval_Prompt[query['SubQType']].format_map({
KeyError: 'User_Answer'
Processing text modality:   7%|▋         | 214/3071 [36:58<22:49:24, 28.76s/it]
============================================================
Query ID: 215 | Type: Data Analysis | SubType: Rudimentary Analysis
============================================================
Predictions:  ['1646 1771']
Answer:  ['higher eci in leisure and hospitality consistent eci in education and health services']
Prediction: 164.6, 177.1
Reference: Higher ECI in Leisure and hospitality, Consistent ECI in Education and health services
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   7%|▋         | 215/3071 [37:03<17:01:41, 21.46s/it]
============================================================
Query ID: 216 | Type: Numerical Reasoning | SubType: Ranking
============================================================
Predictions:  ['pacific']
Answer:  ['pacific']
Prediction: Pacific
Reference: Pacific
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   7%|▋         | 216/3071 [37:04<12:14:55, 15.45s/it]
============================================================
Query ID: 217 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['1664 1674']
Answer:  ['84']
Prediction: 166.4, 167.4
Reference: 8.40
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   7%|▋         | 217/3071 [37:06<9:00:12, 11.36s/it] 
============================================================
Query ID: 218 | Type: Numerical Reasoning | SubType: Counting
============================================================
Predictions:  ['new england middle atlantic south west south central west north central west']
Answer:  ['7']
Prediction: New England, Middle Atlantic, South, West South Central, West North Central, West
Reference: 7
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   7%|▋         | 218/3071 [37:08<6:45:54,  8.54s/it]
============================================================
Query ID: 219 | Type: Data Analysis | SubType: Rudimentary Analysis
============================================================
Predictions:  ['1621']
Answer:  ['1615']
Prediction: 162.10
Reference: 161.52
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   7%|▋         | 219/3071 [37:10<5:07:03,  6.46s/it]
============================================================
Query ID: 220 | Type: Data Analysis | SubType: Summary Analysis
============================================================
Error processing query 220: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    eval_prompt = Eval_Prompt[query['SubQType']].format_map({
KeyError: 'User_Answer'
Processing text modality:   7%|▋         | 220/3071 [37:18<5:33:28,  7.02s/it]
============================================================
Query ID: 221 | Type: Numerical Reasoning | SubType: Counting
============================================================
Predictions:  ['production transportation and material moving service occupations']
Answer:  ['3']
Prediction: Production, transportation, and material moving, Service occupations
Reference: 3
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   7%|▋         | 221/3071 [37:20<4:16:09,  5.39s/it]
============================================================
Query ID: 222 | Type: Numerical Reasoning | SubType: Multi-hop Numerical Reasoning
============================================================
Predictions:  ['1077 01']
Answer:  ['1077 01']
Prediction: 107.7, -0.1
Reference: 107.70, -0.10%
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   7%|▋         | 222/3071 [37:21<3:22:30,  4.26s/it]
============================================================
Query ID: 223 | Type: Data Analysis | SubType: Rudimentary Analysis
============================================================
Predictions:  ['34 34']
Answer:  ['equal']
Prediction: 3.4, 3.4
Reference: equal
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Checkpoint saved: 200 queries processed
Processing text modality:   7%|▋         | 223/3071 [37:23<2:44:02,  3.46s/it]
============================================================
Query ID: 224 | Type: Data Analysis | SubType: Predictive Analysis
============================================================
Predictions:  ['1926 increasing trend']
Answer:  ['2018']
Prediction: 192.6, Increasing trend
Reference: 201.80
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   7%|▋         | 224/3071 [37:24<2:17:06,  2.89s/it]
============================================================
Query ID: 225 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['39 35 33']
Answer:  ['36']
Prediction: 3.90, 3.50, 3.30
Reference: 3.57
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   7%|▋         | 225/3071 [37:26<2:02:06,  2.57s/it]
============================================================
Query ID: 226 | Type: Numerical Reasoning | SubType: Multi-hop Numerical Reasoning
============================================================
Predictions:  ['540 581 570 532 512']
Answer:  ['571']
Prediction: 53.96, 58.14, 56.97, 53.21, 51.16
Reference: 57.10
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   7%|▋         | 226/3071 [37:34<3:21:05,  4.24s/it]
============================================================
Query ID: 227 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['san josesunnyvalesanta clara ca 641']
Answer:  ['san josesunnyvalesanta clara ca 641']
Prediction: San Jose-Sunnyvale-Santa Clara, CA, 64.06
Reference: San Jose-Sunnyvale-Santa Clara, CA, 64.06
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 100.0}
Processing text modality:   7%|▋         | 227/3071 [37:42<4:04:53,  5.17s/it]
============================================================
Query ID: 228 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['338 313']
Answer:  ['23']
Prediction: 33.83, 31.26
Reference: 2.27
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   7%|▋         | 228/3071 [37:49<4:32:56,  5.76s/it]
============================================================
Query ID: 229 | Type: Fact Checking | SubType: Multi-hop Fact Checking
============================================================
Predictions:  ['44']
Answer:  ['50']
Prediction: 4.43
Reference: 4.97
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   7%|▋         | 229/3071 [37:56<4:47:08,  6.06s/it]
============================================================
Query ID: 230 | Type: Numerical Reasoning | SubType: Multi-hop Numerical Reasoning
============================================================
Predictions:  ['530 523 525 549 552']
Answer:  ['553']
Prediction: 52.98, 52.34, 52.46, 54.88, 55.23
Reference: 55.27
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   7%|▋         | 230/3071 [38:04<5:16:22,  6.68s/it]
============================================================
Query ID: 231 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['13 13']
Answer:  ['21']
Prediction: 1.3, 1.3
Reference: 2.10
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   8%|▊         | 231/3071 [38:08<4:40:23,  5.92s/it]
============================================================
Query ID: 232 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['production transportation and material moving']
Answer:  ['service occupations']
Prediction: Production, transportation, and material moving
Reference: Service occupations
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   8%|▊         | 232/3071 [38:12<4:13:40,  5.36s/it]
============================================================
Query ID: 233 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['06 06']
Answer:  ['06']
Prediction: 0.6, 0.6
Reference: 0.60
Metrics: {'F1': 66.67, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 0.0}
Checkpoint saved: 210 queries processed
Processing text modality:   8%|▊         | 233/3071 [38:16<3:56:33,  5.00s/it]
============================================================
Query ID: 234 | Type: Data Analysis | SubType: Summary Analysis
============================================================
Error processing query 234: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    eval_prompt = Eval_Prompt[query['SubQType']].format_map({
KeyError: 'User_Answer'
Processing text modality:   8%|▊         | 234/3071 [38:27<5:21:25,  6.80s/it]
============================================================
Query ID: 235 | Type: Data Analysis | SubType: Predictive Analysis
============================================================
Predictions:  ['1703 increasing trend']
Answer:  ['1714']
Prediction: 170.3, Increasing trend
Reference: 171.4
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   8%|▊         | 235/3071 [38:31<4:43:48,  6.00s/it]
============================================================
Query ID: 236 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['230 548']
Answer:  ['230']
Prediction: 23.01, 54.84
Reference: 23.01
Metrics: {'F1': 66.67, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 0.0}
Processing text modality:   8%|▊         | 236/3071 [38:33<3:44:13,  4.75s/it]
============================================================
Query ID: 237 | Type: Numerical Reasoning | SubType: Ranking
============================================================
Predictions:  ['bostoncambridgenashua manh']
Answer:  ['sacramentorosevilleardenarcade ca']
Prediction: Boston-Cambridge-Nashua, MA-NH
Reference: Sacramento--Roseville--Arden-Arcade, CA
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   8%|▊         | 237/3071 [38:35<3:01:36,  3.84s/it]
============================================================
Query ID: 238 | Type: Numerical Reasoning | SubType: Counting
============================================================
Predictions:  ['atlantasandy springsroswell ga detroitwarrendearborn mi houstonthe woodlandssugar land tx las vegashendersonparadise nv']
Answer:  ['6']
Prediction: Atlanta-Sandy Springs-Roswell, GA, Detroit-Warren-Dearborn, MI, Houston-The Woodlands-Sugar Land, TX, Las Vegas-Henderson-Paradise, NV
Reference: 6
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   8%|▊         | 238/3071 [38:38<2:46:15,  3.52s/it]
============================================================
Query ID: 239 | Type: Numerical Reasoning | SubType: Comparison
============================================================
Predictions:  ['los angeleslong beachanaheim ca philadelphiacamdenwilmington panjdemd']
Answer:  ['los angeleslong beachanaheim ca']
Prediction: Los Angeles-Long Beach-Anaheim, CA, Philadelphia-Camden-Wilmington, PA-NJ-DE-MD
Reference: Los Angeles-Long Beach-Anaheim, CA
Metrics: {'F1': 80.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(80.0), 'SacreBLEU': 50.81}
Processing text modality:   8%|▊         | 239/3071 [38:40<2:27:50,  3.13s/it]
============================================================
Query ID: 240 | Type: Fact Checking | SubType: Multi-hop Fact Checking
============================================================
Predictions:  ['778']
Answer:  ['778']
Prediction: 77.85
Reference: 77.85
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   8%|▊         | 240/3071 [38:41<2:05:36,  2.66s/it]
============================================================
Query ID: 241 | Type: Data Analysis | SubType: Anomaly Analysis
============================================================
Error processing query 241: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    eval_prompt = Eval_Prompt[query['SubQType']].format_map({
KeyError: 'User_Answer'
Processing text modality:   8%|▊         | 241/3071 [38:43<1:52:44,  2.39s/it]
============================================================
Query ID: 242 | Type: Data Analysis | SubType: Predictive Analysis
============================================================
Predictions:  ['increasing trend 1606']
Answer:  ['increasing trend']
Prediction: Increasing trend, 160.6
Reference: Increasing trend
Metrics: {'F1': 80.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(80.0), 'SacreBLEU': 0.0}
Processing text modality:   8%|▊         | 242/3071 [38:45<1:45:28,  2.24s/it]
============================================================
Query ID: 243 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['service occupations']
Answer:  ['service occupations']
Prediction: Service occupations
Reference: Service occupations
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   8%|▊         | 243/3071 [38:47<1:36:53,  2.06s/it]
============================================================
Query ID: 244 | Type: Fact Checking | SubType: Multi-hop Fact Checking
============================================================
Predictions:  ['public administration']
Answer:  ['transportation and material moving']
Prediction: Public administration
Reference: Transportation and material moving
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   8%|▊         | 244/3071 [38:48<1:30:51,  1.93s/it]
============================================================
Query ID: 245 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['1793 1724']
Answer:  ['6']
Prediction: 179.3, 172.4
Reference: 6
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Checkpoint saved: 220 queries processed
Processing text modality:   8%|▊         | 245/3071 [38:52<1:58:53,  2.52s/it]
============================================================
Query ID: 246 | Type: Numerical Reasoning | SubType: Comparison
============================================================
Predictions:  ['1591 1628']
Answer:  ['jun 2024 37']
Prediction: 159.1, 162.8
Reference: Jun. 2024, 3.7
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   8%|▊         | 246/3071 [38:56<2:18:29,  2.94s/it]
============================================================
Query ID: 247 | Type: Visualization | SubType: BarChart Generation
============================================================
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel("/mnt/data1/users/4xin/RealHiTBench/tables/welfare-table09.xlsx")
data = df[df['Occupational group and industry'] == 'All workers']
x = data.iloc[:, 4:7].columns
y = data.iloc[:, 4:7].values[0]
plt.bar(x, y)
plt.xlabel('Period')
plt.ylabel('Percent Change')
plt.title('Percent Changes in Employment Cost Index for All Workers')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

Python Error: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.
Prediction: import pandas as pd 
 import matplotlib.pyplot as plt 
 df = pd.read_excel("table.xlsx")
 data = df[df['Occupational group and industry'] == 'All workers']
 x = data.iloc[:, 4:7].columns
 y = data.ilo...
Reference: [4.3, 3.9, 3.6]

Metrics: {'ECR': False, 'Pass': 'None'}
Processing text modality:   8%|▊         | 247/3071 [39:04<3:23:49,  4.33s/it]
============================================================
Query ID: 248 | Type: Data Analysis | SubType: Rudimentary Analysis
============================================================
Predictions:  ['40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40 40']
Answer:  ['36']
Prediction: 4.00, 4.00, 4.00, 4.00, 4.00, 4.00, 4.00, 4.00, 4.00, 4.00, 4.00, 4.00, 4.00, 4.00, 4.00, 4.00, 4.00, 4.00, 4.00, 4.00, 4.00, 4.00, 4.00, 4.00, 4.00, 4.00, 4.00, 4.00, 4.00, 4.00, 4.00, 4.00, 4.00, 4....
Reference: 3.58
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   8%|▊         | 248/3071 [41:55<42:42:28, 54.46s/it]
============================================================
Query ID: 249 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['12171 12484']
Answer:  ['246551']
Prediction: 12171, 12484
Reference: 24655.08
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   8%|▊         | 249/3071 [41:59<30:45:32, 39.24s/it]
============================================================
Query ID: 250 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['3']
Answer:  ['26']
Prediction: 3
Reference: 2.57
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   8%|▊         | 250/3071 [42:02<22:17:40, 28.45s/it]
============================================================
Query ID: 251 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['182527']
Answer:  ['1825266']
Prediction: 182527
Reference: 182526.64
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   8%|▊         | 251/3071 [42:06<16:25:00, 20.96s/it]
============================================================
Query ID: 252 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['12171 12484']
Answer:  ['123275']
Prediction: 12171, 12484
Reference: 12327.54
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   8%|▊         | 252/3071 [42:09<12:21:33, 15.78s/it]
============================================================
Query ID: 253 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['50989476']
Answer:  ['599694862']
Prediction: 50989476
Reference: 59969486.20
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   8%|▊         | 253/3071 [42:12<9:22:35, 11.98s/it] 
============================================================
Query ID: 254 | Type: Numerical Reasoning | SubType: Ranking
============================================================
Predictions:  ['china european union27 mexico japan indonesia taiwan egypt south korea vietnam thailand']
Answer:  ['china european union27 mexico japan indonesia taiwan egypt south korea vietnam thailand']
Prediction: China, European Union-27, Mexico, Japan, Indonesia, Taiwan, Egypt, South Korea, Vietnam, Thailand
Reference: China, European Union-27, Mexico, Japan, Indonesia, Taiwan, Egypt, South Korea, Vietnam, Thailand
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 100.0}
Processing text modality:   8%|▊         | 254/3071 [42:16<7:25:03,  9.48s/it]
============================================================
Query ID: 255 | Type: Numerical Reasoning | SubType: Comparison
============================================================
Predictions:  ['aug 2022 12020670']
Answer:  ['aug 2022 9634024']
Prediction: Aug. 2022, 1202067.00
Reference: Aug. 2022, 963402.40
Metrics: {'F1': 66.67, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 0.0}
Checkpoint saved: 230 queries processed
Processing text modality:   8%|▊         | 255/3071 [42:19<6:00:30,  7.68s/it]
============================================================
Query ID: 256 | Type: Data Analysis | SubType: Predictive Analysis
============================================================
Predictions:  ['decrease decrease']
Answer:  ['increasing trend']
Prediction: Decrease, Decrease
Reference: Increasing trend
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   8%|▊         | 256/3071 [42:22<4:53:50,  6.26s/it]
============================================================
Query ID: 257 | Type: Data Analysis | SubType: Anomaly Analysis
============================================================
Error processing query 257: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    eval_prompt = Eval_Prompt[query['SubQType']].format_map({
KeyError: 'User_Answer'
Processing text modality:   8%|▊         | 257/3071 [42:25<4:06:17,  5.25s/it]
============================================================
Query ID: 258 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['no']
Answer:  ['no']
Prediction: No
Reference: No
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   8%|▊         | 258/3071 [42:28<3:28:58,  4.46s/it]
============================================================
Query ID: 259 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['3902']
Answer:  ['3902']
Prediction: 390.193
Reference: 390.19
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   8%|▊         | 259/3071 [42:31<3:06:29,  3.98s/it]
============================================================
Query ID: 260 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['2021 2022']
Answer:  ['2021 2022']
Prediction: 2021, 2022
Reference: 2021, 2022
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   8%|▊         | 260/3071 [42:34<2:52:19,  3.68s/it]
============================================================
Query ID: 261 | Type: Data Analysis | SubType: Rudimentary Analysis
============================================================
Predictions:  ['1692 1692 1692']
Answer:  ['1692']
Prediction: 169.17, 169.17, 169.17
Reference: 169.20
Metrics: {'F1': 50.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(50.0), 'SacreBLEU': 0.0}
Processing text modality:   8%|▊         | 261/3071 [42:37<2:48:51,  3.61s/it]
============================================================
Query ID: 262 | Type: Visualization | SubType: LineChart Generation
============================================================
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/mnt/data1/users/4xin/RealHiTBench/tables/agriculture-table02.xlsx')
fiscal_years = ['2020', '2021', '2022', '2023', '2024']
exports = [139.724, 171.833, 196.055, 178.184, 174.428]
plt.plot(fiscal_years, exports, marker='o')
plt.title('Agricultural Export Values (Billion Dollars) from Fiscal Years 2020 to 2024')
plt.xlabel('Fiscal Year')
plt.ylabel('Export Value (Billion Dollars)')
plt.xticks(fiscal_years)
plt.grid(True)
plt.show()

Python Error: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.
Prediction: import pandas as pd 
 import matplotlib.pyplot as plt 
 df = pd.read_excel('table.xlsx')
 fiscal_years = ['2020', '2021', '2022', '2023', '2024']
 exports = [139.724, 171.833, 196.055, 178.184, 174.42...
Reference: [[139.724, 171.833, 196.055, 178.184]]

Metrics: {'ECR': False, 'Pass': 'None'}
Processing text modality:   9%|▊         | 262/3071 [42:46<4:03:00,  5.19s/it]
============================================================
Query ID: 263 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['30990 35119 46542 48017 46854 45998 44294 41863 35410 31856']
Answer:  ['406943']
Prediction: 30990, 35119, 46542, 48017, 46854, 45998, 44294, 41863, 35410, 31856
Reference: 406943
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   9%|▊         | 263/3071 [42:50<3:42:02,  4.74s/it]
============================================================
Query ID: 264 | Type: Numerical Reasoning | SubType: Ranking
============================================================
Predictions:  ['fy 11 fy 10 fy 12 fy 09 fy 13 fy 14 fy 15 fy 16 fy 17 fy 18']
Answer:  ['fy 12 fy 13 fy 11 fy 14 fy 15 fy 16 fy 17 fy 10 fy 18 fy 09']
Prediction: FY '11, FY '10, FY '12, FY '09, FY '13, FY '14, FY '15, FY '16, FY '17, FY '18
Reference: FY '12, FY '13, FY '11, FY '14, FY '15, FY '16, FY '17, FY '10, FY '18, FY '09
Metrics: {'F1': 100.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(70.0), 'SacreBLEU': 67.23}
Processing text modality:   9%|▊         | 264/3071 [42:53<3:17:32,  4.22s/it]
============================================================
Query ID: 265 | Type: Visualization | SubType: PieChart Generation
============================================================
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/mnt/data1/users/4xin/RealHiTBench/tables/economy-table02.xlsx')
data = df.iloc[2:5, 2:13].values.flatten()
years = ['FY \'09', 'FY \'13', 'FY \'18']
values = [data[0], data[5], data[10]]
plt.pie(values, labels=years, autopct='%1.1f%%')
plt.title('Proportion of Net Operating Revenue')
plt.show()

Python Error: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.
Prediction: import pandas as pd 
 import matplotlib.pyplot as plt 
 df = pd.read_excel('table.xlsx')
 data = df.iloc[2:5, 2:13].values.flatten()
 years = ['FY \'09', 'FY \'13', 'FY \'18']
 values = [data[0], data...
Reference: [0.28, 0.43, 0.29]

Metrics: {'ECR': False, 'Pass': 'None'}
Processing text modality:   9%|▊         | 265/3071 [42:58<3:26:45,  4.42s/it]
============================================================
Query ID: 266 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['andaman nicobar']
Answer:  ['andaman nicobar']
Prediction: Andaman Nicobar
Reference: Andaman Nicobar
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Checkpoint saved: 240 queries processed
Processing text modality:   9%|▊         | 266/3071 [43:01<3:13:30,  4.14s/it]
============================================================
Query ID: 267 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['yes']
Answer:  ['yes']
Prediction: Yes
Reference: Yes
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   9%|▊         | 267/3071 [43:05<3:02:22,  3.90s/it]
============================================================
Query ID: 268 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['992']
Answer:  ['992']
Prediction: 99.15
Reference: 99.15
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   9%|▊         | 268/3071 [43:08<2:57:22,  3.80s/it]
============================================================
Query ID: 269 | Type: Numerical Reasoning | SubType: Comparison
============================================================
Predictions:  ['karnataka kerala']
Answer:  ['kerala']
Prediction: Karnataka, Kerala
Reference: Kerala
Metrics: {'F1': 66.67, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 0.0}
Processing text modality:   9%|▉         | 269/3071 [43:11<2:52:12,  3.69s/it]
============================================================
Query ID: 270 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['21364']
Answer:  ['21364']
Prediction: 21364
Reference: 21364
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   9%|▉         | 270/3071 [43:15<2:50:14,  3.65s/it]
============================================================
Query ID: 271 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['punjab']
Answer:  ['punjab']
Prediction: Punjab
Reference: Punjab
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   9%|▉         | 271/3071 [43:18<2:46:05,  3.56s/it]
============================================================
Query ID: 272 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['36']
Answer:  ['36']
Prediction: $3.56
Reference: 3.56
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   9%|▉         | 272/3071 [43:20<2:20:36,  3.01s/it]
============================================================
Query ID: 273 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['canned packed in syrup or water']
Answer:  ['canned packed in syrup or water']
Prediction: Canned, packed in syrup or water
Reference: Canned, packed in syrup or water
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 100.0}
Processing text modality:   9%|▉         | 273/3071 [43:22<2:04:12,  2.66s/it]
============================================================
Query ID: 274 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['466 262']
Answer:  ['495']
Prediction: 46.60, 26.20
Reference: 49.53
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   9%|▉         | 274/3071 [43:24<1:55:08,  2.47s/it]
============================================================
Query ID: 275 | Type: Data Analysis | SubType: Rudimentary Analysis
============================================================
Predictions:  ['usda economic research service ers calculations from 2022 circana formerly information resources inc iri omnimarket core outlets formerly infoscan data and usda ars national nutrient database for standard reference sr legacy release food patterns equivalents database fped 2017–18 and fpeds accompanying methodology and user guide']
Answer:  ['source usda economic research service ers calculations from 2022 circana formerly information resources inc iri omnimarket core outlets formerly infoscan data and usda ars national nutrient database for standard reference sr legacy release food patterns equivalents database fped 2017–18 and fpeds accompanying methodology and user guide']
Prediction: USDA, Economic Research Service (ERS) calculations from 2022 Circana (formerly Information Resources, Inc. (IRI)) OmniMarket Core Outlets (formerly InfoScan) data; and USDA, ARS, National Nutrient Dat...
Reference: Source: USDA, Economic Research Service (ERS) calculations from 2022 Circana (formerly Information Resources, Inc. (IRI)) OmniMarket Core Outlets (formerly InfoScan) data; and USDA, ARS, National Nutr...
Metrics: {'F1': 98.9, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(98.92), 'SacreBLEU': 97.8}
Processing text modality:   9%|▉         | 275/3071 [43:29<2:25:31,  3.12s/it]
============================================================
Query ID: 276 | Type: Data Analysis | SubType: Rudimentary Analysis
============================================================
Predictions:  ['50 03']
Answer:  ['50 04']
Prediction: 4.95, 0.29
Reference: 4.95, 0.41
Metrics: {'F1': 50.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(50.0), 'SacreBLEU': 0.0}
Checkpoint saved: 250 queries processed
Processing text modality:   9%|▉         | 276/3071 [43:31<2:09:11,  2.77s/it]
============================================================
Query ID: 277 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['92 92 93']
Answer:  ['95 92 93']
Prediction: 9.20, 9.23, 9.29
Reference: 9.47, 9.23, 9.30
Metrics: {'F1': 66.67, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 0.0}
Processing text modality:   9%|▉         | 277/3071 [43:44<4:34:26,  5.89s/it]
============================================================
Query ID: 278 | Type: Numerical Reasoning | SubType: Comparison
============================================================
Predictions:  ['93 95']
Answer:  ['after']
Prediction: 9.27, 9.47
Reference: After
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   9%|▉         | 278/3071 [43:57<6:11:47,  7.99s/it]
============================================================
Query ID: 279 | Type: Data Analysis | SubType: Exploratory Analysis
============================================================
Predictions:  ['weak positive correlation 02']
Answer:  ['weak negative correlation 04']
Prediction: Weak positive correlation, 0.23
Reference: Weak negative correlation, -0.38
Metrics: {'F1': 50.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(50.0), 'SacreBLEU': 19.0}
Processing text modality:   9%|▉         | 279/3071 [44:09<7:19:07,  9.44s/it]
============================================================
Query ID: 280 | Type: Data Analysis | SubType: Summary Analysis
============================================================
Error processing query 280: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    eval_prompt = Eval_Prompt[query['SubQType']].format_map({
KeyError: 'User_Answer'
Processing text modality:   9%|▉         | 280/3071 [44:27<9:08:16, 11.79s/it]
============================================================
Query ID: 281 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['100 106 96 91 86 83 81 82']
Answer:  ['172']
Prediction: 10.02, 10.609, 9.554, 9.105, 8.644, 8.275, 8.123, 8.191
Reference: 17.18
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   9%|▉         | 281/3071 [44:30<7:03:21,  9.10s/it]
============================================================
Query ID: 282 | Type: Data Analysis | SubType: Rudimentary Analysis
============================================================
Predictions:  ['0 mgl malathion']
Answer:  ['no such concentration exists']
Prediction: 0 mg/L malathion
Reference: No such concentration exists
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   9%|▉         | 282/3071 [44:31<5:12:08,  6.71s/it]
============================================================
Query ID: 283 | Type: Numerical Reasoning | SubType: Comparison
============================================================
Predictions:  ['0 mgl 5 mgl']
Answer:  ['5 mgl']
Prediction: 0 mg/L, 5 mg/L
Reference: 5 mg/L
Metrics: {'F1': 66.67, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 31.95}
Processing text modality:   9%|▉         | 283/3071 [44:32<3:55:17,  5.06s/it]
============================================================
Query ID: 284 | Type: Numerical Reasoning | SubType: Ranking
============================================================
Predictions:  ['5 mgl malathion 1 mgl malathion 0 mgl malathion']
Answer:  ['1 mgl 5 mgl 0 mgl']
Prediction: 5 mg/L malathion, 1 mg/L malathion, 0 mg/L malathion
Reference: 1 mg/L, 5 mg/L, 0 mg/L
Metrics: {'F1': 80.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(53.33), 'SacreBLEU': 16.52}
Processing text modality:   9%|▉         | 284/3071 [44:34<3:08:12,  4.05s/it]
============================================================
Query ID: 285 | Type: Data Analysis | SubType: Exploratory Analysis
============================================================
Predictions:  ['strong negative correlation 09']
Answer:  ['negative impact']
Prediction: Strong negative correlation, -0.92
Reference: Negative impact
Metrics: {'F1': 33.33, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(33.33), 'SacreBLEU': 15.97}
Processing text modality:   9%|▉         | 285/3071 [44:35<2:29:14,  3.21s/it]
============================================================
Query ID: 286 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['463']
Answer:  ['463']
Prediction: 46.3
Reference: 46.30
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:   9%|▉         | 286/3071 [44:36<2:03:43,  2.67s/it]
============================================================
Query ID: 287 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['barley']
Answer:  ['soybean']
Prediction: Barley
Reference: Soybean
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Checkpoint saved: 260 queries processed
Processing text modality:   9%|▉         | 287/3071 [44:38<1:44:31,  2.25s/it]
============================================================
Query ID: 288 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['corn barley']
Answer:  ['corn']
Prediction: Corn, Barley
Reference: Corn
Metrics: {'F1': 66.67, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 0.0}
Processing text modality:   9%|▉         | 288/3071 [44:39<1:31:57,  1.98s/it]
============================================================
Query ID: 289 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['257']
Answer:  ['252']
Prediction: 25.67
Reference: 25.20
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:   9%|▉         | 289/3071 [44:40<1:24:07,  1.81s/it]
============================================================
Query ID: 290 | Type: Data Analysis | SubType: Predictive Analysis
============================================================
Predictions:  ['decreasing trend 320 265']
Answer:  ['decreasing trend']
Prediction: Decreasing trend, 32.00, 26.50
Reference: Decreasing trend
Metrics: {'F1': 66.67, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 31.95}
Processing text modality:   9%|▉         | 290/3071 [44:42<1:23:56,  1.81s/it]
============================================================
Query ID: 291 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['israel netherlands united kingdom united states']
Answer:  ['malta belgium canada france greece hungary ireland israel italy lithuania luxembourg netherlands poland portugal slovak republic spain united kingdom united states cyprus romania']
Prediction: Israel, Netherlands, United Kingdom, United States
Reference: Malta, Belgium, Canada, France, Greece, Hungary, Ireland, Israel, Italy, Lithuania, Luxembourg, Netherlands, Poland, Portugal, Slovak Republic, Spain, United Kingdom, United States, Cyprus, Romania 
Metrics: {'F1': 41.38, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(41.38), 'SacreBLEU': 3.31}
Processing text modality:   9%|▉         | 291/3071 [44:45<1:33:53,  2.03s/it]
============================================================
Query ID: 292 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['belgium malta']
Answer:  ['belgium']
Prediction: Belgium, Malta
Reference: Belgium
Metrics: {'F1': 66.67, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 0.0}
Processing text modality:  10%|▉         | 292/3071 [44:47<1:37:44,  2.11s/it]
============================================================
Query ID: 293 | Type: Data Analysis | SubType: Summary Analysis
============================================================
Error processing query 293: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    eval_prompt = Eval_Prompt[query['SubQType']].format_map({
KeyError: 'User_Answer'
Processing text modality:  10%|▉         | 293/3071 [44:55<3:06:00,  4.02s/it]
============================================================
Query ID: 294 | Type: Data Analysis | SubType: Rudimentary Analysis
============================================================
Predictions:  ['00 00']
Answer:  ['00']
Prediction: 0.0347, 0.0347
Reference: 0.04
Metrics: {'F1': 66.67, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 0.0}
Processing text modality:  10%|▉         | 294/3071 [44:58<2:48:19,  3.64s/it]
============================================================
Query ID: 295 | Type: Data Analysis | SubType: Anomaly Analysis
============================================================
Error processing query 295: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    eval_prompt = Eval_Prompt[query['SubQType']].format_map({
KeyError: 'User_Answer'
Processing text modality:  10%|▉         | 295/3071 [45:01<2:31:15,  3.27s/it]
============================================================
Query ID: 296 | Type: Numerical Reasoning | SubType: Ranking
============================================================
Predictions:  ['northern territory tl2']
Answer:  ['northern territory tl2']
Prediction: Northern Territory, TL2
Reference: Northern Territory, TL2
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:  10%|▉         | 296/3071 [45:07<3:17:42,  4.27s/it]
============================================================
Query ID: 297 | Type: Numerical Reasoning | SubType: Comparison
============================================================
Predictions:  ['2018 2016']
Answer:  ['2018']
Prediction: 2018, 2016
Reference: 2018
Metrics: {'F1': 66.67, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 0.0}
Processing text modality:  10%|▉         | 297/3071 [45:14<3:54:04,  5.06s/it]
============================================================
Query ID: 298 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['4333']
Answer:  ['4283']
Prediction: 433.3
Reference: 428.288
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  10%|▉         | 298/3071 [45:21<4:16:17,  5.55s/it]
============================================================
Query ID: 299 | Type: Data Analysis | SubType: Summary Analysis
============================================================
Error processing query 299: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    eval_prompt = Eval_Prompt[query['SubQType']].format_map({
KeyError: 'User_Answer'
Processing text modality:  10%|▉         | 299/3071 [45:33<5:50:40,  7.59s/it]
============================================================
Query ID: 300 | Type: Data Analysis | SubType: Predictive Analysis
============================================================
Predictions:  ['increasing trend']
Answer:  ['increasing trend']
Prediction: Increasing trend
Reference: Increasing trend
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Checkpoint saved: 270 queries processed
Processing text modality:  10%|▉         | 300/3071 [45:40<5:35:34,  7.27s/it]
============================================================
Query ID: 301 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['baby john bertrand jesse']
Answer:  ['baby john']
Prediction: Baby, John, Bertrand, Jesse
Reference: Baby, John
Metrics: {'F1': 66.67, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 31.95}
Processing text modality:  10%|▉         | 301/3071 [45:42<4:32:53,  5.91s/it]
============================================================
Query ID: 302 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['15']
Answer:  ['42']
Prediction: 15
Reference: 42
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  10%|▉         | 302/3071 [45:45<3:46:25,  4.91s/it]
============================================================
Query ID: 303 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['riberdymichel']
Answer:  ['riberdy michel']
Prediction: Riberdy,Michel
Reference: Riberdy, Michel
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  10%|▉         | 303/3071 [45:48<3:15:25,  4.24s/it]
============================================================
Query ID: 304 | Type: Data Analysis | SubType: Rudimentary Analysis
============================================================
Predictions:  ['2279631']
Answer:  ['25329']
Prediction: 227963.08
Reference: 2532.92
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  10%|▉         | 304/3071 [45:50<2:55:47,  3.81s/it]
============================================================
Query ID: 305 | Type: Data Analysis | SubType: Summary Analysis
============================================================
Error processing query 305: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    eval_prompt = Eval_Prompt[query['SubQType']].format_map({
KeyError: 'User_Answer'
Processing text modality:  10%|▉         | 305/3071 [45:57<3:32:48,  4.62s/it]
============================================================
Query ID: 306 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['31961']
Answer:  ['31961']
Prediction: 3196.1
Reference: 3196.1
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:  10%|▉         | 306/3071 [46:05<4:15:03,  5.53s/it]
============================================================
Query ID: 307 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['09 09 09 10 10 10 10']
Answer:  ['09']
Prediction: 0.920, 0.931, 0.943, 0.958, 0.973, 0.988, 1.000
Reference: 0.95
Metrics: {'F1': 25.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(25.0), 'SacreBLEU': 6.57}
Processing text modality:  10%|▉         | 307/3071 [46:14<5:11:15,  6.76s/it]
============================================================
Query ID: 308 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['09']
Answer:  ['09']
Prediction: 0.920
Reference: 0.92
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:  10%|█         | 308/3071 [46:22<5:23:15,  7.02s/it]
============================================================
Query ID: 309 | Type: Data Analysis | SubType: Summary Analysis
============================================================
Error processing query 309: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    eval_prompt = Eval_Prompt[query['SubQType']].format_map({
KeyError: 'User_Answer'
Processing text modality:  10%|█         | 309/3071 [46:33<6:25:48,  8.38s/it]
============================================================
Query ID: 310 | Type: Data Analysis | SubType: Predictive Analysis
============================================================
Predictions:  ['09 09 10 10 10 10 10']
Answer:  ['09']
Prediction: 0.94, 0.95, 0.96, 0.97, 0.98, 0.99, 1.00
Reference: 0.94
Metrics: {'F1': 25.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(25.0), 'SacreBLEU': 6.57}
Processing text modality:  10%|█         | 310/3071 [46:43<6:38:12,  8.65s/it]
============================================================
Query ID: 311 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['archered cecuttianthony albert fowkekevin g hardingbrian jacquessteve woodian']
Answer:  ['archered cecuttianthony albert fowkekevin g hardingbrian jacquessteve verrilligiovanna woodian']
Prediction: Archer,Ed, Cecutti,Anthony Albert, Fowke,Kevin G, Harding,Brian, Jacques,Steve, Wood,Ian
Reference: Archer,Ed, Cecutti,Anthony Albert, Fowke,Kevin G, Harding,Brian, Jacques,Steve, Verrilli,Giovanna, Wood,Ian
Metrics: {'F1': 94.12, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(94.12), 'SacreBLEU': 76.73}
Processing text modality:  10%|█         | 311/3071 [46:45<5:11:07,  6.76s/it]
============================================================
Query ID: 312 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['archered']
Answer:  ['verrilli giovanna']
Prediction: Archer,Ed
Reference: Verrilli, Giovanna
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Checkpoint saved: 280 queries processed
Processing text modality:  10%|█         | 312/3071 [46:47<3:57:59,  5.18s/it]
============================================================
Query ID: 313 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['43560']
Answer:  ['43229']
Prediction: 4356.00
Reference: 4322.87
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  10%|█         | 313/3071 [46:48<3:09:05,  4.11s/it]
============================================================
Query ID: 314 | Type: Data Analysis | SubType: Summary Analysis
============================================================
Error processing query 314: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    eval_prompt = Eval_Prompt[query['SubQType']].format_map({
KeyError: 'User_Answer'
Processing text modality:  10%|█         | 314/3071 [46:54<3:36:11,  4.71s/it]
============================================================
Query ID: 315 | Type: Data Analysis | SubType: Rudimentary Analysis
============================================================
Predictions:  ['43560 17477']
Answer:  ['43229 18905']
Prediction: 4356.00, 1747.72
Reference: 4322.87, 1890.55
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  10%|█         | 315/3071 [46:56<2:58:10,  3.88s/it]
============================================================
Query ID: 316 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['cripplegate aldersgate']
Answer:  ['cripplegate']
Prediction: Cripplegate, Aldersgate
Reference: Cripplegate
Metrics: {'F1': 66.67, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 0.0}
Processing text modality:  10%|█         | 316/3071 [47:03<3:34:32,  4.67s/it]
============================================================
Query ID: 317 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['farringdon without']
Answer:  ['abbey']
Prediction: Farringdon Without
Reference: Abbey
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  10%|█         | 317/3071 [47:09<3:58:07,  5.19s/it]
============================================================
Query ID: 318 | Type: Numerical Reasoning | SubType: Comparison
============================================================
Predictions:  ['portsoken aldersgate']
Answer:  ['portsoken']
Prediction: Portsoken, Aldersgate
Reference: Portsoken
Metrics: {'F1': 66.67, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 0.0}
Processing text modality:  10%|█         | 318/3071 [47:16<4:15:52,  5.58s/it]
============================================================
Query ID: 319 | Type: Data Analysis | SubType: Predictive Analysis
============================================================
Predictions:  ['farringdon without abbey']
Answer:  ['abbey']
Prediction: Farringdon Without, Abbey
Reference: Abbey
Metrics: {'F1': 50.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(50.0), 'SacreBLEU': 0.0}
Processing text modality:  10%|█         | 319/3071 [47:22<4:28:22,  5.85s/it]
============================================================
Query ID: 320 | Type: Data Analysis | SubType: Exploratory Analysis
============================================================
Predictions:  ['strong positive correlation 10']
Answer:  ['strong positive correlation 09']
Prediction: Strong positive correlation, 0.98
Reference: Strong positive correlation, 0.95
Metrics: {'F1': 75.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(75.0), 'SacreBLEU': 59.46}
Processing text modality:  10%|█         | 320/3071 [47:29<4:39:27,  6.10s/it]
============================================================
Query ID: 321 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['1376 1084 1074']
Answer:  ['3534']
Prediction: 1376, 1084, 1074
Reference: 3534
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  10%|█         | 321/3071 [47:36<4:57:26,  6.49s/it]
============================================================
Query ID: 322 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['mexico 223168']
Answer:  ['china people’s republic of 1942008']
Prediction: Mexico, 223168
Reference: China (People’s Republic of), 1942008
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  10%|█         | 322/3071 [47:43<5:05:01,  6.66s/it]
============================================================
Query ID: 323 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['2840']
Answer:  ['2832']
Prediction: 284.00
Reference: 283.17
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Checkpoint saved: 290 queries processed
Processing text modality:  11%|█         | 323/3071 [47:50<5:09:08,  6.75s/it]
============================================================
Query ID: 324 | Type: Data Analysis | SubType: Summary Analysis
============================================================
Error processing query 324: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    eval_prompt = Eval_Prompt[query['SubQType']].format_map({
KeyError: 'User_Answer'
Processing text modality:  11%|█         | 324/3071 [48:00<5:55:54,  7.77s/it]
============================================================
Query ID: 325 | Type: Data Analysis | SubType: Predictive Analysis
============================================================
Predictions:  ['decreasing trend']
Answer:  ['increasing trend']
Prediction: Decreasing trend
Reference: Increasing trend
Metrics: {'F1': 50.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(50.0), 'SacreBLEU': 0.0}
Processing text modality:  11%|█         | 325/3071 [48:07<5:42:20,  7.48s/it]
============================================================
Query ID: 326 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['03']
Answer:  ['03']
Prediction: -0.26
Reference: -0.26
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:  11%|█         | 326/3071 [48:09<4:26:30,  5.83s/it]
============================================================
Query ID: 327 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['08 07']
Answer:  ['yes']
Prediction: 0.77, 0.73
Reference: Yes
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  11%|█         | 327/3071 [48:11<3:36:15,  4.73s/it]
============================================================
Query ID: 328 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['yes']
Answer:  ['yes']
Prediction: Yes
Reference: Yes
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:  11%|█         | 328/3071 [48:13<2:56:20,  3.86s/it]
============================================================
Query ID: 329 | Type: Data Analysis | SubType: Rudimentary Analysis
============================================================
Predictions:  ['09 05 08 01 01']
Answer:  ['04']
Prediction: 0.90, 0.53, 0.77, -0.09, 0.10
Reference: 0.43
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  11%|█         | 329/3071 [48:16<2:41:53,  3.54s/it]
============================================================
Query ID: 330 | Type: Data Analysis | SubType: Summary Analysis
============================================================
Error processing query 330: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    eval_prompt = Eval_Prompt[query['SubQType']].format_map({
KeyError: 'User_Answer'
Processing text modality:  11%|█         | 330/3071 [48:24<3:42:06,  4.86s/it]
============================================================
Query ID: 331 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['4144']
Answer:  ['15371']
Prediction: 4144
Reference: 15371
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  11%|█         | 331/3071 [48:27<3:20:09,  4.38s/it]
============================================================
Query ID: 332 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['air']
Answer:  ['air visits']
Prediction: Air
Reference: Air Visits
Metrics: {'F1': 66.67, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 0.0}
Processing text modality:  11%|█         | 332/3071 [48:30<3:02:40,  4.00s/it]
============================================================
Query ID: 333 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['1457 1463']
Answer:  ['996']
Prediction: 1,457, 1,463
Reference: 99.59
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  11%|█         | 333/3071 [48:34<2:56:47,  3.87s/it]
============================================================
Query ID: 334 | Type: Data Analysis | SubType: Summary Analysis
============================================================
Error processing query 334: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    eval_prompt = Eval_Prompt[query['SubQType']].format_map({
KeyError: 'User_Answer'
Processing text modality:  11%|█         | 334/3071 [48:40<3:29:54,  4.60s/it]
============================================================
Query ID: 335 | Type: Data Analysis | SubType: Anomaly Analysis
============================================================
Error processing query 335: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    eval_prompt = Eval_Prompt[query['SubQType']].format_map({
KeyError: 'User_Answer'
Processing text modality:  11%|█         | 335/3071 [48:44<3:16:20,  4.31s/it]
============================================================
Query ID: 336 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['england']
Answer:  ['england']
Prediction: England
Reference: England
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:  11%|█         | 336/3071 [48:45<2:39:40,  3.50s/it]
============================================================
Query ID: 337 | Type: Data Analysis | SubType: Predictive Analysis
============================================================
Predictions:  ['decrease 2681686']
Answer:  ['decrease']
Prediction: Decrease, 2,681,686
Reference: Decrease
Metrics: {'F1': 66.67, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 0.0}
Checkpoint saved: 300 queries processed
Processing text modality:  11%|█         | 337/3071 [48:47<2:19:49,  3.07s/it]
============================================================
Query ID: 338 | Type: Data Analysis | SubType: Exploratory Analysis
============================================================
Predictions:  ['strong positive correlation 10']
Answer:  ['strong positive correlation 10']
Prediction: Strong positive correlation, 0.98
Reference: Strong positive correlation, 1.00
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 100.0}
Processing text modality:  11%|█         | 338/3071 [48:49<2:04:08,  2.73s/it]
============================================================
Query ID: 339 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['2259333 390413 31940']
Answer:  ['8938953']
Prediction: 2259333, 390413, 31940
Reference: 893895.33
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  11%|█         | 339/3071 [48:52<1:59:25,  2.62s/it]
============================================================
Query ID: 340 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['626 272']
Answer:  ['626']
Prediction: 626, 272
Reference: 626
Metrics: {'F1': 66.67, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 0.0}
Processing text modality:  11%|█         | 340/3071 [48:55<2:02:12,  2.68s/it]
============================================================
Query ID: 341 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['sector j']
Answer:  ['sector j']
Prediction: Sector J
Reference: Sector J
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:  11%|█         | 341/3071 [48:57<2:00:35,  2.65s/it]
============================================================
Query ID: 342 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['northern ireland sector f']
Answer:  ['sector s']
Prediction: Northern Ireland, Sector F
Reference: Sector S
Metrics: {'F1': 33.33, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(33.33), 'SacreBLEU': 15.97}
Processing text modality:  11%|█         | 342/3071 [49:00<2:00:58,  2.66s/it]
============================================================
Query ID: 343 | Type: Data Analysis | SubType: Rudimentary Analysis
============================================================
Predictions:  ['940 940']
Answer:  ['949']
Prediction: 94.00, 94.00
Reference: 94.86
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  11%|█         | 343/3071 [49:03<2:05:17,  2.76s/it]
============================================================
Query ID: 344 | Type: Data Analysis | SubType: Summary Analysis
============================================================
Error processing query 344: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    eval_prompt = Eval_Prompt[query['SubQType']].format_map({
KeyError: 'User_Answer'
Processing text modality:  11%|█         | 344/3071 [49:07<2:22:28,  3.13s/it]
============================================================
Query ID: 345 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['327884']
Answer:  ['327884']
Prediction: 327884
Reference: 327884
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:  11%|█         | 345/3071 [49:11<2:32:57,  3.37s/it]
============================================================
Query ID: 346 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['2014']
Answer:  ['2014']
Prediction: 2014
Reference: 2014
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:  11%|█▏        | 346/3071 [49:15<2:39:10,  3.50s/it]
============================================================
Query ID: 347 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['23681 8289']
Answer:  ['76319']
Prediction: 23681, -8289
Reference: 76319
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  11%|█▏        | 347/3071 [49:19<2:47:21,  3.69s/it]
============================================================
Query ID: 348 | Type: Visualization | SubType: LineChart Generation
============================================================
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/mnt/data1/users/4xin/RealHiTBench/tables/society-table84.xlsx')
years = df.columns[1:11]
high_value_visas = df.iloc[2, 1:11]
plt.plot(years, high_value_visas, marker='o')
plt.title('Trend in High-Value Visas Issued from 2008 to 2014')
plt.xlabel('Year')
plt.ylabel('Number of High-Value Visas')
plt.xticks(years)
plt.grid(True)
plt.show()

Python Error: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.
Prediction: import pandas as pd 
 import matplotlib.pyplot as plt 
 df = pd.read_excel('table.xlsx')
 years = df.columns[1:11]
 high_value_visas = df.iloc[2, 1:11]
 plt.plot(years, high_value_visas, marker='o')
 ...
Reference: [[12035, 31767, 32564, 22694, 17915, 11513, 9697]]

Metrics: {'ECR': False, 'Pass': 'None'}
Checkpoint saved: 310 queries processed
Processing text modality:  11%|█▏        | 348/3071 [49:27<3:48:38,  5.04s/it]
============================================================
Query ID: 349 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['573480']
Answer:  ['573480']
Prediction: 573480
Reference: 573480
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:  11%|█▏        | 349/3071 [49:51<8:05:49, 10.71s/it]
============================================================
Query ID: 350 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['364000 120490']
Answer:  ['243510']
Prediction: 364000, 120490
Reference: 243510
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  11%|█▏        | 350/3071 [50:15<11:13:25, 14.85s/it]
============================================================
Query ID: 351 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['english and maths']
Answer:  ['sum of participation english and maths']
Prediction: English and maths
Reference: Sum of Participation - English and maths
Metrics: {'F1': 66.67, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 0.0}
Processing text modality:  11%|█▏        | 351/3071 [50:39<13:12:22, 17.48s/it]
============================================================
Query ID: 352 | Type: Data Analysis | SubType: Summary Analysis
============================================================
Error processing query 352: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    eval_prompt = Eval_Prompt[query['SubQType']].format_map({
KeyError: 'User_Answer'
Processing text modality:  11%|█▏        | 352/3071 [51:12<16:39:48, 22.06s/it]
============================================================
Query ID: 353 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['13 28']
Answer:  ['13 28']
Prediction: -1.3%, 2.8%
Reference: -1.3%, 2.8%
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:  11%|█▏        | 353/3071 [51:18<13:02:01, 17.26s/it]
============================================================
Query ID: 354 | Type: Numerical Reasoning | SubType: Ranking
============================================================
Predictions:  ['201011 910200']
Answer:  ['200910 952400']
Prediction: 2010/11, 910200
Reference: 2009/10, 952400
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  12%|█▏        | 354/3071 [51:24<10:33:07, 13.98s/it]
============================================================
Query ID: 355 | Type: Numerical Reasoning | SubType: Multi-hop Numerical Reasoning
============================================================
Predictions:  ['200809 200']
Answer:  ['201112 13']
Prediction: 2008/09, 20.0%
Reference: 2011/12, 1.30%
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  12%|█▏        | 355/3071 [51:30<8:48:06, 11.67s/it] 
============================================================
Query ID: 356 | Type: Data Analysis | SubType: Rudimentary Analysis
============================================================
Predictions:  ['14348000']
Answer:  ['14404200']
Prediction: 1434800.00
Reference: 1440420.00
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  12%|█▏        | 356/3071 [51:36<7:32:12,  9.99s/it]
============================================================
Query ID: 357 | Type: Data Analysis | SubType: Anomaly Analysis
============================================================
Error processing query 357: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    eval_prompt = Eval_Prompt[query['SubQType']].format_map({
KeyError: 'User_Answer'
Processing text modality:  12%|█▏        | 357/3071 [51:43<6:40:25,  8.85s/it]
============================================================
Query ID: 358 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['level 1']
Answer:  ['of which level 1']
Prediction: Level 1
Reference: of which level 1
Metrics: {'F1': 66.67, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 0.0}
Processing text modality:  12%|█▏        | 358/3071 [51:48<5:57:59,  7.92s/it]
============================================================
Query ID: 359 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['level 2']
Answer:  ['of which level 1']
Prediction: level 2
Reference: of which level 1
Metrics: {'F1': 33.33, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(33.33), 'SacreBLEU': 0.0}
Processing text modality:  12%|█▏        | 359/3071 [51:54<5:28:12,  7.26s/it]
============================================================
Query ID: 360 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['1344570 1224210 1156780 1046240']
Answer:  ['13823080']
Prediction: 1344570, 1224210, 1156780, 1046240
Reference: 13823080
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Checkpoint saved: 320 queries processed
Processing text modality:  12%|█▏        | 360/3071 [52:19<9:31:40, 12.65s/it]
============================================================
Query ID: 361 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['201415']
Answer:  ['201415']
Prediction: 201415
Reference: 2014/15
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:  12%|█▏        | 361/3071 [52:43<11:54:42, 15.82s/it]
============================================================
Query ID: 362 | Type: Fact Checking | SubType: Multi-hop Fact Checking
============================================================
Predictions:  ['518800 438100']
Answer:  ['yes']
Prediction: 518800, 438100
Reference: Yes
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  12%|█▏        | 362/3071 [53:06<13:42:24, 18.22s/it]
============================================================
Query ID: 363 | Type: Data Analysis | SubType: Exploratory Analysis
============================================================
Predictions:  ['strong positive correlation 10']
Answer:  ['strong positive correlation 10']
Prediction: Strong positive correlation, 0.98
Reference: Strong positive correlation, 0.99
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 100.0}
Processing text modality:  12%|█▏        | 363/3071 [53:30<14:52:17, 19.77s/it]
============================================================
Query ID: 364 | Type: Data Analysis | SubType: Rudimentary Analysis
============================================================
Predictions:  ['11837500 11837500']
Answer:  ['1192950']
Prediction: 1183750.00, 1183750.00
Reference: 1192950
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  12%|█▏        | 364/3071 [53:54<15:53:55, 21.14s/it]
============================================================
Query ID: 365 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Generation Error (attempt 1/3): CUDA out of memory. Tried to allocate 3.10 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.27 GiB is free. Including non-PyTorch memory, this process has 45.12 GiB memory in use. Of the allocated memory 36.57 GiB is allocated by PyTorch, and 8.24 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Generation Error (attempt 2/3): CUDA out of memory. Tried to allocate 3.10 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.27 GiB is free. Including non-PyTorch memory, this process has 45.12 GiB memory in use. Of the allocated memory 36.05 GiB is allocated by PyTorch, and 8.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Generation Error (attempt 3/3): CUDA out of memory. Tried to allocate 3.10 GiB. GPU 0 has a total capacity of 47.40 GiB of which 2.27 GiB is free. Including non-PyTorch memory, this process has 45.12 GiB memory in use. Of the allocated memory 36.05 GiB is allocated by PyTorch, and 8.76 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Predictions:  ['error failed to get response']
Answer:  ['762100']
Prediction: Error: Failed to get response
Reference: 762100
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  12%|█▏        | 365/3071 [55:29<32:33:16, 43.31s/it]
============================================================
Query ID: 366 | Type: Numerical Reasoning | SubType: Comparison
============================================================
Generation Error (attempt 1/3): CUDA out of memory. Tried to allocate 3.10 GiB. GPU 0 has a total capacity of 47.40 GiB of which 464.31 MiB is free. Including non-PyTorch memory, this process has 46.94 GiB memory in use. Of the allocated memory 40.18 GiB is allocated by PyTorch, and 6.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Generation Error (attempt 2/3): CUDA out of memory. Tried to allocate 3.10 GiB. GPU 0 has a total capacity of 47.40 GiB of which 464.31 MiB is free. Including non-PyTorch memory, this process has 46.94 GiB memory in use. Of the allocated memory 40.18 GiB is allocated by PyTorch, and 6.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Generation Error (attempt 3/3): CUDA out of memory. Tried to allocate 3.10 GiB. GPU 0 has a total capacity of 47.40 GiB of which 464.31 MiB is free. Including non-PyTorch memory, this process has 46.94 GiB memory in use. Of the allocated memory 40.18 GiB is allocated by PyTorch, and 6.44 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Predictions:  ['error failed to get response']
Answer:  ['of which english']
Prediction: Error: Failed to get response
Reference: of which English
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  12%|█▏        | 366/3071 [58:59<70:04:27, 93.26s/it]
============================================================
Query ID: 367 | Type: Numerical Reasoning | SubType: Counting
============================================================
Generation Error (attempt 1/3): CUDA out of memory. Tried to allocate 3.10 GiB. GPU 0 has a total capacity of 47.40 GiB of which 464.31 MiB is free. Including non-PyTorch memory, this process has 46.94 GiB memory in use. Of the allocated memory 39.67 GiB is allocated by PyTorch, and 6.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Generation Error (attempt 2/3): CUDA out of memory. Tried to allocate 3.10 GiB. GPU 0 has a total capacity of 47.40 GiB of which 464.31 MiB is free. Including non-PyTorch memory, this process has 46.94 GiB memory in use. Of the allocated memory 39.67 GiB is allocated by PyTorch, and 6.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Generation Error (attempt 3/3): CUDA out of memory. Tried to allocate 3.10 GiB. GPU 0 has a total capacity of 47.40 GiB of which 464.31 MiB is free. Including non-PyTorch memory, this process has 46.94 GiB memory in use. Of the allocated memory 39.67 GiB is allocated by PyTorch, and 6.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Predictions:  ['error failed to get response']
Answer:  ['6']
Prediction: Error: Failed to get response
Reference: 6
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  12%|█▏        | 367/3071 [1:01:52<87:59:21, 117.15s/it]
============================================================
Query ID: 368 | Type: Visualization | SubType: BarChart Generation
============================================================
Generation Error (attempt 1/3): CUDA out of memory. Tried to allocate 3.10 GiB. GPU 0 has a total capacity of 47.40 GiB of which 908.31 MiB is free. Including non-PyTorch memory, this process has 46.51 GiB memory in use. Of the allocated memory 36.06 GiB is allocated by PyTorch, and 10.13 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Generation Error (attempt 2/3): CUDA out of memory. Tried to allocate 3.10 GiB. GPU 0 has a total capacity of 47.40 GiB of which 908.31 MiB is free. Including non-PyTorch memory, this process has 46.51 GiB memory in use. Of the allocated memory 38.65 GiB is allocated by PyTorch, and 7.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Generation Error (attempt 3/3): CUDA out of memory. Tried to allocate 3.10 GiB. GPU 0 has a total capacity of 47.40 GiB of which 908.31 MiB is free. Including non-PyTorch memory, this process has 46.51 GiB memory in use. Of the allocated memory 38.65 GiB is allocated by PyTorch, and 7.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
invalid visualization_answer: Error: Failed to get response

Code: 

Python Error: expected an indented block after 'if' statement on line 2 (<string>, line 3)
Prediction: Error: Failed to get response
Reference: [504220, 143750, 289030, 620, 23300, 19280]

Metrics: {'ECR': False, 'Pass': 'None'}
Processing text modality:  12%|█▏        | 368/3071 [1:04:20<95:00:46, 126.54s/it]
============================================================
Query ID: 369 | Type: Visualization | SubType: ScatterChart Generation
============================================================
Generation Error (attempt 1/3): CUDA out of memory. Tried to allocate 3.10 GiB. GPU 0 has a total capacity of 47.40 GiB of which 908.31 MiB is free. Including non-PyTorch memory, this process has 46.51 GiB memory in use. Of the allocated memory 38.65 GiB is allocated by PyTorch, and 7.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Generation Error (attempt 2/3): CUDA out of memory. Tried to allocate 3.10 GiB. GPU 0 has a total capacity of 47.40 GiB of which 908.31 MiB is free. Including non-PyTorch memory, this process has 46.51 GiB memory in use. Of the allocated memory 38.65 GiB is allocated by PyTorch, and 7.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Generation Error (attempt 3/3): CUDA out of memory. Tried to allocate 3.10 GiB. GPU 0 has a total capacity of 47.40 GiB of which 908.31 MiB is free. Including non-PyTorch memory, this process has 46.51 GiB memory in use. Of the allocated memory 38.65 GiB is allocated by PyTorch, and 7.54 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
invalid visualization_answer: Error: Failed to get response

Code: 

Python Error: expected an indented block after 'if' statement on line 2 (<string>, line 3)
Prediction: Error: Failed to get response
Reference: [[25690.0, 14870.0, 83060.0, 530.0, 260550.0]]

Metrics: {'ECR': False, 'Pass': 'None'}
Processing text modality:  12%|█▏        | 369/3071 [1:06:59<102:20:21, 136.35s/it]
============================================================
Query ID: 370 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['702230 30150 39820']
Answer:  ['772200']
Prediction: 702230, 30150, 39820
Reference: 772200
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Checkpoint saved: 330 queries processed
Processing text modality:  12%|█▏        | 370/3071 [1:07:04<72:33:24, 96.71s/it]  
============================================================
Query ID: 371 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['164210']
Answer:  ['164210']
Prediction: 164210
Reference: 164210
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:  12%|█▏        | 371/3071 [1:07:07<51:34:44, 68.77s/it]
============================================================
Query ID: 372 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['general fe college incl tertiary']
Answer:  ['general fe college incl tertiary']
Prediction: General FE College incl Tertiary
Reference: General FE College incl Tertiary
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 100.0}
Processing text modality:  12%|█▏        | 372/3071 [1:07:11<36:53:24, 49.20s/it]
============================================================
Query ID: 373 | Type: Data Analysis | SubType: Summary Analysis
============================================================
Error processing query 373: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    metric_scores = {}
KeyError: 'User_Answer'
Processing text modality:  12%|█▏        | 373/3071 [1:07:21<28:01:38, 37.40s/it]
============================================================
Query ID: 374 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['1297800']
Answer:  ['1297800']
Prediction: 1297800
Reference: 1297800
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:  12%|█▏        | 374/3071 [1:07:24<20:25:40, 27.27s/it]
============================================================
Query ID: 375 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['860200']
Answer:  ['860200']
Prediction: 860200
Reference: 860200
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:  12%|█▏        | 375/3071 [1:07:28<15:03:07, 20.10s/it]
============================================================
Query ID: 376 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['general fe college incl tertiary 462770']
Answer:  ['general fe college incl tertiary 462770']
Prediction: General FE College incl Tertiary, 462770
Reference: General FE College incl Tertiary, 462770
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 100.0}
Processing text modality:  12%|█▏        | 376/3071 [1:07:31<11:21:04, 15.16s/it]
============================================================
Query ID: 377 | Type: Fact Checking | SubType: Multi-hop Fact Checking
============================================================
Predictions:  ['572740 492230']
Answer:  ['572740']
Prediction: 572740, 492230
Reference: 572740
Metrics: {'F1': 66.67, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 0.0}
Processing text modality:  12%|█▏        | 377/3071 [1:07:35<8:46:11, 11.72s/it] 
============================================================
Query ID: 378 | Type: Data Analysis | SubType: Summary Analysis
============================================================
Error processing query 378: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    metric_scores = {}
KeyError: 'User_Answer'
Processing text modality:  12%|█▏        | 378/3071 [1:07:47<8:42:48, 11.65s/it]
============================================================
Query ID: 379 | Type: Numerical Reasoning | SubType: Comparison
============================================================
Predictions:  ['maths 12000']
Answer:  ['maths 2700']
Prediction: Maths, 12000
Reference: Maths, 2700
Metrics: {'F1': 50.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(50.0), 'SacreBLEU': 0.0}
Processing text modality:  12%|█▏        | 379/3071 [1:07:50<6:51:40,  9.18s/it]
============================================================
Query ID: 380 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['3822495 3822495']
Answer:  ['5059195']
Prediction: 382249.5, 382249.5
Reference: 505919.50
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  12%|█▏        | 380/3071 [1:07:54<5:39:43,  7.57s/it]
============================================================
Query ID: 381 | Type: Data Analysis | SubType: Rudimentary Analysis
============================================================
Predictions:  ['820730 734650']
Answer:  ['870830']
Prediction: 820730, 734650
Reference: 870830
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  12%|█▏        | 381/3071 [1:07:57<4:47:18,  6.41s/it]
============================================================
Query ID: 382 | Type: Numerical Reasoning | SubType: Comparison
============================================================
Predictions:  ['951100 872800']
Answer:  ['1823950']
Prediction: 951100, 872800
Reference: 1823950
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Checkpoint saved: 340 queries processed
Processing text modality:  12%|█▏        | 382/3071 [1:08:01<4:09:05,  5.56s/it]
============================================================
Query ID: 383 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['753390']
Answer:  ['753390']
Prediction: 753390
Reference: 753390
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:  12%|█▏        | 383/3071 [1:08:04<3:37:19,  4.85s/it]
============================================================
Query ID: 384 | Type: Visualization | SubType: BarChart Generation
============================================================
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/mnt/data1/users/4xin/RealHiTBench/tables/education-table10.xlsx', sheet_name='2009-2010')
participation_english = df.iloc[1:2, 1:9].iloc[0].values
institutions = ['General FE College incl Tertiary', 'Sixth form college', 'Special colleges', 'Other Public Funded', 'Schools', 'Private Sector Public Funded', 'Total']
plt.bar(institutions, participation_english)
plt.xlabel('Institution Type')
plt.ylabel('Total Participation for English')
plt.title('Total Participation for English across All Institution Types')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

Python Error: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.
Prediction: import pandas as pd 
 import matplotlib.pyplot as plt 
 df = pd.read_excel('table.xlsx', sheet_name='2009-2010')
 participation_english = df.iloc[1:2, 1:9].iloc[0].values
 institutions = ['General FE ...
Reference: [20300.0, 540.0, 951100.0, 323490.0, 17460.0, 106730.0, 23540.0, 580.0, 872800.0, 346230.0, 15180.0, 84650.0]

Metrics: {'ECR': False, 'Pass': 'None'}
Processing text modality:  13%|█▎        | 384/3071 [1:08:13<4:25:46,  5.93s/it]
============================================================
Query ID: 385 | Type: Visualization | SubType: PieChart Generation
============================================================
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/mnt/data1/users/4xin/RealHiTBench/tables/education-table10.xlsx', sheet_name='2009-2010')
english_participation = df.iloc[1:5, 1:9].iloc[:, 0].values
institution_types = ['General FE College incl Tertiary', 'Sixth form college', 'Special colleges', 'Other Public Funded', 'Schools', 'Private Sector Public Funded']
plt.pie(english_participation, labels=institution_types, autopct='%1.1f%%')
plt.title('Proportion of Total Participation for English by Institution Type')
plt.show()

Python Error: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.
Prediction: import pandas as pd 
 import matplotlib.pyplot as plt 
 df = pd.read_excel('table.xlsx', sheet_name='2009-2010')
 english_participation = df.iloc[1:5, 1:9].iloc[:, 0].values
 institution_types = ['Gen...
Reference: [0.02, 0.0, 0.65, 0.26, 0.01, 0.06]

Metrics: {'ECR': False, 'Pass': 'None'}
Processing text modality:  13%|█▎        | 385/3071 [1:08:21<4:53:25,  6.55s/it]
============================================================
Query ID: 386 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['485340 437520']
Answer:  ['922860']
Prediction: 485340, 437520
Reference: 922860
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  13%|█▎        | 386/3071 [1:08:26<4:30:25,  6.04s/it]
============================================================
Query ID: 387 | Type: Numerical Reasoning | SubType: Multi-hop Numerical Reasoning
============================================================
Predictions:  ['560 411040']
Answer:  ['853070']
Prediction: 560, 411040
Reference: 853070
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  13%|█▎        | 387/3071 [1:08:30<4:12:28,  5.64s/it]
============================================================
Query ID: 388 | Type: Fact Checking | SubType: Multi-hop Fact Checking
============================================================
Predictions:  ['general fe college incl tertiary other public funded']
Answer:  ['other public funded']
Prediction: General FE College incl Tertiary, Other Public Funded
Reference: Other Public Funded
Metrics: {'F1': 54.55, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(54.55), 'SacreBLEU': 20.56}
Processing text modality:  13%|█▎        | 388/3071 [1:08:35<3:59:27,  5.35s/it]
============================================================
Query ID: 389 | Type: Data Analysis | SubType: Rudimentary Analysis
============================================================
Predictions:  ['440750 21530 16620 77150 720 12400 994300']
Answer:  ['994290 private sector public funded']
Prediction: 440750, 21530, 16620, 77150, 720, 12400, 994300
Reference: 994290, Private Sector Public Funded
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  13%|█▎        | 389/3071 [1:08:41<4:11:11,  5.62s/it]
============================================================
Query ID: 390 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['568']
Answer:  ['07']
Prediction: 56.78
Reference: 0.66
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  13%|█▎        | 390/3071 [1:08:46<3:55:39,  5.27s/it]
============================================================
Query ID: 391 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['1119800']
Answer:  ['1119800']
Prediction: 1119800
Reference: 1119800
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:  13%|█▎        | 391/3071 [1:08:53<4:28:44,  6.02s/it]
============================================================
Query ID: 392 | Type: Numerical Reasoning | SubType: Ranking
============================================================
Predictions:  ['general fe college incl tertiary private sector public funded other public funded special colleges sixth form college schools']
Answer:  ['general fe college incl tertiary private sector public funded other public funded sixth form college special colleges schools']
Prediction: General FE College incl Tertiary, Private Sector Public Funded, Other Public Funded, Special colleges, Sixth form college, Schools
Reference: General FE College incl Tertiary, Private Sector Public Funded, Other Public Funded, Sixth form college, Special colleges, Schools
Metrics: {'F1': 100.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(88.89), 'SacreBLEU': 76.34}
Checkpoint saved: 350 queries processed
Processing text modality:  13%|█▎        | 392/3071 [1:09:02<5:03:26,  6.80s/it]
============================================================
Query ID: 393 | Type: Numerical Reasoning | SubType: Comparison
============================================================
Predictions:  ['23410 23410']
Answer:  ['23370']
Prediction: 23410, 23410
Reference: 23370
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  13%|█▎        | 393/3071 [1:09:10<5:18:57,  7.15s/it]
============================================================
Query ID: 394 | Type: Data Analysis | SubType: Rudimentary Analysis
============================================================
Predictions:  ['1573']
Answer:  ['183610']
Prediction: 157.33
Reference: 183610
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  13%|█▎        | 394/3071 [1:09:18<5:26:22,  7.31s/it]
============================================================
Query ID: 395 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['28368']
Answer:  ['28368']
Prediction: 28,368
Reference: 28368
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:  13%|█▎        | 395/3071 [1:09:28<6:03:52,  8.16s/it]
============================================================
Query ID: 396 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['2020 q2 2019 q2']
Answer:  ['q2 2019']
Prediction: 2020 Q2, 2019 Q2
Reference: Q2 2019
Metrics: {'F1': 66.67, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 31.95}
Processing text modality:  13%|█▎        | 396/3071 [1:09:38<6:35:58,  8.88s/it]
============================================================
Query ID: 397 | Type: Numerical Reasoning | SubType: Multi-hop Numerical Reasoning
============================================================
Predictions:  ['2019 2018']
Answer:  ['2018']
Prediction: 2019, 2018
Reference: 2018
Metrics: {'F1': 66.67, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 0.0}
Processing text modality:  13%|█▎        | 397/3071 [1:09:49<6:55:32,  9.32s/it]
============================================================
Query ID: 398 | Type: Data Analysis | SubType: Rudimentary Analysis
============================================================
Predictions:  ['54845']
Answer:  ['17745']
Prediction: 5484.50
Reference: 17745
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  13%|█▎        | 398/3071 [1:09:59<7:07:08,  9.59s/it]
============================================================
Query ID: 399 | Type: Data Analysis | SubType: Exploratory Analysis
============================================================
Predictions:  ['strong positive correlation 10']
Answer:  ['strong positive correlation 10']
Prediction: Strong positive correlation, 0.98
Reference: Strong positive correlation, 0.97
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 100.0}
Processing text modality:  13%|█▎        | 399/3071 [1:10:09<7:16:33,  9.80s/it]
============================================================
Query ID: 400 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['115010']
Answer:  ['115010']
Prediction: 115010
Reference: 115010
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:  13%|█▎        | 400/3071 [1:10:17<6:55:00,  9.32s/it]
============================================================
Query ID: 401 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['2019 1633']
Answer:  ['2019 4085']
Prediction: 2019, 1633
Reference: 2019, 4085
Metrics: {'F1': 50.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(50.0), 'SacreBLEU': 0.0}
Processing text modality:  13%|█▎        | 401/3071 [1:10:26<6:43:17,  9.06s/it]
============================================================
Query ID: 402 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['increasing']
Answer:  ['increasing']
Prediction: Increasing
Reference: Increasing
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Checkpoint saved: 360 queries processed
Processing text modality:  13%|█▎        | 402/3071 [1:10:34<6:28:30,  8.73s/it]
============================================================
Query ID: 403 | Type: Data Analysis | SubType: Predictive Analysis
============================================================
Predictions:  ['decreasing trend decreasing trend']
Answer:  ['decreasing']
Prediction: Decreasing trend, Decreasing trend
Reference: Decreasing
Metrics: {'F1': 40.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(40.0), 'SacreBLEU': 15.97}
Processing text modality:  13%|█▎        | 403/3071 [1:10:42<6:22:00,  8.59s/it]
============================================================
Query ID: 404 | Type: Data Analysis | SubType: Exploratory Analysis
============================================================
Predictions:  ['strong positive correlation 10']
Answer:  ['strong positive correlation 10']
Prediction: Strong positive correlation, 0.98
Reference: Strong positive correlation, 0.96
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 100.0}
Processing text modality:  13%|█▎        | 404/3071 [1:10:50<6:19:00,  8.53s/it]
============================================================
Query ID: 405 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['257']
Answer:  ['257']
Prediction: 25.70
Reference: 25.70
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:  13%|█▎        | 405/3071 [1:10:58<6:00:37,  8.12s/it]
============================================================
Query ID: 406 | Type: Numerical Reasoning | SubType: Counting
============================================================
Predictions:  ['q1 q2 q3']
Answer:  ['3']
Prediction: Q1, Q2, Q3
Reference: 3
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  13%|█▎        | 406/3071 [1:11:05<5:48:41,  7.85s/it]
============================================================
Query ID: 407 | Type: Numerical Reasoning | SubType: Comparison
============================================================
Predictions:  ['q1 q2']
Answer:  ['q2']
Prediction: Q1, Q2
Reference: Q2
Metrics: {'F1': 66.67, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 0.0}
Processing text modality:  13%|█▎        | 407/3071 [1:11:12<5:38:47,  7.63s/it]
============================================================
Query ID: 408 | Type: Data Analysis | SubType: Summary Analysis
============================================================
Error processing query 408: 'User_Answer'
Traceback (most recent call last):
  File "/ltstorage/home/4xin/image_table/RealHiTBench/inference/inference_qwen3vl_local.py", line 1167, in gen_solution
    metric_scores = {}
KeyError: 'User_Answer'
Processing text modality:  13%|█▎        | 408/3071 [1:11:26<7:08:43,  9.66s/it]
============================================================
Query ID: 409 | Type: Data Analysis | SubType: Exploratory Analysis
============================================================
Predictions:  ['strong positive correlation 10']
Answer:  ['strong negative correlation 09']
Prediction: Strong positive correlation, 0.98
Reference: Strong negative correlation, -0.95
Metrics: {'F1': 50.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(50.0), 'SacreBLEU': 19.0}
Processing text modality:  13%|█▎        | 409/3071 [1:11:34<6:37:43,  8.96s/it]
============================================================
Query ID: 410 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['15849']
Answer:  ['15849']
Prediction: 15849
Reference: 15849
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:  13%|█▎        | 410/3071 [1:11:38<5:36:32,  7.59s/it]
============================================================
Query ID: 411 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['2014 4783 3902 881']
Answer:  ['2014 881']
Prediction: 2014, 4783, 3902, 881
Reference: 2014, 881
Metrics: {'F1': 66.67, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(66.67), 'SacreBLEU': 19.0}
Processing text modality:  13%|█▎        | 411/3071 [1:11:43<5:02:35,  6.83s/it]
============================================================
Query ID: 412 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['11445 11149 11804']
Answer:  ['38491']
Prediction: 11445, 11149, 11804
Reference: 3849.08
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  13%|█▎        | 412/3071 [1:11:48<4:37:38,  6.27s/it]
============================================================
Query ID: 413 | Type: Visualization | SubType: LineChart Generation
============================================================
Code: import pandas as pd
import matplotlib.pyplot as plt
df = pd.read_excel('/mnt/data1/users/4xin/RealHiTBench/tables/economy-table08.xlsx')
years = df[df['Year'].isin(['2012', '2013', '2014', '2015', '2016'])]['Year'].astype(str).tolist()
bankruptcies = df[df['Year'].isin(['2012', '2013', '2014', '2015', '2016'])]['Total bankruptcies [note 8]'].tolist()
plt.plot(years, bankruptcies, marker='o')
plt.title('Trend of Total Bankruptcies from 2012 to 2016')
plt.xlabel('Year')
plt.ylabel('Total Bankruptcies')
plt.xticks(years)
plt.grid(True)
plt.show()

Python Error: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.
Prediction: import pandas as pd 
 import matplotlib.pyplot as plt 
 df = pd.read_excel('table.xlsx')
 years = df[df['Year'].isin(['2012', '2013', '2014', '2015', '2016'])]['Year'].astype(str).tolist()
 bankruptci...
Reference: [[31776.0, 24565.0, 20339.0, 15849.0, 15051.0, 8686.0, 8075.0, 7719.0, 7296.0, 6451.0, 6373.0, 6038.0, 5703.0, 5429.0, 5471.0, 4908.0, 4530.0, 4198.0, 3984.0, 3877.0, 3790.0, 3612.0, 3668.0, 3906.0, 3...
Metrics: {'ECR': False, 'Pass': 'None'}
Checkpoint saved: 370 queries processed
Processing text modality:  13%|█▎        | 413/3071 [1:12:00<5:46:29,  7.82s/it]
============================================================
Query ID: 414 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['1722']
Answer:  ['8719']
Prediction: 1722
Reference: 8719
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  13%|█▎        | 414/3071 [1:12:09<6:08:42,  8.33s/it]
============================================================
Query ID: 415 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['2018']
Answer:  ['2019']
Prediction: 2018
Reference: 2019
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  14%|█▎        | 415/3071 [1:12:19<6:24:14,  8.68s/it]
============================================================
Query ID: 416 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['2020 2021 2022']
Answer:  ['2013 2014 2015 2016 2017 2018 2019 2020 2021']
Prediction: 2020, 2021, 2022
Reference: 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021
Metrics: {'F1': 33.33, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(33.33), 'SacreBLEU': 0.0}
Processing text modality:  14%|█▎        | 416/3071 [1:12:29<6:43:18,  9.11s/it]
============================================================
Query ID: 417 | Type: Data Analysis | SubType: Rudimentary Analysis
============================================================
Predictions:  ['147775 147775']
Answer:  ['187479']
Prediction: 14777.5, 14777.5
Reference: 18747.89
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  14%|█▎        | 417/3071 [1:12:39<6:56:40,  9.42s/it]
============================================================
Query ID: 418 | Type: Data Analysis | SubType: Exploratory Analysis
============================================================
Predictions:  ['strong positive correlation 10']
Answer:  ['strong positive correlation 10']
Prediction: Strong positive correlation, 0.98
Reference: Strong positive correlation, 0.97
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 100.0}
Processing text modality:  14%|█▎        | 418/3071 [1:12:49<7:01:15,  9.53s/it]
============================================================
Query ID: 419 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['6451']
Answer:  ['6451']
Prediction: 6451
Reference: 6451
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:  14%|█▎        | 419/3071 [1:12:56<6:35:08,  8.94s/it]
============================================================
Query ID: 420 | Type: Fact Checking | SubType: Multi-hop Fact Checking
============================================================
Predictions:  ['q4 2012 1805']
Answer:  ['q1 2013 845']
Prediction: Q4 2012, 1805
Reference: Q1 2013, 845
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  14%|█▎        | 420/3071 [1:13:04<6:22:11,  8.65s/it]
============================================================
Query ID: 421 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['no']
Answer:  ['yes']
Prediction: No
Reference: Yes
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  14%|█▎        | 421/3071 [1:13:12<6:05:21,  8.27s/it]
============================================================
Query ID: 422 | Type: Data Analysis | SubType: Rudimentary Analysis
============================================================
Predictions:  ['317760']
Answer:  ['7944']
Prediction: 31776.00
Reference: 7944
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  14%|█▎        | 422/3071 [1:13:19<5:58:48,  8.13s/it]
============================================================
Query ID: 423 | Type: Numerical Reasoning | SubType: Counting
============================================================
Predictions:  ['greece spain costa rica']
Answer:  ['11']
Prediction: Greece, Spain, Costa Rica
Reference: 11
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Checkpoint saved: 380 queries processed
Processing text modality:  14%|█▍        | 423/3071 [1:13:23<5:03:06,  6.87s/it]
============================================================
Query ID: 424 | Type: Numerical Reasoning | SubType: Comparison
============================================================
Predictions:  ['austria 07']
Answer:  ['austria 04']
Prediction: Austria, 0.7
Reference: Austria, 0.4
Metrics: {'F1': 50.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(50.0), 'SacreBLEU': 0.0}
Processing text modality:  14%|█▍        | 424/3071 [1:13:27<4:23:55,  5.98s/it]
============================================================
Query ID: 425 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Predictions:  ['37 37 21 25 32 36 48 32 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 35 3']
Answer:  ['48']
Prediction: 3.7, 3.7, 2.1, 2.5, 3.2, 3.6, 4.8, 3.2, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, ...
Reference: 4.83
Metrics: {'F1': 0.24, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.24), 'SacreBLEU': 0.04}
Processing text modality:  14%|█▍        | 425/3071 [1:16:22<41:36:21, 56.61s/it]
============================================================
Query ID: 426 | Type: Data Analysis | SubType: Exploratory Analysis
============================================================
Predictions:  ['weak positive correlation 05']
Answer:  ['weak positive correlation 07']
Prediction: Weak positive correlation, 0.45
Reference: Weak positive correlation, 0.69
Metrics: {'F1': 75.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(75.0), 'SacreBLEU': 59.46}
Processing text modality:  14%|█▍        | 426/3071 [1:16:26<30:01:17, 40.86s/it]
============================================================
Query ID: 427 | Type: Data Analysis | SubType: Rudimentary Analysis
============================================================
Predictions:  ['50 56 48 122 22 78 42 34 108 45 70 46 84 72 115 50 34 40 51 50 64 53 53 91 43 54 60 61 80 34 30 27 25 29 25 18 17 27']
Answer:  ['65']
Prediction: 5.0, 5.6, 4.8, 12.2, 2.2, 7.8, 4.2, 3.4, 10.8, 4.5, 7.0, 4.6, 8.4, 7.2, 11.5, 5.0, 3.4, 4.0, 5.1, 5.0, 6.4, 5.3, 5.3, 9.1, 4.3, 5.4, 6.0, 6.1, 8.0, 3.4, 3.0, 2.7, 2.5, 2.9, 2.5, 1.8, 1.7, 2.7
Reference: 6.46
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  14%|█▍        | 427/3071 [1:16:37<23:32:01, 32.04s/it]
============================================================
Query ID: 428 | Type: Fact Checking | SubType: Inference-based Fact Checking
============================================================
Predictions:  ['3173375 3302667']
Answer:  ['64760422']
Prediction: 3173375, 3302667
Reference: 6476042.18
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  14%|█▍        | 428/3071 [1:16:44<17:55:08, 24.41s/it]
============================================================
Query ID: 429 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['creative']
Answer:  ['creative']
Prediction: Creative
Reference: Creative
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:  14%|█▍        | 429/3071 [1:16:50<13:49:48, 18.84s/it]
============================================================
Query ID: 430 | Type: Fact Checking | SubType: Value-Matching
============================================================
Predictions:  ['north east']
Answer:  ['north east']
Prediction: North East
Reference: North East
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 0.0}
Processing text modality:  14%|█▍        | 430/3071 [1:16:56<10:58:41, 14.96s/it]
============================================================
Query ID: 431 | Type: Data Analysis | SubType: Rudimentary Analysis
============================================================
Predictions:  ['1899271 3302667 24020716 930128 4349957 10882020 2561668 2775420 2182638 53708763']
Answer:  ['1066132471']
Prediction: 1899271, 3302667, 24020716, 930128, 4349957, 10882020, 2561668, 2775420, 2182638, 53708763
Reference: 106613247.1
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  14%|█▍        | 431/3071 [1:17:06<9:52:13, 13.46s/it] 
============================================================
Query ID: 432 | Type: Data Analysis | SubType: Exploratory Analysis
============================================================
Predictions:  ['strong positive correlation 10']
Answer:  ['strong positive correlation 10']
Prediction: Strong positive correlation, 0.98
Reference: Strong positive correlation, 0.96
Metrics: {'F1': 100.0, 'EM': np.float64(100.0), 'ROUGE-L': np.float64(100.0), 'SacreBLEU': 100.0}
Processing text modality:  14%|█▍        | 432/3071 [1:17:12<8:17:47, 11.32s/it]
============================================================
Query ID: 433 | Type: Numerical Reasoning | SubType: Calculation
============================================================
Generation Error (attempt 1/3): CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.02 GiB is free. Including non-PyTorch memory, this process has 46.37 GiB memory in use. Of the allocated memory 38.07 GiB is allocated by PyTorch, and 7.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Generation Error (attempt 2/3): CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.02 GiB is free. Including non-PyTorch memory, this process has 46.37 GiB memory in use. Of the allocated memory 38.07 GiB is allocated by PyTorch, and 7.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Generation Error (attempt 3/3): CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.02 GiB is free. Including non-PyTorch memory, this process has 46.37 GiB memory in use. Of the allocated memory 38.07 GiB is allocated by PyTorch, and 7.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Predictions:  ['error failed to get response']
Answer:  ['3205']
Prediction: Error: Failed to get response
Reference: 3205
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Checkpoint saved: 390 queries processed
Processing text modality:  14%|█▍        | 433/3071 [1:19:45<39:29:10, 53.89s/it]
============================================================
Query ID: 434 | Type: Numerical Reasoning | SubType: Counting
============================================================
Generation Error (attempt 1/3): CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.02 GiB is free. Including non-PyTorch memory, this process has 46.37 GiB memory in use. Of the allocated memory 38.07 GiB is allocated by PyTorch, and 7.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Generation Error (attempt 2/3): CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.02 GiB is free. Including non-PyTorch memory, this process has 46.37 GiB memory in use. Of the allocated memory 38.07 GiB is allocated by PyTorch, and 7.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Generation Error (attempt 3/3): CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.02 GiB is free. Including non-PyTorch memory, this process has 46.37 GiB memory in use. Of the allocated memory 38.07 GiB is allocated by PyTorch, and 7.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Predictions:  ['error failed to get response']
Answer:  ['1']
Prediction: Error: Failed to get response
Reference: 1
Metrics: {'F1': 0.0, 'EM': np.float64(0.0), 'ROUGE-L': np.float64(0.0), 'SacreBLEU': 0.0}
Processing text modality:  14%|█▍        | 434/3071 [1:22:18<61:15:27, 83.63s/it]
============================================================
Query ID: 435 | Type: Numerical Reasoning | SubType: Comparison
============================================================
Generation Error (attempt 1/3): CUDA out of memory. Tried to allocate 2.55 GiB. GPU 0 has a total capacity of 47.40 GiB of which 1.02 GiB is free. Including non-PyTorch memory, this process has 46.37 GiB memory in use. Of the allocated memory 38.07 GiB is allocated by PyTorch, and 7.99 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
